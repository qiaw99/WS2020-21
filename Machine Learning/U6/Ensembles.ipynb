{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo9GWxKgTN1h"
   },
   "source": [
    "# Mustererkennung/Machine Learning - Assignment 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.347720Z",
     "start_time": "2018-11-29T11:28:47.572823Z"
    },
    "id": "V7XaSv5wTN1i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.406520Z",
     "start_time": "2018-11-29T11:28:48.349530Z"
    },
    "id": "sT2Hk2k-TN1i"
   },
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('./spambase/spambase.data', header=None))\n",
    "\n",
    "X = data[:,:-1] # features\n",
    "y = data[:,-1] # Last column is label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=True, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3450, 57)\n",
      "(1151, 57)\n",
      "(3450,)\n",
      "(1151,)\n",
      "[ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     1.14   0.     0.     0.     0.     0.     0.     2.29   0.\n",
      "  0.     0.     0.     0.     1.14   1.14   0.     0.     0.     0.\n",
      "  1.14   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     2.29   0.     0.     0.     0.     0.     0.\n",
      "  0.     0.596  0.     0.198  2.133 14.    64.   ]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train[1])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority(y):\n",
    "    counts = np.bincount(y)\n",
    "    return np.argmax(counts)\n",
    "\n",
    "def square(num):\n",
    "    return pow(num, 2)\n",
    "\n",
    "# reorder x and y according to j-dimension\n",
    "def reorder_data(x_data, y_data, j):\n",
    "    index = x_data[:,j-1].argsort()\n",
    "    \n",
    "    temp_x = x_data[index]\n",
    "    temp_y = y_data[index]\n",
    "    \n",
    "    return temp_x, temp_y\n",
    "\n",
    "def calculate_entropy(feature, y_data):\n",
    "    right = (feature == True).sum() / feature.size\n",
    "    left = 1 - right\n",
    "    \n",
    "    left_child = np.sum(y_data[feature]) / y_data[feature].size\n",
    "    right_child = np.sum(y_data[np.invert(feature)]) / y_data[np.invert(feature)].size\n",
    "    \n",
    "    Q_1 = right * loss_function(left_child)\n",
    "    Q_2 = left * loss_function(right_child)\n",
    "    Q_tot = Q_1 + Q_2\n",
    "    \n",
    "    return Q_tot, right_child, left_child\n",
    "\n",
    "def loss_function(p):\n",
    "        if p == 1 or p == 0: \n",
    "            return 0\n",
    "        \n",
    "        return - (p * np.log(p) + (1-p) * np.log((1-p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    \n",
    "    def __init__(self, height):\n",
    "        self.min_size = 3\n",
    "        self.height = height\n",
    "        \n",
    "    def set_min_size(self, min_size):\n",
    "        self.min_size = min_size\n",
    "    \n",
    "    def fit(self, X_data, y_data, sample_weight=None):\n",
    "        self.tree_size = pow(2, self.height) - 1\n",
    "        self.tmp_size = pow(2, self.height + 1) - 1\n",
    "        self.features = X_data.shape[1]\n",
    "        self.tree = np.full(self.tmp_size, -1)\n",
    "        self.tree_tmp = np.full(self.tmp_size + 1, -1)\n",
    "        \n",
    "        self.split_tree(X_data, y_data, 0)\n",
    "    \n",
    "    # go through the decision tree\n",
    "    def predict(self, X_data):\n",
    "        predictions = []\n",
    "        for x in X_data:\n",
    "            i = 0\n",
    "            leaf = self.tree[i]\n",
    "            \n",
    "            while self.tree[self.left_node(i)] != -1 or self.tree[self.right_node(i)] != -1:\n",
    "\n",
    "                if leaf >= self.tree_size:\n",
    "                    return\n",
    "                \n",
    "                if x[leaf]:\n",
    "                    i = self.right_node(i)\n",
    "                else:\n",
    "                    i = self.left_node(i)\n",
    "                prediction = self.tree_tmp[i]\n",
    "                leaf = self.tree[i]\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "    \n",
    "    def split_data(self, index, value, X_data):\n",
    "        left, right = [], []\n",
    "        for x in X_data:\n",
    "            if x[index] < value:\n",
    "                left.append(x)\n",
    "            else:\n",
    "                right.append(x)\n",
    "        return left, right\n",
    "        \n",
    "    def split_tree(self, X_data, y_data, leaf):\n",
    "        if leaf >= self.tree_size:\n",
    "            return\n",
    "        \n",
    "        entropies = np.full(self.features, np.inf) \n",
    "        left = np.empty(self.features)\n",
    "        right = np.empty(self.features)\n",
    "        \n",
    "        for i, feature in enumerate(X_data.T):\n",
    "            temp = feature.astype(int)\n",
    "            if np.sum(feature) == 0 or np.sum(np.invert(temp)) == 0:\n",
    "                continue \n",
    "            entropies[i], left[i], right[i] = calculate_entropy(feature, y_data)\n",
    "        \n",
    "        index = np.argmin(entropies)\n",
    "        \n",
    "        right = X_data[:,index]\n",
    "        left = np.invert(right)\n",
    "\n",
    "        self.tree[leaf] = index\n",
    "        if index < len(self.tree_tmp):\n",
    "            if (index < len(left)) and (index < len(right)):\n",
    "                self.tree_tmp[self.left_node(leaf)] = left[index]\n",
    "                self.tree_tmp[self.right_node(leaf)] = right[index]\n",
    "        \n",
    "        if len(y_data[right]) == 0 or len(y_data[left]) == 0:\n",
    "            return\n",
    "\n",
    "        if leaf >= self.min_size:\n",
    "            return\n",
    "\n",
    "        self.split_tree(X_data[left], y_data[left], self.left_node(leaf))\n",
    "        self.split_tree(X_data[right], y_data[right], self.right_node(leaf))\n",
    "            \n",
    "    def left_node(self, node):\n",
    "        return 2 * node + 1\n",
    "    \n",
    "    def right_node(self, node):\n",
    "        return 2 * node + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-91ecc1c01dec>:33: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  right_child = np.sum(y_data[np.invert(feature)]) / y_data[np.invert(feature)].size\n"
     ]
    }
   ],
   "source": [
    "means = (np.mean(X_train[y_train==1], axis=0) + np.mean(X_train[y_train==0])) / 2 \n",
    "                  \n",
    "X_train_means = X_train > means\n",
    "X_test_means = X_test > means\n",
    "\n",
    "tree = DecisionTree(20)\n",
    "tree.fit(X_train_means, y_train)\n",
    "predictions = tree.predict(X_test_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 a)\n",
    "If classifying a genuine E-Mail as spam is ten times worse than classifying spam as genuine, we can just exchange the prediction value from 1 to 0 and from 0 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[365   0]\n",
      " [  0 786]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "estimates = (np.array(predictions) > 0.5)\n",
    "print(confusion_matrix(predictions, estimates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 features: \n",
    "1. address \n",
    "2. free \n",
    "3. money \n",
    "4. direct \n",
    "5. re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [1, 15, 23, 39, 44]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    \n",
    "    def __init__(self, height=7, n_trees = 100):\n",
    "        self.n_trees = n_trees\n",
    "        self.height = height\n",
    "        self.trees = [DecisionTree(height = height) for _ in range(n_trees)]\n",
    "    \n",
    "    def fit(self, X, y, n_samples = 500):        \n",
    "        for tree in self.trees:\n",
    "            random_samples = np.random.randint(0, high=len(X), size=n_samples)\n",
    "            \n",
    "            X_train = X[random_samples]\n",
    "            y_train = y[random_samples]\n",
    "            \n",
    "            random_features = np.random.randint(0, high=len(X.T), size=self.height*2)\n",
    "            X_train = X_train[:,random_features]          \n",
    "            \n",
    "            means = (np.mean(X_train[y_train==1], axis=0) + np.mean(X_train[y_train==0])) / 2       \n",
    "            X_train_means = (X_train > means)\n",
    "            tree.fit(X_train_means, y_train)\n",
    "        \n",
    "    def predict(self,X):\n",
    "        forest_predictions = np.array(self.trees[0].predict(X))\n",
    "        forest_predictions = forest_predictions[:, np.newaxis]\n",
    "        \n",
    "        for i in range(1, self.n_trees):\n",
    "            prediction = np.array(self.trees[i].predict(X))\n",
    "            forest_predictions = np.append(forest_predictions, prediction[:, np.newaxis], axis=1)\n",
    "        \n",
    "        avg = np.array(np.mean(forest_predictions, axis=0))\n",
    "        return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tree):\n",
    "    random_forest = RandomForest(height=7, n_trees=tree)\n",
    "    random_forest.fit(X, y, n_samples = 1000)\n",
    "    predictions_rf = random_forest.predict(X_test_means)\n",
    "\n",
    "    estimates_rf = (np.array(predictions_rf) > 0.5)\n",
    "    \n",
    "    print(\"trees: \", tree)\n",
    "    print(confusion_matrix(predictions_rf.round(), estimates_rf.round()))\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-91ecc1c01dec>:33: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  right_child = np.sum(y_data[np.invert(feature)]) / y_data[np.invert(feature)].size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trees:  10\n",
      "[[10]]\n",
      "-----\n",
      "trees:  30\n",
      "[[ 7  0]\n",
      " [ 0 23]]\n",
      "-----\n",
      "trees:  100\n",
      "[[ 9  0]\n",
      " [ 0 91]]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "test(10)\n",
    "test(30)\n",
    "test(100)\n",
    "\n",
    "# for tree in range(5, 300, 25):\n",
    "#     test(tree)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 b)\n",
    "In general, the more trees you use the better get the results. However, the improvement decreases as the number of trees increases, i.e. at a certain point the benefit in prediction performance from learning more trees will be lower than the cost in computation time for learning these additional trees.\n",
    "\n",
    "Typical values for the number of trees is 10, 30 or 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ensembles.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
