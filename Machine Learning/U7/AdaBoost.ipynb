{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo9GWxKgTN1h"
   },
   "source": [
    "# Mustererkennung/Machine Learning - Assignment 7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.347720Z",
     "start_time": "2018-11-29T11:28:47.572823Z"
    },
    "id": "V7XaSv5wTN1i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax8ea49_bkdb"
   },
   "source": [
    "### Load the spam dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T11:28:48.406520Z",
     "start_time": "2018-11-29T11:28:48.349530Z"
    },
    "id": "sT2Hk2k-TN1i"
   },
   "outputs": [],
   "source": [
    "data = np.array(pd.read_csv('./spambase/spambase.data', header=None))\n",
    "\n",
    "X = data[:,:-1] # features\n",
    "y = data[:,-1] # Last column is label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, shuffle=True, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3450, 57)\n",
      "(1151, 57)\n",
      "(3450,)\n",
      "(1151,)\n",
      "[ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     1.14   0.     0.     0.     0.     0.     0.     2.29   0.\n",
      "  0.     0.     0.     0.     1.14   1.14   0.     0.     0.     0.\n",
      "  1.14   0.     0.     0.     0.     0.     0.     0.     0.     0.\n",
      "  0.     0.     0.     2.29   0.     0.     0.     0.     0.     0.\n",
      "  0.     0.596  0.     0.198  2.133 14.    64.   ]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train[1])\n",
    "print(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def my_adaboost_clf(Y_train, X_train, Y_test, X_test, n_trees=20, weak_clf=tree.DecisionTreeClassifier(max_depth = 1)):\n",
    "    n_train, n_test = X_train.shape[0], X_test.shape[0]\n",
    "    \n",
    "    # Initialize all w_i\n",
    "    w = np.ones(n_train) / n_train\n",
    "    \n",
    "    pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        # Fit a classifier with the specific weights\n",
    "        weak_clf.fit(X_train, Y_train, sample_weight = w)\n",
    "        \n",
    "        pred_train_i = weak_clf.predict(X_train)\n",
    "        pred_test_i = weak_clf.predict(X_test)\n",
    "        \n",
    "        # Indicator function\n",
    "        miss = [int(x) for x in (pred_train_i != Y_train)]\n",
    "        print(\"weak_clf_%02d train acc: %.4f\" % (i + 1, 1 - sum(miss) / n_train))\n",
    "        \n",
    "        # Error\n",
    "        err_m = np.dot(w, miss)\n",
    "        \n",
    "        # Alpha\n",
    "        alpha_m = 0.5 * np.log((1 - err_m) / float(err_m))\n",
    "        \n",
    "        # New weights\n",
    "        miss2 = [x if x==1 else -1 for x in miss] # -1 * y_i * G(x_i): 1 / -1\n",
    "        w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2]))\n",
    "        w = w / sum(w)\n",
    "\n",
    "        # Add to prediction\n",
    "        pred_train_i = [1 if x == 1 else -1 for x in pred_train_i]\n",
    "        pred_test_i = [1 if x == 1 else -1 for x in pred_test_i]\n",
    "        pred_train = pred_train + np.multiply(alpha_m, pred_train_i)\n",
    "        pred_test = pred_test + np.multiply(alpha_m, pred_test_i)\n",
    "    \n",
    "    print(\"**************************************\")\n",
    "    print(\"Confusion matrix:\")\n",
    "    pred_train = (pred_train > 0) * 1\n",
    "    estimates = (np.array(pred_train) > 0.5)\n",
    "    print(confusion_matrix(pred_train, estimates))\n",
    "    \n",
    "    pred_test = (pred_test > 0) * 1\n",
    "    estimates = (np.array(pred_test) > 0.5)\n",
    "    print(confusion_matrix(pred_test, estimates))\n",
    "    \n",
    "    print(\"**************************************\")\n",
    "\n",
    "    print(\"My AdaBoost clf train accuracy: %.4f\" % (sum(pred_train == Y_train) / n_train))\n",
    "    print(\"My AdaBoost clf test accuracy: %.4f\" % (sum(pred_test == Y_test) / n_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weak_clf_01 train acc: 0.7928\n",
      "weak_clf_02 train acc: 0.7925\n",
      "weak_clf_03 train acc: 0.6061\n",
      "weak_clf_04 train acc: 0.7586\n",
      "weak_clf_05 train acc: 0.5597\n",
      "weak_clf_06 train acc: 0.7145\n",
      "weak_clf_07 train acc: 0.7214\n",
      "weak_clf_08 train acc: 0.5296\n",
      "weak_clf_09 train acc: 0.6061\n",
      "weak_clf_10 train acc: 0.4571\n",
      "weak_clf_11 train acc: 0.6061\n",
      "weak_clf_12 train acc: 0.5597\n",
      "weak_clf_13 train acc: 0.6061\n",
      "weak_clf_14 train acc: 0.4849\n",
      "weak_clf_15 train acc: 0.6061\n",
      "weak_clf_16 train acc: 0.5597\n",
      "weak_clf_17 train acc: 0.6061\n",
      "weak_clf_18 train acc: 0.4893\n",
      "weak_clf_19 train acc: 0.6061\n",
      "weak_clf_20 train acc: 0.6061\n",
      "**************************************\n",
      "Confusion matrix:\n",
      "[[2136    0]\n",
      " [   0 1314]]\n",
      "[[711   0]\n",
      " [  0 440]]\n",
      "**************************************\n",
      "My AdaBoost clf train accuracy: 0.9116\n",
      "My AdaBoost clf test accuracy: 0.9114\n"
     ]
    }
   ],
   "source": [
    "my_adaboost_clf(y_train, X_train, y_test, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Ensembles.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
