{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hqhD_QjKWQV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "global first_layer\n",
    "first_layer = 1\n",
    "\n",
    "global res \n",
    "res = None\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "\n",
    "        # Skip the layer\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 16,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 32, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 64, 2, stride=2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 128, 2, stride=2)\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    # Initialize the layer\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)   #strides=[1,1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        global first_layer\n",
    "        global res \n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        if(first_layer == 1):\n",
    "          #print(\"First layer\")\n",
    "          #print(out)\n",
    "          res = out\n",
    "          first_layer += 1\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tf-q0aZDExNT"
   },
   "source": [
    "# Task 2\n",
    "Plot the loss and acc at each iteration and epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "0446944c23cb48b08cd1e0d270478a5b",
      "494eb3708e364fabb989d364d8c2d1d9",
      "759886e77ad941cd8ebc9b3d33311fb2",
      "8cb2a46ee9044db6b2f1aba1b5d01f1f",
      "c7d5e01911ac4a8c974ac2e66902de11",
      "67f97d835c6d46648af2cfb703882ca0",
      "4fdb7a3f28514830ab18df59dcbb19a9",
      "93163ac16ca14b1e8870852b67209f12"
     ]
    },
    "id": "ECj1-C-5d_NI",
    "outputId": "6aeb91b8-d189-4015-e1a1-e6fea137854b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0446944c23cb48b08cd1e0d270478a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n",
      "Start Training, Resnet-18!\n",
      "\n",
      "Epoch: 1\n",
      "[epoch:1, iter:1] Loss: 2.331 | Acc: 10.938% \n",
      "[epoch:1, iter:2] Loss: 2.352 | Acc: 10.938% \n",
      "[epoch:1, iter:3] Loss: 2.359 | Acc: 10.156% \n",
      "[epoch:1, iter:4] Loss: 2.356 | Acc: 11.523% \n",
      "[epoch:1, iter:5] Loss: 2.340 | Acc: 12.500% \n",
      "[epoch:1, iter:6] Loss: 2.335 | Acc: 12.109% \n",
      "[epoch:1, iter:7] Loss: 2.327 | Acc: 12.612% \n",
      "[epoch:1, iter:8] Loss: 2.318 | Acc: 12.988% \n",
      "[epoch:1, iter:9] Loss: 2.309 | Acc: 13.802% \n",
      "[epoch:1, iter:10] Loss: 2.298 | Acc: 13.906% \n",
      "[epoch:1, iter:11] Loss: 2.296 | Acc: 13.849% \n",
      "[epoch:1, iter:12] Loss: 2.289 | Acc: 13.477% \n",
      "[epoch:1, iter:13] Loss: 2.282 | Acc: 13.702% \n",
      "[epoch:1, iter:14] Loss: 2.270 | Acc: 14.230% \n",
      "[epoch:1, iter:15] Loss: 2.255 | Acc: 14.896% \n",
      "[epoch:1, iter:16] Loss: 2.245 | Acc: 15.088% \n",
      "[epoch:1, iter:17] Loss: 2.238 | Acc: 15.074% \n",
      "[epoch:1, iter:18] Loss: 2.228 | Acc: 15.538% \n",
      "[epoch:1, iter:19] Loss: 2.217 | Acc: 15.872% \n",
      "[epoch:1, iter:20] Loss: 2.207 | Acc: 16.094% \n",
      "[epoch:1, iter:21] Loss: 2.197 | Acc: 16.555% \n",
      "[epoch:1, iter:22] Loss: 2.186 | Acc: 16.903% \n",
      "[epoch:1, iter:23] Loss: 2.181 | Acc: 16.984% \n",
      "[epoch:1, iter:24] Loss: 2.170 | Acc: 17.253% \n",
      "[epoch:1, iter:25] Loss: 2.160 | Acc: 17.281% \n",
      "[epoch:1, iter:26] Loss: 2.156 | Acc: 17.368% \n",
      "[epoch:1, iter:27] Loss: 2.145 | Acc: 17.506% \n",
      "[epoch:1, iter:28] Loss: 2.139 | Acc: 17.634% \n",
      "[epoch:1, iter:29] Loss: 2.130 | Acc: 18.050% \n",
      "[epoch:1, iter:30] Loss: 2.126 | Acc: 18.099% \n",
      "[epoch:1, iter:31] Loss: 2.120 | Acc: 18.271% \n",
      "[epoch:1, iter:32] Loss: 2.112 | Acc: 18.579% \n",
      "[epoch:1, iter:33] Loss: 2.106 | Acc: 18.797% \n",
      "[epoch:1, iter:34] Loss: 2.099 | Acc: 18.865% \n",
      "[epoch:1, iter:35] Loss: 2.096 | Acc: 19.062% \n",
      "[epoch:1, iter:36] Loss: 2.091 | Acc: 19.336% \n",
      "[epoch:1, iter:37] Loss: 2.083 | Acc: 19.700% \n",
      "[epoch:1, iter:38] Loss: 2.077 | Acc: 20.004% \n",
      "[epoch:1, iter:39] Loss: 2.069 | Acc: 20.373% \n",
      "[epoch:1, iter:40] Loss: 2.063 | Acc: 20.723% \n",
      "[epoch:1, iter:41] Loss: 2.057 | Acc: 20.922% \n",
      "[epoch:1, iter:42] Loss: 2.054 | Acc: 21.094% \n",
      "[epoch:1, iter:43] Loss: 2.050 | Acc: 21.130% \n",
      "[epoch:1, iter:44] Loss: 2.043 | Acc: 21.591% \n",
      "[epoch:1, iter:45] Loss: 2.038 | Acc: 21.701% \n",
      "[epoch:1, iter:46] Loss: 2.033 | Acc: 21.960% \n",
      "[epoch:1, iter:47] Loss: 2.028 | Acc: 22.141% \n",
      "[epoch:1, iter:48] Loss: 2.020 | Acc: 22.428% \n",
      "[epoch:1, iter:49] Loss: 2.018 | Acc: 22.513% \n",
      "[epoch:1, iter:50] Loss: 2.010 | Acc: 22.828% \n",
      "[epoch:1, iter:51] Loss: 2.005 | Acc: 22.993% \n",
      "[epoch:1, iter:52] Loss: 2.001 | Acc: 23.167% \n",
      "[epoch:1, iter:53] Loss: 1.996 | Acc: 23.364% \n",
      "[epoch:1, iter:54] Loss: 1.994 | Acc: 23.452% \n",
      "[epoch:1, iter:55] Loss: 1.989 | Acc: 23.679% \n",
      "[epoch:1, iter:56] Loss: 1.984 | Acc: 23.870% \n",
      "[epoch:1, iter:57] Loss: 1.979 | Acc: 24.054% \n",
      "[epoch:1, iter:58] Loss: 1.974 | Acc: 24.246% \n",
      "[epoch:1, iter:59] Loss: 1.969 | Acc: 24.391% \n",
      "[epoch:1, iter:60] Loss: 1.967 | Acc: 24.466% \n",
      "[epoch:1, iter:61] Loss: 1.961 | Acc: 24.590% \n",
      "[epoch:1, iter:62] Loss: 1.958 | Acc: 24.685% \n",
      "[epoch:1, iter:63] Loss: 1.953 | Acc: 24.913% \n",
      "[epoch:1, iter:64] Loss: 1.951 | Acc: 25.024% \n",
      "[epoch:1, iter:65] Loss: 1.947 | Acc: 25.204% \n",
      "[epoch:1, iter:66] Loss: 1.944 | Acc: 25.391% \n",
      "[epoch:1, iter:67] Loss: 1.940 | Acc: 25.501% \n",
      "[epoch:1, iter:68] Loss: 1.938 | Acc: 25.597% \n",
      "[epoch:1, iter:69] Loss: 1.933 | Acc: 25.725% \n",
      "[epoch:1, iter:70] Loss: 1.932 | Acc: 25.848% \n",
      "[epoch:1, iter:71] Loss: 1.927 | Acc: 26.045% \n",
      "[epoch:1, iter:72] Loss: 1.923 | Acc: 26.183% \n",
      "[epoch:1, iter:73] Loss: 1.921 | Acc: 26.274% \n",
      "[epoch:1, iter:74] Loss: 1.916 | Acc: 26.383% \n",
      "[epoch:1, iter:75] Loss: 1.914 | Acc: 26.500% \n",
      "[epoch:1, iter:76] Loss: 1.911 | Acc: 26.614% \n",
      "[epoch:1, iter:77] Loss: 1.909 | Acc: 26.755% \n",
      "[epoch:1, iter:78] Loss: 1.907 | Acc: 26.803% \n",
      "[epoch:1, iter:79] Loss: 1.905 | Acc: 26.869% \n",
      "[epoch:1, iter:80] Loss: 1.902 | Acc: 26.924% \n",
      "[epoch:1, iter:81] Loss: 1.901 | Acc: 26.948% \n",
      "[epoch:1, iter:82] Loss: 1.899 | Acc: 27.039% \n",
      "[epoch:1, iter:83] Loss: 1.894 | Acc: 27.240% \n",
      "[epoch:1, iter:84] Loss: 1.890 | Acc: 27.418% \n",
      "[epoch:1, iter:85] Loss: 1.889 | Acc: 27.509% \n",
      "[epoch:1, iter:86] Loss: 1.886 | Acc: 27.616% \n",
      "[epoch:1, iter:87] Loss: 1.884 | Acc: 27.766% \n",
      "[epoch:1, iter:88] Loss: 1.882 | Acc: 27.903% \n",
      "[epoch:1, iter:89] Loss: 1.880 | Acc: 27.906% \n",
      "[epoch:1, iter:90] Loss: 1.876 | Acc: 28.073% \n",
      "[epoch:1, iter:91] Loss: 1.875 | Acc: 28.134% \n",
      "[epoch:1, iter:92] Loss: 1.872 | Acc: 28.303% \n",
      "[epoch:1, iter:93] Loss: 1.872 | Acc: 28.259% \n",
      "[epoch:1, iter:94] Loss: 1.869 | Acc: 28.324% \n",
      "[epoch:1, iter:95] Loss: 1.868 | Acc: 28.380% \n",
      "[epoch:1, iter:96] Loss: 1.866 | Acc: 28.451% \n",
      "[epoch:1, iter:97] Loss: 1.863 | Acc: 28.600% \n",
      "[epoch:1, iter:98] Loss: 1.861 | Acc: 28.691% \n",
      "[epoch:1, iter:99] Loss: 1.859 | Acc: 28.772% \n",
      "[epoch:1, iter:100] Loss: 1.855 | Acc: 28.883% \n",
      "[epoch:1, iter:101] Loss: 1.851 | Acc: 29.100% \n",
      "[epoch:1, iter:102] Loss: 1.849 | Acc: 29.220% \n",
      "[epoch:1, iter:103] Loss: 1.847 | Acc: 29.331% \n",
      "[epoch:1, iter:104] Loss: 1.846 | Acc: 29.334% \n",
      "[epoch:1, iter:105] Loss: 1.845 | Acc: 29.360% \n",
      "[epoch:1, iter:106] Loss: 1.843 | Acc: 29.466% \n",
      "[epoch:1, iter:107] Loss: 1.839 | Acc: 29.666% \n",
      "[epoch:1, iter:108] Loss: 1.837 | Acc: 29.789% \n",
      "[epoch:1, iter:109] Loss: 1.834 | Acc: 29.881% \n",
      "[epoch:1, iter:110] Loss: 1.832 | Acc: 29.979% \n",
      "[epoch:1, iter:111] Loss: 1.830 | Acc: 30.061% \n",
      "[epoch:1, iter:112] Loss: 1.828 | Acc: 30.141% \n",
      "[epoch:1, iter:113] Loss: 1.827 | Acc: 30.178% \n",
      "[epoch:1, iter:114] Loss: 1.825 | Acc: 30.311% \n",
      "[epoch:1, iter:115] Loss: 1.822 | Acc: 30.414% \n",
      "[epoch:1, iter:116] Loss: 1.821 | Acc: 30.462% \n",
      "[epoch:1, iter:117] Loss: 1.819 | Acc: 30.569% \n",
      "[epoch:1, iter:118] Loss: 1.818 | Acc: 30.608% \n",
      "[epoch:1, iter:119] Loss: 1.816 | Acc: 30.685% \n",
      "[epoch:1, iter:120] Loss: 1.814 | Acc: 30.768% \n",
      "[epoch:1, iter:121] Loss: 1.812 | Acc: 30.817% \n",
      "[epoch:1, iter:122] Loss: 1.809 | Acc: 30.898% \n",
      "[epoch:1, iter:123] Loss: 1.807 | Acc: 30.977% \n",
      "[epoch:1, iter:124] Loss: 1.804 | Acc: 31.092% \n",
      "[epoch:1, iter:125] Loss: 1.803 | Acc: 31.138% \n",
      "[epoch:1, iter:126] Loss: 1.802 | Acc: 31.169% \n",
      "[epoch:1, iter:127] Loss: 1.800 | Acc: 31.238% \n",
      "[epoch:1, iter:128] Loss: 1.799 | Acc: 31.299% \n",
      "[epoch:1, iter:129] Loss: 1.797 | Acc: 31.414% \n",
      "[epoch:1, iter:130] Loss: 1.795 | Acc: 31.526% \n",
      "[epoch:1, iter:131] Loss: 1.793 | Acc: 31.584% \n",
      "[epoch:1, iter:132] Loss: 1.792 | Acc: 31.664% \n",
      "[epoch:1, iter:133] Loss: 1.790 | Acc: 31.714% \n",
      "[epoch:1, iter:134] Loss: 1.788 | Acc: 31.804% \n",
      "[epoch:1, iter:135] Loss: 1.786 | Acc: 31.892% \n",
      "[epoch:1, iter:136] Loss: 1.785 | Acc: 31.945% \n",
      "[epoch:1, iter:137] Loss: 1.784 | Acc: 31.963% \n",
      "[epoch:1, iter:138] Loss: 1.782 | Acc: 32.082% \n",
      "[epoch:1, iter:139] Loss: 1.780 | Acc: 32.189% \n",
      "[epoch:1, iter:140] Loss: 1.778 | Acc: 32.266% \n",
      "[epoch:1, iter:141] Loss: 1.776 | Acc: 32.386% \n",
      "[epoch:1, iter:142] Loss: 1.775 | Acc: 32.416% \n",
      "[epoch:1, iter:143] Loss: 1.774 | Acc: 32.485% \n",
      "[epoch:1, iter:144] Loss: 1.773 | Acc: 32.541% \n",
      "[epoch:1, iter:145] Loss: 1.772 | Acc: 32.602% \n",
      "[epoch:1, iter:146] Loss: 1.771 | Acc: 32.647% \n",
      "[epoch:1, iter:147] Loss: 1.769 | Acc: 32.733% \n",
      "[epoch:1, iter:148] Loss: 1.767 | Acc: 32.828% \n",
      "[epoch:1, iter:149] Loss: 1.766 | Acc: 32.870% \n",
      "[epoch:1, iter:150] Loss: 1.765 | Acc: 32.932% \n",
      "[epoch:1, iter:151] Loss: 1.764 | Acc: 32.968% \n",
      "[epoch:1, iter:152] Loss: 1.762 | Acc: 33.080% \n",
      "[epoch:1, iter:153] Loss: 1.761 | Acc: 33.104% \n",
      "[epoch:1, iter:154] Loss: 1.760 | Acc: 33.157% \n",
      "[epoch:1, iter:155] Loss: 1.758 | Acc: 33.216% \n",
      "[epoch:1, iter:156] Loss: 1.757 | Acc: 33.288% \n",
      "[epoch:1, iter:157] Loss: 1.755 | Acc: 33.350% \n",
      "[epoch:1, iter:158] Loss: 1.753 | Acc: 33.475% \n",
      "[epoch:1, iter:159] Loss: 1.752 | Acc: 33.520% \n",
      "[epoch:1, iter:160] Loss: 1.750 | Acc: 33.584% \n",
      "[epoch:1, iter:161] Loss: 1.749 | Acc: 33.642% \n",
      "[epoch:1, iter:162] Loss: 1.747 | Acc: 33.724% \n",
      "[epoch:1, iter:163] Loss: 1.746 | Acc: 33.809% \n",
      "[epoch:1, iter:164] Loss: 1.744 | Acc: 33.875% \n",
      "[epoch:1, iter:165] Loss: 1.743 | Acc: 33.902% \n",
      "[epoch:1, iter:166] Loss: 1.741 | Acc: 34.017% \n",
      "[epoch:1, iter:167] Loss: 1.739 | Acc: 34.094% \n",
      "[epoch:1, iter:168] Loss: 1.737 | Acc: 34.194% \n",
      "[epoch:1, iter:169] Loss: 1.736 | Acc: 34.250% \n",
      "[epoch:1, iter:170] Loss: 1.736 | Acc: 34.278% \n",
      "[epoch:1, iter:171] Loss: 1.736 | Acc: 34.320% \n",
      "[epoch:1, iter:172] Loss: 1.734 | Acc: 34.375% \n",
      "[epoch:1, iter:173] Loss: 1.733 | Acc: 34.389% \n",
      "[epoch:1, iter:174] Loss: 1.732 | Acc: 34.429% \n",
      "[epoch:1, iter:175] Loss: 1.732 | Acc: 34.473% \n",
      "[epoch:1, iter:176] Loss: 1.730 | Acc: 34.539% \n",
      "[epoch:1, iter:177] Loss: 1.729 | Acc: 34.587% \n",
      "[epoch:1, iter:178] Loss: 1.728 | Acc: 34.647% \n",
      "[epoch:1, iter:179] Loss: 1.726 | Acc: 34.694% \n",
      "[epoch:1, iter:180] Loss: 1.726 | Acc: 34.753% \n",
      "[epoch:1, iter:181] Loss: 1.724 | Acc: 34.820% \n",
      "[epoch:1, iter:182] Loss: 1.723 | Acc: 34.843% \n",
      "[epoch:1, iter:183] Loss: 1.723 | Acc: 34.845% \n",
      "[epoch:1, iter:184] Loss: 1.721 | Acc: 34.931% \n",
      "[epoch:1, iter:185] Loss: 1.720 | Acc: 34.996% \n",
      "[epoch:1, iter:186] Loss: 1.720 | Acc: 34.980% \n",
      "[epoch:1, iter:187] Loss: 1.719 | Acc: 35.048% \n",
      "[epoch:1, iter:188] Loss: 1.719 | Acc: 35.023% \n",
      "[epoch:1, iter:189] Loss: 1.718 | Acc: 35.094% \n",
      "[epoch:1, iter:190] Loss: 1.716 | Acc: 35.169% \n",
      "[epoch:1, iter:191] Loss: 1.715 | Acc: 35.238% \n",
      "[epoch:1, iter:192] Loss: 1.714 | Acc: 35.258% \n",
      "[epoch:1, iter:193] Loss: 1.713 | Acc: 35.298% \n",
      "[epoch:1, iter:194] Loss: 1.712 | Acc: 35.350% \n",
      "[epoch:1, iter:195] Loss: 1.711 | Acc: 35.397% \n",
      "[epoch:1, iter:196] Loss: 1.710 | Acc: 35.443% \n",
      "[epoch:1, iter:197] Loss: 1.708 | Acc: 35.493% \n",
      "[epoch:1, iter:198] Loss: 1.708 | Acc: 35.515% \n",
      "[epoch:1, iter:199] Loss: 1.707 | Acc: 35.514% \n",
      "[epoch:1, iter:200] Loss: 1.707 | Acc: 35.559% \n",
      "[epoch:1, iter:201] Loss: 1.706 | Acc: 35.623% \n",
      "[epoch:1, iter:202] Loss: 1.704 | Acc: 35.682% \n",
      "[epoch:1, iter:203] Loss: 1.702 | Acc: 35.737% \n",
      "[epoch:1, iter:204] Loss: 1.701 | Acc: 35.777% \n",
      "[epoch:1, iter:205] Loss: 1.700 | Acc: 35.823% \n",
      "[epoch:1, iter:206] Loss: 1.700 | Acc: 35.862% \n",
      "[epoch:1, iter:207] Loss: 1.699 | Acc: 35.911% \n",
      "[epoch:1, iter:208] Loss: 1.698 | Acc: 35.945% \n",
      "[epoch:1, iter:209] Loss: 1.697 | Acc: 35.967% \n",
      "[epoch:1, iter:210] Loss: 1.696 | Acc: 36.001% \n",
      "[epoch:1, iter:211] Loss: 1.695 | Acc: 36.071% \n",
      "[epoch:1, iter:212] Loss: 1.693 | Acc: 36.111% \n",
      "[epoch:1, iter:213] Loss: 1.693 | Acc: 36.139% \n",
      "[epoch:1, iter:214] Loss: 1.692 | Acc: 36.167% \n",
      "[epoch:1, iter:215] Loss: 1.690 | Acc: 36.239% \n",
      "[epoch:1, iter:216] Loss: 1.688 | Acc: 36.303% \n",
      "[epoch:1, iter:217] Loss: 1.687 | Acc: 36.373% \n",
      "[epoch:1, iter:218] Loss: 1.686 | Acc: 36.396% \n",
      "[epoch:1, iter:219] Loss: 1.685 | Acc: 36.440% \n",
      "[epoch:1, iter:220] Loss: 1.685 | Acc: 36.460% \n",
      "[epoch:1, iter:221] Loss: 1.684 | Acc: 36.528% \n",
      "[epoch:1, iter:222] Loss: 1.682 | Acc: 36.589% \n",
      "[epoch:1, iter:223] Loss: 1.681 | Acc: 36.631% \n",
      "[epoch:1, iter:224] Loss: 1.680 | Acc: 36.632% \n",
      "[epoch:1, iter:225] Loss: 1.678 | Acc: 36.736% \n",
      "[epoch:1, iter:226] Loss: 1.677 | Acc: 36.774% \n",
      "[epoch:1, iter:227] Loss: 1.676 | Acc: 36.781% \n",
      "[epoch:1, iter:228] Loss: 1.675 | Acc: 36.846% \n",
      "[epoch:1, iter:229] Loss: 1.673 | Acc: 36.900% \n",
      "[epoch:1, iter:230] Loss: 1.672 | Acc: 36.919% \n",
      "[epoch:1, iter:231] Loss: 1.671 | Acc: 36.955% \n",
      "[epoch:1, iter:232] Loss: 1.670 | Acc: 36.998% \n",
      "[epoch:1, iter:233] Loss: 1.669 | Acc: 37.057% \n",
      "[epoch:1, iter:234] Loss: 1.668 | Acc: 37.093% \n",
      "[epoch:1, iter:235] Loss: 1.666 | Acc: 37.158% \n",
      "[epoch:1, iter:236] Loss: 1.665 | Acc: 37.199% \n",
      "[epoch:1, iter:237] Loss: 1.664 | Acc: 37.269% \n",
      "[epoch:1, iter:238] Loss: 1.663 | Acc: 37.303% \n",
      "[epoch:1, iter:239] Loss: 1.662 | Acc: 37.366% \n",
      "[epoch:1, iter:240] Loss: 1.661 | Acc: 37.383% \n",
      "[epoch:1, iter:241] Loss: 1.660 | Acc: 37.432% \n",
      "[epoch:1, iter:242] Loss: 1.659 | Acc: 37.474% \n",
      "[epoch:1, iter:243] Loss: 1.657 | Acc: 37.523% \n",
      "[epoch:1, iter:244] Loss: 1.657 | Acc: 37.554% \n",
      "[epoch:1, iter:245] Loss: 1.656 | Acc: 37.564% \n",
      "[epoch:1, iter:246] Loss: 1.655 | Acc: 37.605% \n",
      "[epoch:1, iter:247] Loss: 1.654 | Acc: 37.642% \n",
      "[epoch:1, iter:248] Loss: 1.653 | Acc: 37.664% \n",
      "[epoch:1, iter:249] Loss: 1.652 | Acc: 37.698% \n",
      "[epoch:1, iter:250] Loss: 1.651 | Acc: 37.744% \n",
      "[epoch:1, iter:251] Loss: 1.649 | Acc: 37.789% \n",
      "[epoch:1, iter:252] Loss: 1.648 | Acc: 37.832% \n",
      "[epoch:1, iter:253] Loss: 1.647 | Acc: 37.852% \n",
      "[epoch:1, iter:254] Loss: 1.646 | Acc: 37.897% \n",
      "[epoch:1, iter:255] Loss: 1.644 | Acc: 37.941% \n",
      "[epoch:1, iter:256] Loss: 1.643 | Acc: 37.997% \n",
      "[epoch:1, iter:257] Loss: 1.642 | Acc: 38.047% \n",
      "[epoch:1, iter:258] Loss: 1.641 | Acc: 38.090% \n",
      "[epoch:1, iter:259] Loss: 1.640 | Acc: 38.149% \n",
      "[epoch:1, iter:260] Loss: 1.639 | Acc: 38.179% \n",
      "[epoch:1, iter:261] Loss: 1.639 | Acc: 38.179% \n",
      "[epoch:1, iter:262] Loss: 1.638 | Acc: 38.222% \n",
      "[epoch:1, iter:263] Loss: 1.636 | Acc: 38.293% \n",
      "[epoch:1, iter:264] Loss: 1.636 | Acc: 38.293% \n",
      "[epoch:1, iter:265] Loss: 1.635 | Acc: 38.343% \n",
      "[epoch:1, iter:266] Loss: 1.634 | Acc: 38.396% \n",
      "[epoch:1, iter:267] Loss: 1.633 | Acc: 38.436% \n",
      "[epoch:1, iter:268] Loss: 1.632 | Acc: 38.497% \n",
      "[epoch:1, iter:269] Loss: 1.631 | Acc: 38.543% \n",
      "[epoch:1, iter:270] Loss: 1.630 | Acc: 38.571% \n",
      "[epoch:1, iter:271] Loss: 1.629 | Acc: 38.610% \n",
      "[epoch:1, iter:272] Loss: 1.629 | Acc: 38.629% \n",
      "[epoch:1, iter:273] Loss: 1.628 | Acc: 38.676% \n",
      "[epoch:1, iter:274] Loss: 1.627 | Acc: 38.729% \n",
      "[epoch:1, iter:275] Loss: 1.625 | Acc: 38.804% \n",
      "[epoch:1, iter:276] Loss: 1.624 | Acc: 38.828% \n",
      "[epoch:1, iter:277] Loss: 1.623 | Acc: 38.874% \n",
      "[epoch:1, iter:278] Loss: 1.622 | Acc: 38.919% \n",
      "[epoch:1, iter:279] Loss: 1.622 | Acc: 38.931% \n",
      "[epoch:1, iter:280] Loss: 1.621 | Acc: 38.970% \n",
      "[epoch:1, iter:281] Loss: 1.621 | Acc: 38.971% \n",
      "[epoch:1, iter:282] Loss: 1.620 | Acc: 39.004% \n",
      "[epoch:1, iter:283] Loss: 1.619 | Acc: 39.057% \n",
      "[epoch:1, iter:284] Loss: 1.618 | Acc: 39.112% \n",
      "[epoch:1, iter:285] Loss: 1.616 | Acc: 39.139% \n",
      "[epoch:1, iter:286] Loss: 1.616 | Acc: 39.183% \n",
      "[epoch:1, iter:287] Loss: 1.615 | Acc: 39.237% \n",
      "[epoch:1, iter:288] Loss: 1.614 | Acc: 39.280% \n",
      "[epoch:1, iter:289] Loss: 1.613 | Acc: 39.314% \n",
      "[epoch:1, iter:290] Loss: 1.611 | Acc: 39.380% \n",
      "[epoch:1, iter:291] Loss: 1.611 | Acc: 39.401% \n",
      "[epoch:1, iter:292] Loss: 1.610 | Acc: 39.429% \n",
      "[epoch:1, iter:293] Loss: 1.609 | Acc: 39.468% \n",
      "[epoch:1, iter:294] Loss: 1.608 | Acc: 39.520% \n",
      "[epoch:1, iter:295] Loss: 1.607 | Acc: 39.550% \n",
      "[epoch:1, iter:296] Loss: 1.607 | Acc: 39.553% \n",
      "[epoch:1, iter:297] Loss: 1.606 | Acc: 39.591% \n",
      "[epoch:1, iter:298] Loss: 1.605 | Acc: 39.634% \n",
      "[epoch:1, iter:299] Loss: 1.604 | Acc: 39.690% \n",
      "[epoch:1, iter:300] Loss: 1.603 | Acc: 39.737% \n",
      "[epoch:1, iter:301] Loss: 1.602 | Acc: 39.779% \n",
      "[epoch:1, iter:302] Loss: 1.602 | Acc: 39.813% \n",
      "[epoch:1, iter:303] Loss: 1.601 | Acc: 39.846% \n",
      "[epoch:1, iter:304] Loss: 1.600 | Acc: 39.887% \n",
      "[epoch:1, iter:305] Loss: 1.600 | Acc: 39.908% \n",
      "[epoch:1, iter:306] Loss: 1.599 | Acc: 39.954% \n",
      "[epoch:1, iter:307] Loss: 1.598 | Acc: 39.989% \n",
      "[epoch:1, iter:308] Loss: 1.597 | Acc: 40.021% \n",
      "[epoch:1, iter:309] Loss: 1.596 | Acc: 40.074% \n",
      "[epoch:1, iter:310] Loss: 1.595 | Acc: 40.123% \n",
      "[epoch:1, iter:311] Loss: 1.594 | Acc: 40.168% \n",
      "[epoch:1, iter:312] Loss: 1.593 | Acc: 40.212% \n",
      "[epoch:1, iter:313] Loss: 1.592 | Acc: 40.241% \n",
      "[epoch:1, iter:314] Loss: 1.591 | Acc: 40.284% \n",
      "[epoch:1, iter:315] Loss: 1.590 | Acc: 40.330% \n",
      "[epoch:1, iter:316] Loss: 1.589 | Acc: 40.370% \n",
      "[epoch:1, iter:317] Loss: 1.588 | Acc: 40.403% \n",
      "[epoch:1, iter:318] Loss: 1.588 | Acc: 40.409% \n",
      "[epoch:1, iter:319] Loss: 1.588 | Acc: 40.417% \n",
      "[epoch:1, iter:320] Loss: 1.587 | Acc: 40.464% \n",
      "[epoch:1, iter:321] Loss: 1.586 | Acc: 40.494% \n",
      "[epoch:1, iter:322] Loss: 1.585 | Acc: 40.557% \n",
      "[epoch:1, iter:323] Loss: 1.585 | Acc: 40.579% \n",
      "[epoch:1, iter:324] Loss: 1.584 | Acc: 40.627% \n",
      "[epoch:1, iter:325] Loss: 1.583 | Acc: 40.663% \n",
      "[epoch:1, iter:326] Loss: 1.582 | Acc: 40.694% \n",
      "[epoch:1, iter:327] Loss: 1.581 | Acc: 40.733% \n",
      "[epoch:1, iter:328] Loss: 1.581 | Acc: 40.751% \n",
      "[epoch:1, iter:329] Loss: 1.580 | Acc: 40.777% \n",
      "[epoch:1, iter:330] Loss: 1.580 | Acc: 40.826% \n",
      "[epoch:1, iter:331] Loss: 1.579 | Acc: 40.870% \n",
      "[epoch:1, iter:332] Loss: 1.578 | Acc: 40.914% \n",
      "[epoch:1, iter:333] Loss: 1.578 | Acc: 40.942% \n",
      "[epoch:1, iter:334] Loss: 1.577 | Acc: 40.983% \n",
      "[epoch:1, iter:335] Loss: 1.576 | Acc: 41.019% \n",
      "[epoch:1, iter:336] Loss: 1.575 | Acc: 41.060% \n",
      "[epoch:1, iter:337] Loss: 1.575 | Acc: 41.089% \n",
      "[epoch:1, iter:338] Loss: 1.574 | Acc: 41.113% \n",
      "[epoch:1, iter:339] Loss: 1.574 | Acc: 41.127% \n",
      "[epoch:1, iter:340] Loss: 1.573 | Acc: 41.153% \n",
      "[epoch:1, iter:341] Loss: 1.572 | Acc: 41.202% \n",
      "[epoch:1, iter:342] Loss: 1.571 | Acc: 41.228% \n",
      "[epoch:1, iter:343] Loss: 1.570 | Acc: 41.270% \n",
      "[epoch:1, iter:344] Loss: 1.569 | Acc: 41.290% \n",
      "[epoch:1, iter:345] Loss: 1.568 | Acc: 41.332% \n",
      "[epoch:1, iter:346] Loss: 1.568 | Acc: 41.363% \n",
      "[epoch:1, iter:347] Loss: 1.567 | Acc: 41.377% \n",
      "[epoch:1, iter:348] Loss: 1.566 | Acc: 41.393% \n",
      "[epoch:1, iter:349] Loss: 1.565 | Acc: 41.422% \n",
      "[epoch:1, iter:350] Loss: 1.565 | Acc: 41.440% \n",
      "[epoch:1, iter:351] Loss: 1.564 | Acc: 41.466% \n",
      "[epoch:1, iter:352] Loss: 1.563 | Acc: 41.522% \n",
      "[epoch:1, iter:353] Loss: 1.562 | Acc: 41.546% \n",
      "[epoch:1, iter:354] Loss: 1.562 | Acc: 41.581% \n",
      "[epoch:1, iter:355] Loss: 1.561 | Acc: 41.604% \n",
      "[epoch:1, iter:356] Loss: 1.560 | Acc: 41.626% \n",
      "[epoch:1, iter:357] Loss: 1.560 | Acc: 41.647% \n",
      "[epoch:1, iter:358] Loss: 1.558 | Acc: 41.688% \n",
      "[epoch:1, iter:359] Loss: 1.558 | Acc: 41.722% \n",
      "[epoch:1, iter:360] Loss: 1.557 | Acc: 41.751% \n",
      "[epoch:1, iter:361] Loss: 1.556 | Acc: 41.781% \n",
      "[epoch:1, iter:362] Loss: 1.556 | Acc: 41.806% \n",
      "[epoch:1, iter:363] Loss: 1.555 | Acc: 41.832% \n",
      "[epoch:1, iter:364] Loss: 1.555 | Acc: 41.851% \n",
      "[epoch:1, iter:365] Loss: 1.554 | Acc: 41.884% \n",
      "[epoch:1, iter:366] Loss: 1.553 | Acc: 41.916% \n",
      "[epoch:1, iter:367] Loss: 1.552 | Acc: 41.962% \n",
      "[epoch:1, iter:368] Loss: 1.551 | Acc: 42.007% \n",
      "[epoch:1, iter:369] Loss: 1.550 | Acc: 42.065% \n",
      "[epoch:1, iter:370] Loss: 1.549 | Acc: 42.118% \n",
      "[epoch:1, iter:371] Loss: 1.548 | Acc: 42.139% \n",
      "[epoch:1, iter:372] Loss: 1.548 | Acc: 42.167% \n",
      "[epoch:1, iter:373] Loss: 1.547 | Acc: 42.200% \n",
      "[epoch:1, iter:374] Loss: 1.546 | Acc: 42.231% \n",
      "[epoch:1, iter:375] Loss: 1.545 | Acc: 42.279% \n",
      "[epoch:1, iter:376] Loss: 1.544 | Acc: 42.333% \n",
      "[epoch:1, iter:377] Loss: 1.543 | Acc: 42.355% \n",
      "[epoch:1, iter:378] Loss: 1.543 | Acc: 42.382% \n",
      "[epoch:1, iter:379] Loss: 1.542 | Acc: 42.408% \n",
      "[epoch:1, iter:380] Loss: 1.541 | Acc: 42.436% \n",
      "[epoch:1, iter:381] Loss: 1.540 | Acc: 42.487% \n",
      "[epoch:1, iter:382] Loss: 1.540 | Acc: 42.521% \n",
      "[epoch:1, iter:383] Loss: 1.538 | Acc: 42.563% \n",
      "[epoch:1, iter:384] Loss: 1.537 | Acc: 42.617% \n",
      "[epoch:1, iter:385] Loss: 1.537 | Acc: 42.648% \n",
      "[epoch:1, iter:386] Loss: 1.536 | Acc: 42.683% \n",
      "[epoch:1, iter:387] Loss: 1.535 | Acc: 42.729% \n",
      "[epoch:1, iter:388] Loss: 1.534 | Acc: 42.771% \n",
      "[epoch:1, iter:389] Loss: 1.534 | Acc: 42.790% \n",
      "[epoch:1, iter:390] Loss: 1.533 | Acc: 42.821% \n",
      "[epoch:1, iter:391] Loss: 1.532 | Acc: 42.842% \n",
      "Waiting Test!\n",
      "Test acc：54.970%\n",
      "\n",
      "Epoch: 2\n",
      "[epoch:2, iter:392] Loss: 1.160 | Acc: 53.125% \n",
      "[epoch:2, iter:393] Loss: 1.199 | Acc: 55.859% \n",
      "[epoch:2, iter:394] Loss: 1.169 | Acc: 57.552% \n",
      "[epoch:2, iter:395] Loss: 1.232 | Acc: 55.078% \n",
      "[epoch:2, iter:396] Loss: 1.255 | Acc: 54.219% \n",
      "[epoch:2, iter:397] Loss: 1.272 | Acc: 53.776% \n",
      "[epoch:2, iter:398] Loss: 1.254 | Acc: 55.134% \n",
      "[epoch:2, iter:399] Loss: 1.239 | Acc: 56.055% \n",
      "[epoch:2, iter:400] Loss: 1.238 | Acc: 56.163% \n",
      "[epoch:2, iter:401] Loss: 1.230 | Acc: 56.641% \n",
      "[epoch:2, iter:402] Loss: 1.230 | Acc: 56.534% \n",
      "[epoch:2, iter:403] Loss: 1.229 | Acc: 56.315% \n",
      "[epoch:2, iter:404] Loss: 1.229 | Acc: 56.370% \n",
      "[epoch:2, iter:405] Loss: 1.231 | Acc: 56.194% \n",
      "[epoch:2, iter:406] Loss: 1.223 | Acc: 56.510% \n",
      "[epoch:2, iter:407] Loss: 1.212 | Acc: 56.836% \n",
      "[epoch:2, iter:408] Loss: 1.209 | Acc: 56.985% \n",
      "[epoch:2, iter:409] Loss: 1.212 | Acc: 56.771% \n",
      "[epoch:2, iter:410] Loss: 1.211 | Acc: 56.785% \n",
      "[epoch:2, iter:411] Loss: 1.209 | Acc: 56.875% \n",
      "[epoch:2, iter:412] Loss: 1.213 | Acc: 56.659% \n",
      "[epoch:2, iter:413] Loss: 1.217 | Acc: 56.676% \n",
      "[epoch:2, iter:414] Loss: 1.217 | Acc: 56.590% \n",
      "[epoch:2, iter:415] Loss: 1.216 | Acc: 56.738% \n",
      "[epoch:2, iter:416] Loss: 1.214 | Acc: 56.781% \n",
      "[epoch:2, iter:417] Loss: 1.224 | Acc: 56.370% \n",
      "[epoch:2, iter:418] Loss: 1.224 | Acc: 56.481% \n",
      "[epoch:2, iter:419] Loss: 1.223 | Acc: 56.445% \n",
      "[epoch:2, iter:420] Loss: 1.221 | Acc: 56.546% \n",
      "[epoch:2, iter:421] Loss: 1.225 | Acc: 56.302% \n",
      "[epoch:2, iter:422] Loss: 1.223 | Acc: 56.376% \n",
      "[epoch:2, iter:423] Loss: 1.226 | Acc: 56.226% \n",
      "[epoch:2, iter:424] Loss: 1.221 | Acc: 56.416% \n",
      "[epoch:2, iter:425] Loss: 1.216 | Acc: 56.526% \n",
      "[epoch:2, iter:426] Loss: 1.214 | Acc: 56.562% \n",
      "[epoch:2, iter:427] Loss: 1.213 | Acc: 56.597% \n",
      "[epoch:2, iter:428] Loss: 1.216 | Acc: 56.250% \n",
      "[epoch:2, iter:429] Loss: 1.219 | Acc: 56.106% \n",
      "[epoch:2, iter:430] Loss: 1.215 | Acc: 56.130% \n",
      "[epoch:2, iter:431] Loss: 1.210 | Acc: 56.426% \n",
      "[epoch:2, iter:432] Loss: 1.207 | Acc: 56.574% \n",
      "[epoch:2, iter:433] Loss: 1.210 | Acc: 56.455% \n",
      "[epoch:2, iter:434] Loss: 1.208 | Acc: 56.523% \n",
      "[epoch:2, iter:435] Loss: 1.205 | Acc: 56.605% \n",
      "[epoch:2, iter:436] Loss: 1.203 | Acc: 56.667% \n",
      "[epoch:2, iter:437] Loss: 1.206 | Acc: 56.522% \n",
      "[epoch:2, iter:438] Loss: 1.207 | Acc: 56.533% \n",
      "[epoch:2, iter:439] Loss: 1.205 | Acc: 56.527% \n",
      "[epoch:2, iter:440] Loss: 1.203 | Acc: 56.537% \n",
      "[epoch:2, iter:441] Loss: 1.204 | Acc: 56.500% \n",
      "[epoch:2, iter:442] Loss: 1.204 | Acc: 56.327% \n",
      "[epoch:2, iter:443] Loss: 1.207 | Acc: 56.265% \n",
      "[epoch:2, iter:444] Loss: 1.206 | Acc: 56.368% \n",
      "[epoch:2, iter:445] Loss: 1.210 | Acc: 56.236% \n",
      "[epoch:2, iter:446] Loss: 1.208 | Acc: 56.222% \n",
      "[epoch:2, iter:447] Loss: 1.207 | Acc: 56.362% \n",
      "[epoch:2, iter:448] Loss: 1.203 | Acc: 56.469% \n",
      "[epoch:2, iter:449] Loss: 1.200 | Acc: 56.587% \n",
      "[epoch:2, iter:450] Loss: 1.201 | Acc: 56.581% \n",
      "[epoch:2, iter:451] Loss: 1.200 | Acc: 56.680% \n",
      "[epoch:2, iter:452] Loss: 1.198 | Acc: 56.814% \n",
      "[epoch:2, iter:453] Loss: 1.197 | Acc: 56.792% \n",
      "[epoch:2, iter:454] Loss: 1.197 | Acc: 56.796% \n",
      "[epoch:2, iter:455] Loss: 1.196 | Acc: 56.799% \n",
      "[epoch:2, iter:456] Loss: 1.194 | Acc: 56.863% \n",
      "[epoch:2, iter:457] Loss: 1.192 | Acc: 56.948% \n",
      "[epoch:2, iter:458] Loss: 1.193 | Acc: 56.973% \n",
      "[epoch:2, iter:459] Loss: 1.192 | Acc: 57.077% \n",
      "[epoch:2, iter:460] Loss: 1.188 | Acc: 57.258% \n",
      "[epoch:2, iter:461] Loss: 1.189 | Acc: 57.232% \n",
      "[epoch:2, iter:462] Loss: 1.189 | Acc: 57.229% \n",
      "[epoch:2, iter:463] Loss: 1.189 | Acc: 57.237% \n",
      "[epoch:2, iter:464] Loss: 1.189 | Acc: 57.224% \n",
      "[epoch:2, iter:465] Loss: 1.187 | Acc: 57.253% \n",
      "[epoch:2, iter:466] Loss: 1.186 | Acc: 57.312% \n",
      "[epoch:2, iter:467] Loss: 1.186 | Acc: 57.299% \n",
      "[epoch:2, iter:468] Loss: 1.184 | Acc: 57.366% \n",
      "[epoch:2, iter:469] Loss: 1.185 | Acc: 57.372% \n",
      "[epoch:2, iter:470] Loss: 1.187 | Acc: 57.278% \n",
      "[epoch:2, iter:471] Loss: 1.186 | Acc: 57.295% \n",
      "[epoch:2, iter:472] Loss: 1.186 | Acc: 57.272% \n",
      "[epoch:2, iter:473] Loss: 1.186 | Acc: 57.298% \n",
      "[epoch:2, iter:474] Loss: 1.189 | Acc: 57.248% \n",
      "[epoch:2, iter:475] Loss: 1.189 | Acc: 57.254% \n",
      "[epoch:2, iter:476] Loss: 1.187 | Acc: 57.335% \n",
      "[epoch:2, iter:477] Loss: 1.186 | Acc: 57.386% \n",
      "[epoch:2, iter:478] Loss: 1.187 | Acc: 57.355% \n",
      "[epoch:2, iter:479] Loss: 1.186 | Acc: 57.404% \n",
      "[epoch:2, iter:480] Loss: 1.186 | Acc: 57.409% \n",
      "[epoch:2, iter:481] Loss: 1.186 | Acc: 57.352% \n",
      "[epoch:2, iter:482] Loss: 1.185 | Acc: 57.375% \n",
      "[epoch:2, iter:483] Loss: 1.183 | Acc: 57.464% \n",
      "[epoch:2, iter:484] Loss: 1.182 | Acc: 57.434% \n",
      "[epoch:2, iter:485] Loss: 1.181 | Acc: 57.472% \n",
      "[epoch:2, iter:486] Loss: 1.180 | Acc: 57.467% \n",
      "[epoch:2, iter:487] Loss: 1.178 | Acc: 57.520% \n",
      "[epoch:2, iter:488] Loss: 1.179 | Acc: 57.514% \n",
      "[epoch:2, iter:489] Loss: 1.180 | Acc: 57.454% \n",
      "[epoch:2, iter:490] Loss: 1.178 | Acc: 57.481% \n",
      "[epoch:2, iter:491] Loss: 1.179 | Acc: 57.453% \n",
      "[epoch:2, iter:492] Loss: 1.179 | Acc: 57.457% \n",
      "[epoch:2, iter:493] Loss: 1.177 | Acc: 57.560% \n",
      "[epoch:2, iter:494] Loss: 1.177 | Acc: 57.585% \n",
      "[epoch:2, iter:495] Loss: 1.177 | Acc: 57.587% \n",
      "[epoch:2, iter:496] Loss: 1.178 | Acc: 57.567% \n",
      "[epoch:2, iter:497] Loss: 1.178 | Acc: 57.555% \n",
      "[epoch:2, iter:498] Loss: 1.178 | Acc: 57.520% \n",
      "[epoch:2, iter:499] Loss: 1.178 | Acc: 57.516% \n",
      "[epoch:2, iter:500] Loss: 1.179 | Acc: 57.562% \n",
      "[epoch:2, iter:501] Loss: 1.179 | Acc: 57.585% \n",
      "[epoch:2, iter:502] Loss: 1.178 | Acc: 57.559% \n",
      "[epoch:2, iter:503] Loss: 1.176 | Acc: 57.624% \n",
      "[epoch:2, iter:504] Loss: 1.173 | Acc: 57.730% \n",
      "[epoch:2, iter:505] Loss: 1.175 | Acc: 57.730% \n",
      "[epoch:2, iter:506] Loss: 1.175 | Acc: 57.683% \n",
      "[epoch:2, iter:507] Loss: 1.176 | Acc: 57.685% \n",
      "[epoch:2, iter:508] Loss: 1.174 | Acc: 57.792% \n",
      "[epoch:2, iter:509] Loss: 1.174 | Acc: 57.793% \n",
      "[epoch:2, iter:510] Loss: 1.174 | Acc: 57.786% \n",
      "[epoch:2, iter:511] Loss: 1.173 | Acc: 57.819% \n",
      "[epoch:2, iter:512] Loss: 1.173 | Acc: 57.819% \n",
      "[epoch:2, iter:513] Loss: 1.172 | Acc: 57.864% \n",
      "[epoch:2, iter:514] Loss: 1.172 | Acc: 57.851% \n",
      "[epoch:2, iter:515] Loss: 1.172 | Acc: 57.926% \n",
      "[epoch:2, iter:516] Loss: 1.172 | Acc: 57.912% \n",
      "[epoch:2, iter:517] Loss: 1.171 | Acc: 57.949% \n",
      "[epoch:2, iter:518] Loss: 1.172 | Acc: 57.917% \n",
      "[epoch:2, iter:519] Loss: 1.173 | Acc: 57.886% \n",
      "[epoch:2, iter:520] Loss: 1.172 | Acc: 57.861% \n",
      "[epoch:2, iter:521] Loss: 1.172 | Acc: 57.885% \n",
      "[epoch:2, iter:522] Loss: 1.171 | Acc: 57.908% \n",
      "[epoch:2, iter:523] Loss: 1.171 | Acc: 57.895% \n",
      "[epoch:2, iter:524] Loss: 1.170 | Acc: 57.942% \n",
      "[epoch:2, iter:525] Loss: 1.169 | Acc: 58.011% \n",
      "[epoch:2, iter:526] Loss: 1.168 | Acc: 58.061% \n",
      "[epoch:2, iter:527] Loss: 1.166 | Acc: 58.111% \n",
      "[epoch:2, iter:528] Loss: 1.166 | Acc: 58.103% \n",
      "[epoch:2, iter:529] Loss: 1.167 | Acc: 58.101% \n",
      "[epoch:2, iter:530] Loss: 1.166 | Acc: 58.110% \n",
      "[epoch:2, iter:531] Loss: 1.166 | Acc: 58.097% \n",
      "[epoch:2, iter:532] Loss: 1.166 | Acc: 58.073% \n",
      "[epoch:2, iter:533] Loss: 1.165 | Acc: 58.154% \n",
      "[epoch:2, iter:534] Loss: 1.164 | Acc: 58.162% \n",
      "[epoch:2, iter:535] Loss: 1.165 | Acc: 58.143% \n",
      "[epoch:2, iter:536] Loss: 1.164 | Acc: 58.168% \n",
      "[epoch:2, iter:537] Loss: 1.165 | Acc: 58.150% \n",
      "[epoch:2, iter:538] Loss: 1.164 | Acc: 58.216% \n",
      "[epoch:2, iter:539] Loss: 1.163 | Acc: 58.272% \n",
      "[epoch:2, iter:540] Loss: 1.162 | Acc: 58.305% \n",
      "[epoch:2, iter:541] Loss: 1.162 | Acc: 58.276% \n",
      "[epoch:2, iter:542] Loss: 1.162 | Acc: 58.237% \n",
      "[epoch:2, iter:543] Loss: 1.162 | Acc: 58.244% \n",
      "[epoch:2, iter:544] Loss: 1.161 | Acc: 58.282% \n",
      "[epoch:2, iter:545] Loss: 1.161 | Acc: 58.289% \n",
      "[epoch:2, iter:546] Loss: 1.160 | Acc: 58.306% \n",
      "[epoch:2, iter:547] Loss: 1.159 | Acc: 58.348% \n",
      "[epoch:2, iter:548] Loss: 1.159 | Acc: 58.335% \n",
      "[epoch:2, iter:549] Loss: 1.159 | Acc: 58.327% \n",
      "[epoch:2, iter:550] Loss: 1.159 | Acc: 58.309% \n",
      "[epoch:2, iter:551] Loss: 1.159 | Acc: 58.345% \n",
      "[epoch:2, iter:552] Loss: 1.158 | Acc: 58.400% \n",
      "[epoch:2, iter:553] Loss: 1.157 | Acc: 58.425% \n",
      "[epoch:2, iter:554] Loss: 1.157 | Acc: 58.440% \n",
      "[epoch:2, iter:555] Loss: 1.158 | Acc: 58.394% \n",
      "[epoch:2, iter:556] Loss: 1.157 | Acc: 58.423% \n",
      "[epoch:2, iter:557] Loss: 1.157 | Acc: 58.410% \n",
      "[epoch:2, iter:558] Loss: 1.157 | Acc: 58.374% \n",
      "[epoch:2, iter:559] Loss: 1.156 | Acc: 58.389% \n",
      "[epoch:2, iter:560] Loss: 1.156 | Acc: 58.395% \n",
      "[epoch:2, iter:561] Loss: 1.156 | Acc: 58.433% \n",
      "[epoch:2, iter:562] Loss: 1.156 | Acc: 58.429% \n",
      "[epoch:2, iter:563] Loss: 1.156 | Acc: 58.421% \n",
      "[epoch:2, iter:564] Loss: 1.157 | Acc: 58.386% \n",
      "[epoch:2, iter:565] Loss: 1.157 | Acc: 58.396% \n",
      "[epoch:2, iter:566] Loss: 1.157 | Acc: 58.402% \n",
      "[epoch:2, iter:567] Loss: 1.158 | Acc: 58.398% \n",
      "[epoch:2, iter:568] Loss: 1.156 | Acc: 58.453% \n",
      "[epoch:2, iter:569] Loss: 1.156 | Acc: 58.480% \n",
      "[epoch:2, iter:570] Loss: 1.155 | Acc: 58.511% \n",
      "[epoch:2, iter:571] Loss: 1.155 | Acc: 58.542% \n",
      "[epoch:2, iter:572] Loss: 1.155 | Acc: 58.525% \n",
      "[epoch:2, iter:573] Loss: 1.155 | Acc: 58.538% \n",
      "[epoch:2, iter:574] Loss: 1.155 | Acc: 58.547% \n",
      "[epoch:2, iter:575] Loss: 1.154 | Acc: 58.564% \n",
      "[epoch:2, iter:576] Loss: 1.154 | Acc: 58.606% \n",
      "[epoch:2, iter:577] Loss: 1.153 | Acc: 58.648% \n",
      "[epoch:2, iter:578] Loss: 1.152 | Acc: 58.648% \n",
      "[epoch:2, iter:579] Loss: 1.152 | Acc: 58.669% \n",
      "[epoch:2, iter:580] Loss: 1.153 | Acc: 58.643% \n",
      "[epoch:2, iter:581] Loss: 1.153 | Acc: 58.610% \n",
      "[epoch:2, iter:582] Loss: 1.152 | Acc: 58.643% \n",
      "[epoch:2, iter:583] Loss: 1.152 | Acc: 58.647% \n",
      "[epoch:2, iter:584] Loss: 1.152 | Acc: 58.659% \n",
      "[epoch:2, iter:585] Loss: 1.151 | Acc: 58.670% \n",
      "[epoch:2, iter:586] Loss: 1.151 | Acc: 58.702% \n",
      "[epoch:2, iter:587] Loss: 1.151 | Acc: 58.693% \n",
      "[epoch:2, iter:588] Loss: 1.151 | Acc: 58.677% \n",
      "[epoch:2, iter:589] Loss: 1.151 | Acc: 58.669% \n",
      "[epoch:2, iter:590] Loss: 1.152 | Acc: 58.637% \n",
      "[epoch:2, iter:591] Loss: 1.152 | Acc: 58.652% \n",
      "[epoch:2, iter:592] Loss: 1.151 | Acc: 58.668% \n",
      "[epoch:2, iter:593] Loss: 1.151 | Acc: 58.679% \n",
      "[epoch:2, iter:594] Loss: 1.151 | Acc: 58.659% \n",
      "[epoch:2, iter:595] Loss: 1.150 | Acc: 58.697% \n",
      "[epoch:2, iter:596] Loss: 1.150 | Acc: 58.693% \n",
      "[epoch:2, iter:597] Loss: 1.150 | Acc: 58.723% \n",
      "[epoch:2, iter:598] Loss: 1.149 | Acc: 58.748% \n",
      "[epoch:2, iter:599] Loss: 1.149 | Acc: 58.763% \n",
      "[epoch:2, iter:600] Loss: 1.149 | Acc: 58.747% \n",
      "[epoch:2, iter:601] Loss: 1.148 | Acc: 58.765% \n",
      "[epoch:2, iter:602] Loss: 1.148 | Acc: 58.760% \n",
      "[epoch:2, iter:603] Loss: 1.148 | Acc: 58.771% \n",
      "[epoch:2, iter:604] Loss: 1.148 | Acc: 58.770% \n",
      "[epoch:2, iter:605] Loss: 1.148 | Acc: 58.776% \n",
      "[epoch:2, iter:606] Loss: 1.147 | Acc: 58.772% \n",
      "[epoch:2, iter:607] Loss: 1.146 | Acc: 58.822% \n",
      "[epoch:2, iter:608] Loss: 1.145 | Acc: 58.857% \n",
      "[epoch:2, iter:609] Loss: 1.145 | Acc: 58.859% \n",
      "[epoch:2, iter:610] Loss: 1.145 | Acc: 58.836% \n",
      "[epoch:2, iter:611] Loss: 1.145 | Acc: 58.849% \n",
      "[epoch:2, iter:612] Loss: 1.145 | Acc: 58.827% \n",
      "[epoch:2, iter:613] Loss: 1.144 | Acc: 58.840% \n",
      "[epoch:2, iter:614] Loss: 1.144 | Acc: 58.839% \n",
      "[epoch:2, iter:615] Loss: 1.143 | Acc: 58.866% \n",
      "[epoch:2, iter:616] Loss: 1.143 | Acc: 58.889% \n",
      "[epoch:2, iter:617] Loss: 1.143 | Acc: 58.888% \n",
      "[epoch:2, iter:618] Loss: 1.142 | Acc: 58.914% \n",
      "[epoch:2, iter:619] Loss: 1.142 | Acc: 58.936% \n",
      "[epoch:2, iter:620] Loss: 1.140 | Acc: 58.976% \n",
      "[epoch:2, iter:621] Loss: 1.140 | Acc: 59.022% \n",
      "[epoch:2, iter:622] Loss: 1.140 | Acc: 59.027% \n",
      "[epoch:2, iter:623] Loss: 1.139 | Acc: 59.028% \n",
      "[epoch:2, iter:624] Loss: 1.139 | Acc: 59.040% \n",
      "[epoch:2, iter:625] Loss: 1.138 | Acc: 59.058% \n",
      "[epoch:2, iter:626] Loss: 1.138 | Acc: 59.096% \n",
      "[epoch:2, iter:627] Loss: 1.137 | Acc: 59.090% \n",
      "[epoch:2, iter:628] Loss: 1.138 | Acc: 59.062% \n",
      "[epoch:2, iter:629] Loss: 1.138 | Acc: 59.053% \n",
      "[epoch:2, iter:630] Loss: 1.138 | Acc: 59.064% \n",
      "[epoch:2, iter:631] Loss: 1.137 | Acc: 59.079% \n",
      "[epoch:2, iter:632] Loss: 1.137 | Acc: 59.086% \n",
      "[epoch:2, iter:633] Loss: 1.137 | Acc: 59.117% \n",
      "[epoch:2, iter:634] Loss: 1.137 | Acc: 59.102% \n",
      "[epoch:2, iter:635] Loss: 1.137 | Acc: 59.119% \n",
      "[epoch:2, iter:636] Loss: 1.136 | Acc: 59.149% \n",
      "[epoch:2, iter:637] Loss: 1.136 | Acc: 59.165% \n",
      "[epoch:2, iter:638] Loss: 1.136 | Acc: 59.169% \n",
      "[epoch:2, iter:639] Loss: 1.135 | Acc: 59.180% \n",
      "[epoch:2, iter:640] Loss: 1.135 | Acc: 59.187% \n",
      "[epoch:2, iter:641] Loss: 1.135 | Acc: 59.194% \n",
      "[epoch:2, iter:642] Loss: 1.134 | Acc: 59.226% \n",
      "[epoch:2, iter:643] Loss: 1.135 | Acc: 59.211% \n",
      "[epoch:2, iter:644] Loss: 1.135 | Acc: 59.211% \n",
      "[epoch:2, iter:645] Loss: 1.134 | Acc: 59.227% \n",
      "[epoch:2, iter:646] Loss: 1.134 | Acc: 59.213% \n",
      "[epoch:2, iter:647] Loss: 1.134 | Acc: 59.210% \n",
      "[epoch:2, iter:648] Loss: 1.133 | Acc: 59.253% \n",
      "[epoch:2, iter:649] Loss: 1.133 | Acc: 59.269% \n",
      "[epoch:2, iter:650] Loss: 1.132 | Acc: 59.294% \n",
      "[epoch:2, iter:651] Loss: 1.131 | Acc: 59.336% \n",
      "[epoch:2, iter:652] Loss: 1.131 | Acc: 59.351% \n",
      "[epoch:2, iter:653] Loss: 1.130 | Acc: 59.408% \n",
      "[epoch:2, iter:654] Loss: 1.129 | Acc: 59.428% \n",
      "[epoch:2, iter:655] Loss: 1.129 | Acc: 59.422% \n",
      "[epoch:2, iter:656] Loss: 1.129 | Acc: 59.449% \n",
      "[epoch:2, iter:657] Loss: 1.128 | Acc: 59.490% \n",
      "[epoch:2, iter:658] Loss: 1.128 | Acc: 59.480% \n",
      "[epoch:2, iter:659] Loss: 1.128 | Acc: 59.506% \n",
      "[epoch:2, iter:660] Loss: 1.127 | Acc: 59.506% \n",
      "[epoch:2, iter:661] Loss: 1.127 | Acc: 59.499% \n",
      "[epoch:2, iter:662] Loss: 1.127 | Acc: 59.502% \n",
      "[epoch:2, iter:663] Loss: 1.127 | Acc: 59.510% \n",
      "[epoch:2, iter:664] Loss: 1.127 | Acc: 59.504% \n",
      "[epoch:2, iter:665] Loss: 1.126 | Acc: 59.518% \n",
      "[epoch:2, iter:666] Loss: 1.126 | Acc: 59.548% \n",
      "[epoch:2, iter:667] Loss: 1.125 | Acc: 59.590% \n",
      "[epoch:2, iter:668] Loss: 1.125 | Acc: 59.587% \n",
      "[epoch:2, iter:669] Loss: 1.125 | Acc: 59.611% \n",
      "[epoch:2, iter:670] Loss: 1.125 | Acc: 59.641% \n",
      "[epoch:2, iter:671] Loss: 1.124 | Acc: 59.648% \n",
      "[epoch:2, iter:672] Loss: 1.123 | Acc: 59.675% \n",
      "[epoch:2, iter:673] Loss: 1.123 | Acc: 59.694% \n",
      "[epoch:2, iter:674] Loss: 1.123 | Acc: 59.657% \n",
      "[epoch:2, iter:675] Loss: 1.123 | Acc: 59.664% \n",
      "[epoch:2, iter:676] Loss: 1.123 | Acc: 59.696% \n",
      "[epoch:2, iter:677] Loss: 1.121 | Acc: 59.752% \n",
      "[epoch:2, iter:678] Loss: 1.121 | Acc: 59.759% \n",
      "[epoch:2, iter:679] Loss: 1.120 | Acc: 59.774% \n",
      "[epoch:2, iter:680] Loss: 1.120 | Acc: 59.799% \n",
      "[epoch:2, iter:681] Loss: 1.119 | Acc: 59.817% \n",
      "[epoch:2, iter:682] Loss: 1.119 | Acc: 59.807% \n",
      "[epoch:2, iter:683] Loss: 1.118 | Acc: 59.851% \n",
      "[epoch:2, iter:684] Loss: 1.118 | Acc: 59.863% \n",
      "[epoch:2, iter:685] Loss: 1.117 | Acc: 59.867% \n",
      "[epoch:2, iter:686] Loss: 1.117 | Acc: 59.870% \n",
      "[epoch:2, iter:687] Loss: 1.117 | Acc: 59.892% \n",
      "[epoch:2, iter:688] Loss: 1.116 | Acc: 59.898% \n",
      "[epoch:2, iter:689] Loss: 1.117 | Acc: 59.905% \n",
      "[epoch:2, iter:690] Loss: 1.116 | Acc: 59.937% \n",
      "[epoch:2, iter:691] Loss: 1.115 | Acc: 59.964% \n",
      "[epoch:2, iter:692] Loss: 1.115 | Acc: 59.972% \n",
      "[epoch:2, iter:693] Loss: 1.114 | Acc: 59.986% \n",
      "[epoch:2, iter:694] Loss: 1.114 | Acc: 60.004% \n",
      "[epoch:2, iter:695] Loss: 1.114 | Acc: 59.994% \n",
      "[epoch:2, iter:696] Loss: 1.114 | Acc: 60.008% \n",
      "[epoch:2, iter:697] Loss: 1.113 | Acc: 60.029% \n",
      "[epoch:2, iter:698] Loss: 1.112 | Acc: 60.057% \n",
      "[epoch:2, iter:699] Loss: 1.112 | Acc: 60.075% \n",
      "[epoch:2, iter:700] Loss: 1.111 | Acc: 60.116% \n",
      "[epoch:2, iter:701] Loss: 1.110 | Acc: 60.149% \n",
      "[epoch:2, iter:702] Loss: 1.109 | Acc: 60.184% \n",
      "[epoch:2, iter:703] Loss: 1.109 | Acc: 60.184% \n",
      "[epoch:2, iter:704] Loss: 1.109 | Acc: 60.176% \n",
      "[epoch:2, iter:705] Loss: 1.108 | Acc: 60.204% \n",
      "[epoch:2, iter:706] Loss: 1.107 | Acc: 60.231% \n",
      "[epoch:2, iter:707] Loss: 1.107 | Acc: 60.245% \n",
      "[epoch:2, iter:708] Loss: 1.107 | Acc: 60.265% \n",
      "[epoch:2, iter:709] Loss: 1.106 | Acc: 60.274% \n",
      "[epoch:2, iter:710] Loss: 1.106 | Acc: 60.284% \n",
      "[epoch:2, iter:711] Loss: 1.106 | Acc: 60.278% \n",
      "[epoch:2, iter:712] Loss: 1.106 | Acc: 60.293% \n",
      "[epoch:2, iter:713] Loss: 1.105 | Acc: 60.312% \n",
      "[epoch:2, iter:714] Loss: 1.105 | Acc: 60.326% \n",
      "[epoch:2, iter:715] Loss: 1.104 | Acc: 60.327% \n",
      "[epoch:2, iter:716] Loss: 1.103 | Acc: 60.361% \n",
      "[epoch:2, iter:717] Loss: 1.103 | Acc: 60.367% \n",
      "[epoch:2, iter:718] Loss: 1.103 | Acc: 60.381% \n",
      "[epoch:2, iter:719] Loss: 1.103 | Acc: 60.387% \n",
      "[epoch:2, iter:720] Loss: 1.102 | Acc: 60.410% \n",
      "[epoch:2, iter:721] Loss: 1.102 | Acc: 60.405% \n",
      "[epoch:2, iter:722] Loss: 1.102 | Acc: 60.390% \n",
      "[epoch:2, iter:723] Loss: 1.102 | Acc: 60.420% \n",
      "[epoch:2, iter:724] Loss: 1.101 | Acc: 60.461% \n",
      "[epoch:2, iter:725] Loss: 1.100 | Acc: 60.493% \n",
      "[epoch:2, iter:726] Loss: 1.100 | Acc: 60.525% \n",
      "[epoch:2, iter:727] Loss: 1.099 | Acc: 60.542% \n",
      "[epoch:2, iter:728] Loss: 1.099 | Acc: 60.543% \n",
      "[epoch:2, iter:729] Loss: 1.098 | Acc: 60.575% \n",
      "[epoch:2, iter:730] Loss: 1.098 | Acc: 60.576% \n",
      "[epoch:2, iter:731] Loss: 1.098 | Acc: 60.600% \n",
      "[epoch:2, iter:732] Loss: 1.097 | Acc: 60.614% \n",
      "[epoch:2, iter:733] Loss: 1.097 | Acc: 60.620% \n",
      "[epoch:2, iter:734] Loss: 1.097 | Acc: 60.651% \n",
      "[epoch:2, iter:735] Loss: 1.096 | Acc: 60.674% \n",
      "[epoch:2, iter:736] Loss: 1.095 | Acc: 60.686% \n",
      "[epoch:2, iter:737] Loss: 1.094 | Acc: 60.728% \n",
      "[epoch:2, iter:738] Loss: 1.094 | Acc: 60.751% \n",
      "[epoch:2, iter:739] Loss: 1.094 | Acc: 60.765% \n",
      "[epoch:2, iter:740] Loss: 1.093 | Acc: 60.781% \n",
      "[epoch:2, iter:741] Loss: 1.092 | Acc: 60.795% \n",
      "[epoch:2, iter:742] Loss: 1.092 | Acc: 60.815% \n",
      "[epoch:2, iter:743] Loss: 1.092 | Acc: 60.820% \n",
      "[epoch:2, iter:744] Loss: 1.092 | Acc: 60.825% \n",
      "[epoch:2, iter:745] Loss: 1.092 | Acc: 60.834% \n",
      "[epoch:2, iter:746] Loss: 1.091 | Acc: 60.856% \n",
      "[epoch:2, iter:747] Loss: 1.091 | Acc: 60.854% \n",
      "[epoch:2, iter:748] Loss: 1.091 | Acc: 60.887% \n",
      "[epoch:2, iter:749] Loss: 1.091 | Acc: 60.883% \n",
      "[epoch:2, iter:750] Loss: 1.091 | Acc: 60.887% \n",
      "[epoch:2, iter:751] Loss: 1.090 | Acc: 60.905% \n",
      "[epoch:2, iter:752] Loss: 1.090 | Acc: 60.916% \n",
      "[epoch:2, iter:753] Loss: 1.089 | Acc: 60.933% \n",
      "[epoch:2, iter:754] Loss: 1.089 | Acc: 60.940% \n",
      "[epoch:2, iter:755] Loss: 1.089 | Acc: 60.968% \n",
      "[epoch:2, iter:756] Loss: 1.088 | Acc: 60.974% \n",
      "[epoch:2, iter:757] Loss: 1.089 | Acc: 60.963% \n",
      "[epoch:2, iter:758] Loss: 1.088 | Acc: 60.978% \n",
      "[epoch:2, iter:759] Loss: 1.088 | Acc: 60.978% \n",
      "[epoch:2, iter:760] Loss: 1.088 | Acc: 60.993% \n",
      "[epoch:2, iter:761] Loss: 1.088 | Acc: 61.014% \n",
      "[epoch:2, iter:762] Loss: 1.088 | Acc: 61.013% \n",
      "[epoch:2, iter:763] Loss: 1.088 | Acc: 61.017% \n",
      "[epoch:2, iter:764] Loss: 1.087 | Acc: 61.044% \n",
      "[epoch:2, iter:765] Loss: 1.087 | Acc: 61.048% \n",
      "[epoch:2, iter:766] Loss: 1.087 | Acc: 61.056% \n",
      "[epoch:2, iter:767] Loss: 1.086 | Acc: 61.081% \n",
      "[epoch:2, iter:768] Loss: 1.086 | Acc: 61.091% \n",
      "[epoch:2, iter:769] Loss: 1.085 | Acc: 61.101% \n",
      "[epoch:2, iter:770] Loss: 1.085 | Acc: 61.123% \n",
      "[epoch:2, iter:771] Loss: 1.085 | Acc: 61.116% \n",
      "[epoch:2, iter:772] Loss: 1.085 | Acc: 61.132% \n",
      "[epoch:2, iter:773] Loss: 1.084 | Acc: 61.144% \n",
      "[epoch:2, iter:774] Loss: 1.084 | Acc: 61.172% \n",
      "[epoch:2, iter:775] Loss: 1.083 | Acc: 61.186% \n",
      "[epoch:2, iter:776] Loss: 1.083 | Acc: 61.222% \n",
      "[epoch:2, iter:777] Loss: 1.083 | Acc: 61.235% \n",
      "[epoch:2, iter:778] Loss: 1.082 | Acc: 61.256% \n",
      "[epoch:2, iter:779] Loss: 1.082 | Acc: 61.274% \n",
      "[epoch:2, iter:780] Loss: 1.081 | Acc: 61.283% \n",
      "[epoch:2, iter:781] Loss: 1.081 | Acc: 61.306% \n",
      "[epoch:2, iter:782] Loss: 1.081 | Acc: 61.302% \n",
      "Waiting Test!\n",
      "Test acc：63.950%\n",
      "\n",
      "Epoch: 3\n",
      "[epoch:3, iter:783] Loss: 0.991 | Acc: 64.062% \n",
      "[epoch:3, iter:784] Loss: 0.983 | Acc: 64.453% \n",
      "[epoch:3, iter:785] Loss: 0.963 | Acc: 64.583% \n",
      "[epoch:3, iter:786] Loss: 0.952 | Acc: 64.453% \n",
      "[epoch:3, iter:787] Loss: 0.965 | Acc: 63.750% \n",
      "[epoch:3, iter:788] Loss: 0.956 | Acc: 64.583% \n",
      "[epoch:3, iter:789] Loss: 0.955 | Acc: 64.844% \n",
      "[epoch:3, iter:790] Loss: 0.947 | Acc: 64.844% \n",
      "[epoch:3, iter:791] Loss: 0.941 | Acc: 65.104% \n",
      "[epoch:3, iter:792] Loss: 0.943 | Acc: 65.000% \n",
      "[epoch:3, iter:793] Loss: 0.941 | Acc: 65.057% \n",
      "[epoch:3, iter:794] Loss: 0.924 | Acc: 65.690% \n",
      "[epoch:3, iter:795] Loss: 0.938 | Acc: 64.844% \n",
      "[epoch:3, iter:796] Loss: 0.943 | Acc: 64.788% \n",
      "[epoch:3, iter:797] Loss: 0.942 | Acc: 64.896% \n",
      "[epoch:3, iter:798] Loss: 0.942 | Acc: 65.088% \n",
      "[epoch:3, iter:799] Loss: 0.943 | Acc: 64.936% \n",
      "[epoch:3, iter:800] Loss: 0.933 | Acc: 65.582% \n",
      "[epoch:3, iter:801] Loss: 0.927 | Acc: 65.789% \n",
      "[epoch:3, iter:802] Loss: 0.921 | Acc: 66.094% \n",
      "[epoch:3, iter:803] Loss: 0.924 | Acc: 66.109% \n",
      "[epoch:3, iter:804] Loss: 0.922 | Acc: 66.335% \n",
      "[epoch:3, iter:805] Loss: 0.931 | Acc: 66.168% \n",
      "[epoch:3, iter:806] Loss: 0.930 | Acc: 66.113% \n",
      "[epoch:3, iter:807] Loss: 0.935 | Acc: 65.969% \n",
      "[epoch:3, iter:808] Loss: 0.940 | Acc: 65.715% \n",
      "[epoch:3, iter:809] Loss: 0.943 | Acc: 65.365% \n",
      "[epoch:3, iter:810] Loss: 0.942 | Acc: 65.402% \n",
      "[epoch:3, iter:811] Loss: 0.943 | Acc: 65.436% \n",
      "[epoch:3, iter:812] Loss: 0.947 | Acc: 65.469% \n",
      "[epoch:3, iter:813] Loss: 0.941 | Acc: 65.776% \n",
      "[epoch:3, iter:814] Loss: 0.943 | Acc: 65.771% \n",
      "[epoch:3, iter:815] Loss: 0.945 | Acc: 65.696% \n",
      "[epoch:3, iter:816] Loss: 0.944 | Acc: 65.786% \n",
      "[epoch:3, iter:817] Loss: 0.942 | Acc: 65.781% \n",
      "[epoch:3, iter:818] Loss: 0.944 | Acc: 65.799% \n",
      "[epoch:3, iter:819] Loss: 0.947 | Acc: 65.667% \n",
      "[epoch:3, iter:820] Loss: 0.947 | Acc: 65.687% \n",
      "[epoch:3, iter:821] Loss: 0.951 | Acc: 65.585% \n",
      "[epoch:3, iter:822] Loss: 0.953 | Acc: 65.547% \n",
      "[epoch:3, iter:823] Loss: 0.957 | Acc: 65.244% \n",
      "[epoch:3, iter:824] Loss: 0.956 | Acc: 65.327% \n",
      "[epoch:3, iter:825] Loss: 0.957 | Acc: 65.298% \n",
      "[epoch:3, iter:826] Loss: 0.959 | Acc: 65.217% \n",
      "[epoch:3, iter:827] Loss: 0.960 | Acc: 65.226% \n",
      "[epoch:3, iter:828] Loss: 0.961 | Acc: 65.115% \n",
      "[epoch:3, iter:829] Loss: 0.955 | Acc: 65.359% \n",
      "[epoch:3, iter:830] Loss: 0.955 | Acc: 65.397% \n",
      "[epoch:3, iter:831] Loss: 0.956 | Acc: 65.338% \n",
      "[epoch:3, iter:832] Loss: 0.956 | Acc: 65.344% \n",
      "[epoch:3, iter:833] Loss: 0.956 | Acc: 65.319% \n",
      "[epoch:3, iter:834] Loss: 0.954 | Acc: 65.355% \n",
      "[epoch:3, iter:835] Loss: 0.954 | Acc: 65.360% \n",
      "[epoch:3, iter:836] Loss: 0.952 | Acc: 65.336% \n",
      "[epoch:3, iter:837] Loss: 0.951 | Acc: 65.369% \n",
      "[epoch:3, iter:838] Loss: 0.950 | Acc: 65.402% \n",
      "[epoch:3, iter:839] Loss: 0.950 | Acc: 65.419% \n",
      "[epoch:3, iter:840] Loss: 0.945 | Acc: 65.665% \n",
      "[epoch:3, iter:841] Loss: 0.943 | Acc: 65.771% \n",
      "[epoch:3, iter:842] Loss: 0.940 | Acc: 65.846% \n",
      "[epoch:3, iter:843] Loss: 0.940 | Acc: 65.856% \n",
      "[epoch:3, iter:844] Loss: 0.938 | Acc: 65.965% \n",
      "[epoch:3, iter:845] Loss: 0.937 | Acc: 66.034% \n",
      "[epoch:3, iter:846] Loss: 0.935 | Acc: 66.138% \n",
      "[epoch:3, iter:847] Loss: 0.936 | Acc: 66.106% \n",
      "[epoch:3, iter:848] Loss: 0.936 | Acc: 66.122% \n",
      "[epoch:3, iter:849] Loss: 0.935 | Acc: 66.185% \n",
      "[epoch:3, iter:850] Loss: 0.934 | Acc: 66.234% \n",
      "[epoch:3, iter:851] Loss: 0.933 | Acc: 66.350% \n",
      "[epoch:3, iter:852] Loss: 0.933 | Acc: 66.373% \n",
      "[epoch:3, iter:853] Loss: 0.931 | Acc: 66.417% \n",
      "[epoch:3, iter:854] Loss: 0.930 | Acc: 66.482% \n",
      "[epoch:3, iter:855] Loss: 0.931 | Acc: 66.449% \n",
      "[epoch:3, iter:856] Loss: 0.930 | Acc: 66.470% \n",
      "[epoch:3, iter:857] Loss: 0.934 | Acc: 66.354% \n",
      "[epoch:3, iter:858] Loss: 0.935 | Acc: 66.324% \n",
      "[epoch:3, iter:859] Loss: 0.935 | Acc: 66.315% \n",
      "[epoch:3, iter:860] Loss: 0.934 | Acc: 66.306% \n",
      "[epoch:3, iter:861] Loss: 0.935 | Acc: 66.238% \n",
      "[epoch:3, iter:862] Loss: 0.934 | Acc: 66.240% \n",
      "[epoch:3, iter:863] Loss: 0.934 | Acc: 66.291% \n",
      "[epoch:3, iter:864] Loss: 0.934 | Acc: 66.340% \n",
      "[epoch:3, iter:865] Loss: 0.936 | Acc: 66.284% \n",
      "[epoch:3, iter:866] Loss: 0.935 | Acc: 66.323% \n",
      "[epoch:3, iter:867] Loss: 0.934 | Acc: 66.342% \n",
      "[epoch:3, iter:868] Loss: 0.935 | Acc: 66.324% \n",
      "[epoch:3, iter:869] Loss: 0.935 | Acc: 66.281% \n",
      "[epoch:3, iter:870] Loss: 0.935 | Acc: 66.300% \n",
      "[epoch:3, iter:871] Loss: 0.936 | Acc: 66.266% \n",
      "[epoch:3, iter:872] Loss: 0.938 | Acc: 66.189% \n",
      "[epoch:3, iter:873] Loss: 0.936 | Acc: 66.252% \n",
      "[epoch:3, iter:874] Loss: 0.937 | Acc: 66.160% \n",
      "[epoch:3, iter:875] Loss: 0.936 | Acc: 66.255% \n",
      "[epoch:3, iter:876] Loss: 0.935 | Acc: 66.290% \n",
      "[epoch:3, iter:877] Loss: 0.935 | Acc: 66.291% \n",
      "[epoch:3, iter:878] Loss: 0.934 | Acc: 66.341% \n",
      "[epoch:3, iter:879] Loss: 0.935 | Acc: 66.350% \n",
      "[epoch:3, iter:880] Loss: 0.935 | Acc: 66.311% \n",
      "[epoch:3, iter:881] Loss: 0.935 | Acc: 66.319% \n",
      "[epoch:3, iter:882] Loss: 0.936 | Acc: 66.297% \n",
      "[epoch:3, iter:883] Loss: 0.935 | Acc: 66.306% \n",
      "[epoch:3, iter:884] Loss: 0.937 | Acc: 66.268% \n",
      "[epoch:3, iter:885] Loss: 0.936 | Acc: 66.323% \n",
      "[epoch:3, iter:886] Loss: 0.936 | Acc: 66.309% \n",
      "[epoch:3, iter:887] Loss: 0.939 | Acc: 66.310% \n",
      "[epoch:3, iter:888] Loss: 0.937 | Acc: 66.369% \n",
      "[epoch:3, iter:889] Loss: 0.937 | Acc: 66.377% \n",
      "[epoch:3, iter:890] Loss: 0.938 | Acc: 66.392% \n",
      "[epoch:3, iter:891] Loss: 0.938 | Acc: 66.442% \n",
      "[epoch:3, iter:892] Loss: 0.938 | Acc: 66.435% \n",
      "[epoch:3, iter:893] Loss: 0.936 | Acc: 66.505% \n",
      "[epoch:3, iter:894] Loss: 0.936 | Acc: 66.476% \n",
      "[epoch:3, iter:895] Loss: 0.935 | Acc: 66.524% \n",
      "[epoch:3, iter:896] Loss: 0.933 | Acc: 66.571% \n",
      "[epoch:3, iter:897] Loss: 0.934 | Acc: 66.590% \n",
      "[epoch:3, iter:898] Loss: 0.933 | Acc: 66.595% \n",
      "[epoch:3, iter:899] Loss: 0.933 | Acc: 66.620% \n",
      "[epoch:3, iter:900] Loss: 0.934 | Acc: 66.611% \n",
      "[epoch:3, iter:901] Loss: 0.933 | Acc: 66.649% \n",
      "[epoch:3, iter:902] Loss: 0.931 | Acc: 66.712% \n",
      "[epoch:3, iter:903] Loss: 0.930 | Acc: 66.690% \n",
      "[epoch:3, iter:904] Loss: 0.929 | Acc: 66.752% \n",
      "[epoch:3, iter:905] Loss: 0.928 | Acc: 66.775% \n",
      "[epoch:3, iter:906] Loss: 0.928 | Acc: 66.791% \n",
      "[epoch:3, iter:907] Loss: 0.927 | Acc: 66.844% \n",
      "[epoch:3, iter:908] Loss: 0.926 | Acc: 66.908% \n",
      "[epoch:3, iter:909] Loss: 0.926 | Acc: 66.923% \n",
      "[epoch:3, iter:910] Loss: 0.926 | Acc: 66.888% \n",
      "[epoch:3, iter:911] Loss: 0.925 | Acc: 66.921% \n",
      "[epoch:3, iter:912] Loss: 0.924 | Acc: 66.977% \n",
      "[epoch:3, iter:913] Loss: 0.924 | Acc: 66.997% \n",
      "[epoch:3, iter:914] Loss: 0.924 | Acc: 67.004% \n",
      "[epoch:3, iter:915] Loss: 0.923 | Acc: 67.035% \n",
      "[epoch:3, iter:916] Loss: 0.924 | Acc: 66.978% \n",
      "[epoch:3, iter:917] Loss: 0.924 | Acc: 66.979% \n",
      "[epoch:3, iter:918] Loss: 0.923 | Acc: 67.038% \n",
      "[epoch:3, iter:919] Loss: 0.923 | Acc: 67.028% \n",
      "[epoch:3, iter:920] Loss: 0.923 | Acc: 67.023% \n",
      "[epoch:3, iter:921] Loss: 0.923 | Acc: 67.041% \n",
      "[epoch:3, iter:922] Loss: 0.923 | Acc: 67.093% \n",
      "[epoch:3, iter:923] Loss: 0.923 | Acc: 67.104% \n",
      "[epoch:3, iter:924] Loss: 0.923 | Acc: 67.132% \n",
      "[epoch:3, iter:925] Loss: 0.923 | Acc: 67.106% \n",
      "[epoch:3, iter:926] Loss: 0.922 | Acc: 67.128% \n",
      "[epoch:3, iter:927] Loss: 0.922 | Acc: 67.112% \n",
      "[epoch:3, iter:928] Loss: 0.922 | Acc: 67.080% \n",
      "[epoch:3, iter:929] Loss: 0.922 | Acc: 67.108% \n",
      "[epoch:3, iter:930] Loss: 0.923 | Acc: 67.071% \n",
      "[epoch:3, iter:931] Loss: 0.922 | Acc: 67.072% \n",
      "[epoch:3, iter:932] Loss: 0.922 | Acc: 67.083% \n",
      "[epoch:3, iter:933] Loss: 0.922 | Acc: 67.084% \n",
      "[epoch:3, iter:934] Loss: 0.922 | Acc: 67.069% \n",
      "[epoch:3, iter:935] Loss: 0.921 | Acc: 67.090% \n",
      "[epoch:3, iter:936] Loss: 0.922 | Acc: 67.040% \n",
      "[epoch:3, iter:937] Loss: 0.921 | Acc: 67.072% \n",
      "[epoch:3, iter:938] Loss: 0.921 | Acc: 67.087% \n",
      "[epoch:3, iter:939] Loss: 0.921 | Acc: 67.098% \n",
      "[epoch:3, iter:940] Loss: 0.921 | Acc: 67.118% \n",
      "[epoch:3, iter:941] Loss: 0.920 | Acc: 67.148% \n",
      "[epoch:3, iter:942] Loss: 0.920 | Acc: 67.144% \n",
      "[epoch:3, iter:943] Loss: 0.921 | Acc: 67.100% \n",
      "[epoch:3, iter:944] Loss: 0.921 | Acc: 67.096% \n",
      "[epoch:3, iter:945] Loss: 0.920 | Acc: 67.120% \n",
      "[epoch:3, iter:946] Loss: 0.921 | Acc: 67.107% \n",
      "[epoch:3, iter:947] Loss: 0.920 | Acc: 67.140% \n",
      "[epoch:3, iter:948] Loss: 0.920 | Acc: 67.122% \n",
      "[epoch:3, iter:949] Loss: 0.921 | Acc: 67.075% \n",
      "[epoch:3, iter:950] Loss: 0.921 | Acc: 67.057% \n",
      "[epoch:3, iter:951] Loss: 0.920 | Acc: 67.127% \n",
      "[epoch:3, iter:952] Loss: 0.919 | Acc: 67.160% \n",
      "[epoch:3, iter:953] Loss: 0.919 | Acc: 67.146% \n",
      "[epoch:3, iter:954] Loss: 0.918 | Acc: 67.151% \n",
      "[epoch:3, iter:955] Loss: 0.917 | Acc: 67.178% \n",
      "[epoch:3, iter:956] Loss: 0.917 | Acc: 67.174% \n",
      "[epoch:3, iter:957] Loss: 0.918 | Acc: 67.129% \n",
      "[epoch:3, iter:958] Loss: 0.918 | Acc: 67.121% \n",
      "[epoch:3, iter:959] Loss: 0.918 | Acc: 67.121% \n",
      "[epoch:3, iter:960] Loss: 0.918 | Acc: 67.104% \n",
      "[epoch:3, iter:961] Loss: 0.918 | Acc: 67.118% \n",
      "[epoch:3, iter:962] Loss: 0.917 | Acc: 67.148% \n",
      "[epoch:3, iter:963] Loss: 0.916 | Acc: 67.196% \n",
      "[epoch:3, iter:964] Loss: 0.916 | Acc: 67.192% \n",
      "[epoch:3, iter:965] Loss: 0.917 | Acc: 67.192% \n",
      "[epoch:3, iter:966] Loss: 0.916 | Acc: 67.221% \n",
      "[epoch:3, iter:967] Loss: 0.916 | Acc: 67.230% \n",
      "[epoch:3, iter:968] Loss: 0.916 | Acc: 67.255% \n",
      "[epoch:3, iter:969] Loss: 0.916 | Acc: 67.246% \n",
      "[epoch:3, iter:970] Loss: 0.916 | Acc: 67.237% \n",
      "[epoch:3, iter:971] Loss: 0.917 | Acc: 67.221% \n",
      "[epoch:3, iter:972] Loss: 0.916 | Acc: 67.245% \n",
      "[epoch:3, iter:973] Loss: 0.916 | Acc: 67.228% \n",
      "[epoch:3, iter:974] Loss: 0.917 | Acc: 67.208% \n",
      "[epoch:3, iter:975] Loss: 0.916 | Acc: 67.216% \n",
      "[epoch:3, iter:976] Loss: 0.916 | Acc: 67.224% \n",
      "[epoch:3, iter:977] Loss: 0.916 | Acc: 67.260% \n",
      "[epoch:3, iter:978] Loss: 0.916 | Acc: 67.263% \n",
      "[epoch:3, iter:979] Loss: 0.916 | Acc: 67.267% \n",
      "[epoch:3, iter:980] Loss: 0.915 | Acc: 67.310% \n",
      "[epoch:3, iter:981] Loss: 0.915 | Acc: 67.305% \n",
      "[epoch:3, iter:982] Loss: 0.914 | Acc: 67.316% \n",
      "[epoch:3, iter:983] Loss: 0.914 | Acc: 67.339% \n",
      "[epoch:3, iter:984] Loss: 0.913 | Acc: 67.342% \n",
      "[epoch:3, iter:985] Loss: 0.913 | Acc: 67.353% \n",
      "[epoch:3, iter:986] Loss: 0.913 | Acc: 67.360% \n",
      "[epoch:3, iter:987] Loss: 0.912 | Acc: 67.386% \n",
      "[epoch:3, iter:988] Loss: 0.912 | Acc: 67.392% \n",
      "[epoch:3, iter:989] Loss: 0.912 | Acc: 67.395% \n",
      "[epoch:3, iter:990] Loss: 0.911 | Acc: 67.435% \n",
      "[epoch:3, iter:991] Loss: 0.911 | Acc: 67.438% \n",
      "[epoch:3, iter:992] Loss: 0.911 | Acc: 67.444% \n",
      "[epoch:3, iter:993] Loss: 0.910 | Acc: 67.450% \n",
      "[epoch:3, iter:994] Loss: 0.909 | Acc: 67.497% \n",
      "[epoch:3, iter:995] Loss: 0.909 | Acc: 67.536% \n",
      "[epoch:3, iter:996] Loss: 0.908 | Acc: 67.549% \n",
      "[epoch:3, iter:997] Loss: 0.908 | Acc: 67.547% \n",
      "[epoch:3, iter:998] Loss: 0.908 | Acc: 67.549% \n",
      "[epoch:3, iter:999] Loss: 0.908 | Acc: 67.566% \n",
      "[epoch:3, iter:1000] Loss: 0.907 | Acc: 67.582% \n",
      "[epoch:3, iter:1001] Loss: 0.907 | Acc: 67.569% \n",
      "[epoch:3, iter:1002] Loss: 0.907 | Acc: 67.599% \n",
      "[epoch:3, iter:1003] Loss: 0.907 | Acc: 67.608% \n",
      "[epoch:3, iter:1004] Loss: 0.906 | Acc: 67.624% \n",
      "[epoch:3, iter:1005] Loss: 0.906 | Acc: 67.615% \n",
      "[epoch:3, iter:1006] Loss: 0.906 | Acc: 67.616% \n",
      "[epoch:3, iter:1007] Loss: 0.906 | Acc: 67.611% \n",
      "[epoch:3, iter:1008] Loss: 0.906 | Acc: 67.620% \n",
      "[epoch:3, iter:1009] Loss: 0.906 | Acc: 67.621% \n",
      "[epoch:3, iter:1010] Loss: 0.905 | Acc: 67.657% \n",
      "[epoch:3, iter:1011] Loss: 0.906 | Acc: 67.651% \n",
      "[epoch:3, iter:1012] Loss: 0.906 | Acc: 67.629% \n",
      "[epoch:3, iter:1013] Loss: 0.905 | Acc: 67.641% \n",
      "[epoch:3, iter:1014] Loss: 0.905 | Acc: 67.649% \n",
      "[epoch:3, iter:1015] Loss: 0.905 | Acc: 67.654% \n",
      "[epoch:3, iter:1016] Loss: 0.906 | Acc: 67.648% \n",
      "[epoch:3, iter:1017] Loss: 0.905 | Acc: 67.660% \n",
      "[epoch:3, iter:1018] Loss: 0.905 | Acc: 67.651% \n",
      "[epoch:3, iter:1019] Loss: 0.904 | Acc: 67.675% \n",
      "[epoch:3, iter:1020] Loss: 0.904 | Acc: 67.680% \n",
      "[epoch:3, iter:1021] Loss: 0.904 | Acc: 67.675% \n",
      "[epoch:3, iter:1022] Loss: 0.904 | Acc: 67.692% \n",
      "[epoch:3, iter:1023] Loss: 0.904 | Acc: 67.703% \n",
      "[epoch:3, iter:1024] Loss: 0.904 | Acc: 67.698% \n",
      "[epoch:3, iter:1025] Loss: 0.903 | Acc: 67.734% \n",
      "[epoch:3, iter:1026] Loss: 0.902 | Acc: 67.748% \n",
      "[epoch:3, iter:1027] Loss: 0.902 | Acc: 67.723% \n",
      "[epoch:3, iter:1028] Loss: 0.902 | Acc: 67.772% \n",
      "[epoch:3, iter:1029] Loss: 0.901 | Acc: 67.782% \n",
      "[epoch:3, iter:1030] Loss: 0.901 | Acc: 67.795% \n",
      "[epoch:3, iter:1031] Loss: 0.901 | Acc: 67.777% \n",
      "[epoch:3, iter:1032] Loss: 0.901 | Acc: 67.781% \n",
      "[epoch:3, iter:1033] Loss: 0.902 | Acc: 67.757% \n",
      "[epoch:3, iter:1034] Loss: 0.902 | Acc: 67.752% \n",
      "[epoch:3, iter:1035] Loss: 0.902 | Acc: 67.750% \n",
      "[epoch:3, iter:1036] Loss: 0.902 | Acc: 67.766% \n",
      "[epoch:3, iter:1037] Loss: 0.901 | Acc: 67.794% \n",
      "[epoch:3, iter:1038] Loss: 0.901 | Acc: 67.783% \n",
      "[epoch:3, iter:1039] Loss: 0.901 | Acc: 67.777% \n",
      "[epoch:3, iter:1040] Loss: 0.901 | Acc: 67.802% \n",
      "[epoch:3, iter:1041] Loss: 0.900 | Acc: 67.815% \n",
      "[epoch:3, iter:1042] Loss: 0.901 | Acc: 67.803% \n",
      "[epoch:3, iter:1043] Loss: 0.900 | Acc: 67.816% \n",
      "[epoch:3, iter:1044] Loss: 0.900 | Acc: 67.826% \n",
      "[epoch:3, iter:1045] Loss: 0.900 | Acc: 67.829% \n",
      "[epoch:3, iter:1046] Loss: 0.900 | Acc: 67.812% \n",
      "[epoch:3, iter:1047] Loss: 0.900 | Acc: 67.804% \n",
      "[epoch:3, iter:1048] Loss: 0.900 | Acc: 67.804% \n",
      "[epoch:3, iter:1049] Loss: 0.900 | Acc: 67.793% \n",
      "[epoch:3, iter:1050] Loss: 0.900 | Acc: 67.808% \n",
      "[epoch:3, iter:1051] Loss: 0.899 | Acc: 67.838% \n",
      "[epoch:3, iter:1052] Loss: 0.899 | Acc: 67.841% \n",
      "[epoch:3, iter:1053] Loss: 0.899 | Acc: 67.845% \n",
      "[epoch:3, iter:1054] Loss: 0.899 | Acc: 67.857% \n",
      "[epoch:3, iter:1055] Loss: 0.898 | Acc: 67.874% \n",
      "[epoch:3, iter:1056] Loss: 0.898 | Acc: 67.880% \n",
      "[epoch:3, iter:1057] Loss: 0.897 | Acc: 67.901% \n",
      "[epoch:3, iter:1058] Loss: 0.897 | Acc: 67.901% \n",
      "[epoch:3, iter:1059] Loss: 0.897 | Acc: 67.898% \n",
      "[epoch:3, iter:1060] Loss: 0.896 | Acc: 67.904% \n",
      "[epoch:3, iter:1061] Loss: 0.896 | Acc: 67.916% \n",
      "[epoch:3, iter:1062] Loss: 0.895 | Acc: 67.949% \n",
      "[epoch:3, iter:1063] Loss: 0.895 | Acc: 67.949% \n",
      "[epoch:3, iter:1064] Loss: 0.895 | Acc: 67.963% \n",
      "[epoch:3, iter:1065] Loss: 0.895 | Acc: 67.972% \n",
      "[epoch:3, iter:1066] Loss: 0.895 | Acc: 67.972% \n",
      "[epoch:3, iter:1067] Loss: 0.895 | Acc: 67.971% \n",
      "[epoch:3, iter:1068] Loss: 0.896 | Acc: 67.969% \n",
      "[epoch:3, iter:1069] Loss: 0.895 | Acc: 67.993% \n",
      "[epoch:3, iter:1070] Loss: 0.895 | Acc: 68.015% \n",
      "[epoch:3, iter:1071] Loss: 0.895 | Acc: 68.017% \n",
      "[epoch:3, iter:1072] Loss: 0.895 | Acc: 68.006% \n",
      "[epoch:3, iter:1073] Loss: 0.895 | Acc: 67.998% \n",
      "[epoch:3, iter:1074] Loss: 0.895 | Acc: 68.009% \n",
      "[epoch:3, iter:1075] Loss: 0.895 | Acc: 67.998% \n",
      "[epoch:3, iter:1076] Loss: 0.895 | Acc: 68.001% \n",
      "[epoch:3, iter:1077] Loss: 0.894 | Acc: 68.001% \n",
      "[epoch:3, iter:1078] Loss: 0.894 | Acc: 68.008% \n",
      "[epoch:3, iter:1079] Loss: 0.894 | Acc: 68.016% \n",
      "[epoch:3, iter:1080] Loss: 0.894 | Acc: 68.032% \n",
      "[epoch:3, iter:1081] Loss: 0.894 | Acc: 68.050% \n",
      "[epoch:3, iter:1082] Loss: 0.893 | Acc: 68.055% \n",
      "[epoch:3, iter:1083] Loss: 0.893 | Acc: 68.047% \n",
      "[epoch:3, iter:1084] Loss: 0.893 | Acc: 68.064% \n",
      "[epoch:3, iter:1085] Loss: 0.892 | Acc: 68.103% \n",
      "[epoch:3, iter:1086] Loss: 0.892 | Acc: 68.110% \n",
      "[epoch:3, iter:1087] Loss: 0.891 | Acc: 68.107% \n",
      "[epoch:3, iter:1088] Loss: 0.891 | Acc: 68.109% \n",
      "[epoch:3, iter:1089] Loss: 0.891 | Acc: 68.109% \n",
      "[epoch:3, iter:1090] Loss: 0.891 | Acc: 68.113% \n",
      "[epoch:3, iter:1091] Loss: 0.891 | Acc: 68.110% \n",
      "[epoch:3, iter:1092] Loss: 0.891 | Acc: 68.115% \n",
      "[epoch:3, iter:1093] Loss: 0.891 | Acc: 68.114% \n",
      "[epoch:3, iter:1094] Loss: 0.891 | Acc: 68.114% \n",
      "[epoch:3, iter:1095] Loss: 0.891 | Acc: 68.106% \n",
      "[epoch:3, iter:1096] Loss: 0.890 | Acc: 68.118% \n",
      "[epoch:3, iter:1097] Loss: 0.890 | Acc: 68.120% \n",
      "[epoch:3, iter:1098] Loss: 0.890 | Acc: 68.115% \n",
      "[epoch:3, iter:1099] Loss: 0.890 | Acc: 68.117% \n",
      "[epoch:3, iter:1100] Loss: 0.889 | Acc: 68.141% \n",
      "[epoch:3, iter:1101] Loss: 0.889 | Acc: 68.157% \n",
      "[epoch:3, iter:1102] Loss: 0.889 | Acc: 68.147% \n",
      "[epoch:3, iter:1103] Loss: 0.888 | Acc: 68.166% \n",
      "[epoch:3, iter:1104] Loss: 0.889 | Acc: 68.158% \n",
      "[epoch:3, iter:1105] Loss: 0.889 | Acc: 68.155% \n",
      "[epoch:3, iter:1106] Loss: 0.888 | Acc: 68.159% \n",
      "[epoch:3, iter:1107] Loss: 0.888 | Acc: 68.192% \n",
      "[epoch:3, iter:1108] Loss: 0.887 | Acc: 68.208% \n",
      "[epoch:3, iter:1109] Loss: 0.887 | Acc: 68.205% \n",
      "[epoch:3, iter:1110] Loss: 0.887 | Acc: 68.224% \n",
      "[epoch:3, iter:1111] Loss: 0.886 | Acc: 68.244% \n",
      "[epoch:3, iter:1112] Loss: 0.886 | Acc: 68.253% \n",
      "[epoch:3, iter:1113] Loss: 0.886 | Acc: 68.269% \n",
      "[epoch:3, iter:1114] Loss: 0.886 | Acc: 68.286% \n",
      "[epoch:3, iter:1115] Loss: 0.885 | Acc: 68.297% \n",
      "[epoch:3, iter:1116] Loss: 0.885 | Acc: 68.303% \n",
      "[epoch:3, iter:1117] Loss: 0.884 | Acc: 68.342% \n",
      "[epoch:3, iter:1118] Loss: 0.884 | Acc: 68.343% \n",
      "[epoch:3, iter:1119] Loss: 0.884 | Acc: 68.372% \n",
      "[epoch:3, iter:1120] Loss: 0.884 | Acc: 68.389% \n",
      "[epoch:3, iter:1121] Loss: 0.883 | Acc: 68.409% \n",
      "[epoch:3, iter:1122] Loss: 0.883 | Acc: 68.419% \n",
      "[epoch:3, iter:1123] Loss: 0.882 | Acc: 68.441% \n",
      "[epoch:3, iter:1124] Loss: 0.882 | Acc: 68.444% \n",
      "[epoch:3, iter:1125] Loss: 0.882 | Acc: 68.438% \n",
      "[epoch:3, iter:1126] Loss: 0.882 | Acc: 68.437% \n",
      "[epoch:3, iter:1127] Loss: 0.881 | Acc: 68.444% \n",
      "[epoch:3, iter:1128] Loss: 0.881 | Acc: 68.443% \n",
      "[epoch:3, iter:1129] Loss: 0.881 | Acc: 68.478% \n",
      "[epoch:3, iter:1130] Loss: 0.880 | Acc: 68.492% \n",
      "[epoch:3, iter:1131] Loss: 0.880 | Acc: 68.517% \n",
      "[epoch:3, iter:1132] Loss: 0.880 | Acc: 68.525% \n",
      "[epoch:3, iter:1133] Loss: 0.880 | Acc: 68.525% \n",
      "[epoch:3, iter:1134] Loss: 0.879 | Acc: 68.524% \n",
      "[epoch:3, iter:1135] Loss: 0.879 | Acc: 68.546% \n",
      "[epoch:3, iter:1136] Loss: 0.879 | Acc: 68.543% \n",
      "[epoch:3, iter:1137] Loss: 0.879 | Acc: 68.534% \n",
      "[epoch:3, iter:1138] Loss: 0.879 | Acc: 68.533% \n",
      "[epoch:3, iter:1139] Loss: 0.879 | Acc: 68.546% \n",
      "[epoch:3, iter:1140] Loss: 0.879 | Acc: 68.560% \n",
      "[epoch:3, iter:1141] Loss: 0.878 | Acc: 68.569% \n",
      "[epoch:3, iter:1142] Loss: 0.878 | Acc: 68.576% \n",
      "[epoch:3, iter:1143] Loss: 0.878 | Acc: 68.586% \n",
      "[epoch:3, iter:1144] Loss: 0.877 | Acc: 68.597% \n",
      "[epoch:3, iter:1145] Loss: 0.877 | Acc: 68.617% \n",
      "[epoch:3, iter:1146] Loss: 0.877 | Acc: 68.623% \n",
      "[epoch:3, iter:1147] Loss: 0.877 | Acc: 68.639% \n",
      "[epoch:3, iter:1148] Loss: 0.877 | Acc: 68.637% \n",
      "[epoch:3, iter:1149] Loss: 0.877 | Acc: 68.652% \n",
      "[epoch:3, iter:1150] Loss: 0.876 | Acc: 68.671% \n",
      "[epoch:3, iter:1151] Loss: 0.876 | Acc: 68.676% \n",
      "[epoch:3, iter:1152] Loss: 0.876 | Acc: 68.676% \n",
      "[epoch:3, iter:1153] Loss: 0.876 | Acc: 68.683% \n",
      "[epoch:3, iter:1154] Loss: 0.876 | Acc: 68.693% \n",
      "[epoch:3, iter:1155] Loss: 0.875 | Acc: 68.702% \n",
      "[epoch:3, iter:1156] Loss: 0.875 | Acc: 68.698% \n",
      "[epoch:3, iter:1157] Loss: 0.875 | Acc: 68.713% \n",
      "[epoch:3, iter:1158] Loss: 0.875 | Acc: 68.725% \n",
      "[epoch:3, iter:1159] Loss: 0.875 | Acc: 68.733% \n",
      "[epoch:3, iter:1160] Loss: 0.874 | Acc: 68.760% \n",
      "[epoch:3, iter:1161] Loss: 0.874 | Acc: 68.769% \n",
      "[epoch:3, iter:1162] Loss: 0.874 | Acc: 68.777% \n",
      "[epoch:3, iter:1163] Loss: 0.874 | Acc: 68.785% \n",
      "[epoch:3, iter:1164] Loss: 0.875 | Acc: 68.764% \n",
      "[epoch:3, iter:1165] Loss: 0.874 | Acc: 68.768% \n",
      "[epoch:3, iter:1166] Loss: 0.874 | Acc: 68.770% \n",
      "[epoch:3, iter:1167] Loss: 0.874 | Acc: 68.772% \n",
      "[epoch:3, iter:1168] Loss: 0.874 | Acc: 68.766% \n",
      "[epoch:3, iter:1169] Loss: 0.874 | Acc: 68.766% \n",
      "[epoch:3, iter:1170] Loss: 0.874 | Acc: 68.786% \n",
      "[epoch:3, iter:1171] Loss: 0.874 | Acc: 68.788% \n",
      "[epoch:3, iter:1172] Loss: 0.874 | Acc: 68.788% \n",
      "[epoch:3, iter:1173] Loss: 0.874 | Acc: 68.784% \n",
      "Waiting Test!\n",
      "Test acc：71.600%\n",
      "\n",
      "Epoch: 4\n",
      "[epoch:4, iter:1174] Loss: 0.750 | Acc: 72.656% \n",
      "[epoch:4, iter:1175] Loss: 0.807 | Acc: 71.094% \n",
      "[epoch:4, iter:1176] Loss: 0.826 | Acc: 69.010% \n",
      "[epoch:4, iter:1177] Loss: 0.872 | Acc: 67.969% \n",
      "[epoch:4, iter:1178] Loss: 0.885 | Acc: 67.656% \n",
      "[epoch:4, iter:1179] Loss: 0.866 | Acc: 68.359% \n",
      "[epoch:4, iter:1180] Loss: 0.866 | Acc: 68.527% \n",
      "[epoch:4, iter:1181] Loss: 0.839 | Acc: 69.824% \n",
      "[epoch:4, iter:1182] Loss: 0.840 | Acc: 69.358% \n",
      "[epoch:4, iter:1183] Loss: 0.856 | Acc: 68.672% \n",
      "[epoch:4, iter:1184] Loss: 0.848 | Acc: 68.963% \n",
      "[epoch:4, iter:1185] Loss: 0.843 | Acc: 69.336% \n",
      "[epoch:4, iter:1186] Loss: 0.835 | Acc: 69.712% \n",
      "[epoch:4, iter:1187] Loss: 0.837 | Acc: 69.810% \n",
      "[epoch:4, iter:1188] Loss: 0.838 | Acc: 69.583% \n",
      "[epoch:4, iter:1189] Loss: 0.829 | Acc: 70.068% \n",
      "[epoch:4, iter:1190] Loss: 0.820 | Acc: 70.542% \n",
      "[epoch:4, iter:1191] Loss: 0.823 | Acc: 70.530% \n",
      "[epoch:4, iter:1192] Loss: 0.829 | Acc: 70.148% \n",
      "[epoch:4, iter:1193] Loss: 0.828 | Acc: 70.156% \n",
      "[epoch:4, iter:1194] Loss: 0.824 | Acc: 70.238% \n",
      "[epoch:4, iter:1195] Loss: 0.823 | Acc: 70.419% \n",
      "[epoch:4, iter:1196] Loss: 0.815 | Acc: 70.788% \n",
      "[epoch:4, iter:1197] Loss: 0.822 | Acc: 70.540% \n",
      "[epoch:4, iter:1198] Loss: 0.824 | Acc: 70.562% \n",
      "[epoch:4, iter:1199] Loss: 0.819 | Acc: 70.823% \n",
      "[epoch:4, iter:1200] Loss: 0.815 | Acc: 71.065% \n",
      "[epoch:4, iter:1201] Loss: 0.813 | Acc: 71.094% \n",
      "[epoch:4, iter:1202] Loss: 0.811 | Acc: 71.121% \n",
      "[epoch:4, iter:1203] Loss: 0.813 | Acc: 71.094% \n",
      "[epoch:4, iter:1204] Loss: 0.808 | Acc: 71.220% \n",
      "[epoch:4, iter:1205] Loss: 0.808 | Acc: 71.143% \n",
      "[epoch:4, iter:1206] Loss: 0.811 | Acc: 71.070% \n",
      "[epoch:4, iter:1207] Loss: 0.810 | Acc: 71.117% \n",
      "[epoch:4, iter:1208] Loss: 0.805 | Acc: 71.339% \n",
      "[epoch:4, iter:1209] Loss: 0.807 | Acc: 71.311% \n",
      "[epoch:4, iter:1210] Loss: 0.805 | Acc: 71.474% \n",
      "[epoch:4, iter:1211] Loss: 0.807 | Acc: 71.361% \n",
      "[epoch:4, iter:1212] Loss: 0.810 | Acc: 71.234% \n",
      "[epoch:4, iter:1213] Loss: 0.812 | Acc: 71.172% \n",
      "[epoch:4, iter:1214] Loss: 0.815 | Acc: 71.132% \n",
      "[epoch:4, iter:1215] Loss: 0.812 | Acc: 71.224% \n",
      "[epoch:4, iter:1216] Loss: 0.811 | Acc: 71.221% \n",
      "[epoch:4, iter:1217] Loss: 0.808 | Acc: 71.307% \n",
      "[epoch:4, iter:1218] Loss: 0.805 | Acc: 71.458% \n",
      "[epoch:4, iter:1219] Loss: 0.803 | Acc: 71.552% \n",
      "[epoch:4, iter:1220] Loss: 0.801 | Acc: 71.642% \n",
      "[epoch:4, iter:1221] Loss: 0.805 | Acc: 71.533% \n",
      "[epoch:4, iter:1222] Loss: 0.807 | Acc: 71.492% \n",
      "[epoch:4, iter:1223] Loss: 0.806 | Acc: 71.484% \n",
      "[epoch:4, iter:1224] Loss: 0.804 | Acc: 71.477% \n",
      "[epoch:4, iter:1225] Loss: 0.802 | Acc: 71.575% \n",
      "[epoch:4, iter:1226] Loss: 0.799 | Acc: 71.728% \n",
      "[epoch:4, iter:1227] Loss: 0.800 | Acc: 71.672% \n",
      "[epoch:4, iter:1228] Loss: 0.799 | Acc: 71.733% \n",
      "[epoch:4, iter:1229] Loss: 0.798 | Acc: 71.819% \n",
      "[epoch:4, iter:1230] Loss: 0.799 | Acc: 71.779% \n",
      "[epoch:4, iter:1231] Loss: 0.801 | Acc: 71.659% \n",
      "[epoch:4, iter:1232] Loss: 0.803 | Acc: 71.544% \n",
      "[epoch:4, iter:1233] Loss: 0.802 | Acc: 71.589% \n",
      "[epoch:4, iter:1234] Loss: 0.802 | Acc: 71.644% \n",
      "[epoch:4, iter:1235] Loss: 0.801 | Acc: 71.648% \n",
      "[epoch:4, iter:1236] Loss: 0.800 | Acc: 71.664% \n",
      "[epoch:4, iter:1237] Loss: 0.798 | Acc: 71.753% \n",
      "[epoch:4, iter:1238] Loss: 0.802 | Acc: 71.659% \n",
      "[epoch:4, iter:1239] Loss: 0.800 | Acc: 71.768% \n",
      "[epoch:4, iter:1240] Loss: 0.800 | Acc: 71.758% \n",
      "[epoch:4, iter:1241] Loss: 0.799 | Acc: 71.760% \n",
      "[epoch:4, iter:1242] Loss: 0.799 | Acc: 71.716% \n",
      "[epoch:4, iter:1243] Loss: 0.800 | Acc: 71.696% \n",
      "[epoch:4, iter:1244] Loss: 0.799 | Acc: 71.710% \n",
      "[epoch:4, iter:1245] Loss: 0.799 | Acc: 71.734% \n",
      "[epoch:4, iter:1246] Loss: 0.796 | Acc: 71.854% \n",
      "[epoch:4, iter:1247] Loss: 0.794 | Acc: 71.991% \n",
      "[epoch:4, iter:1248] Loss: 0.796 | Acc: 71.854% \n",
      "[epoch:4, iter:1249] Loss: 0.796 | Acc: 71.834% \n",
      "[epoch:4, iter:1250] Loss: 0.795 | Acc: 71.875% \n",
      "[epoch:4, iter:1251] Loss: 0.798 | Acc: 71.845% \n",
      "[epoch:4, iter:1252] Loss: 0.798 | Acc: 71.756% \n",
      "[epoch:4, iter:1253] Loss: 0.798 | Acc: 71.748% \n",
      "[epoch:4, iter:1254] Loss: 0.799 | Acc: 71.779% \n",
      "[epoch:4, iter:1255] Loss: 0.799 | Acc: 71.761% \n",
      "[epoch:4, iter:1256] Loss: 0.800 | Acc: 71.734% \n",
      "[epoch:4, iter:1257] Loss: 0.799 | Acc: 71.745% \n",
      "[epoch:4, iter:1258] Loss: 0.797 | Acc: 71.820% \n",
      "[epoch:4, iter:1259] Loss: 0.797 | Acc: 71.793% \n",
      "[epoch:4, iter:1260] Loss: 0.796 | Acc: 71.821% \n",
      "[epoch:4, iter:1261] Loss: 0.796 | Acc: 71.875% \n",
      "[epoch:4, iter:1262] Loss: 0.796 | Acc: 71.875% \n",
      "[epoch:4, iter:1263] Loss: 0.795 | Acc: 71.892% \n",
      "[epoch:4, iter:1264] Loss: 0.795 | Acc: 71.927% \n",
      "[epoch:4, iter:1265] Loss: 0.794 | Acc: 71.909% \n",
      "[epoch:4, iter:1266] Loss: 0.793 | Acc: 71.917% \n",
      "[epoch:4, iter:1267] Loss: 0.792 | Acc: 71.950% \n",
      "[epoch:4, iter:1268] Loss: 0.791 | Acc: 71.957% \n",
      "[epoch:4, iter:1269] Loss: 0.792 | Acc: 71.940% \n",
      "[epoch:4, iter:1270] Loss: 0.790 | Acc: 71.988% \n",
      "[epoch:4, iter:1271] Loss: 0.790 | Acc: 71.987% \n",
      "[epoch:4, iter:1272] Loss: 0.788 | Acc: 72.064% \n",
      "[epoch:4, iter:1273] Loss: 0.789 | Acc: 72.047% \n",
      "[epoch:4, iter:1274] Loss: 0.790 | Acc: 72.030% \n",
      "[epoch:4, iter:1275] Loss: 0.789 | Acc: 72.044% \n",
      "[epoch:4, iter:1276] Loss: 0.789 | Acc: 72.057% \n",
      "[epoch:4, iter:1277] Loss: 0.789 | Acc: 72.108% \n",
      "[epoch:4, iter:1278] Loss: 0.789 | Acc: 72.106% \n",
      "[epoch:4, iter:1279] Loss: 0.790 | Acc: 72.059% \n",
      "[epoch:4, iter:1280] Loss: 0.789 | Acc: 72.072% \n",
      "[epoch:4, iter:1281] Loss: 0.789 | Acc: 72.078% \n",
      "[epoch:4, iter:1282] Loss: 0.789 | Acc: 72.083% \n",
      "[epoch:4, iter:1283] Loss: 0.790 | Acc: 72.053% \n",
      "[epoch:4, iter:1284] Loss: 0.790 | Acc: 72.030% \n",
      "[epoch:4, iter:1285] Loss: 0.790 | Acc: 72.008% \n",
      "[epoch:4, iter:1286] Loss: 0.791 | Acc: 71.993% \n",
      "[epoch:4, iter:1287] Loss: 0.789 | Acc: 72.060% \n",
      "[epoch:4, iter:1288] Loss: 0.788 | Acc: 72.079% \n",
      "[epoch:4, iter:1289] Loss: 0.788 | Acc: 72.131% \n",
      "[epoch:4, iter:1290] Loss: 0.788 | Acc: 72.109% \n",
      "[epoch:4, iter:1291] Loss: 0.787 | Acc: 72.133% \n",
      "[epoch:4, iter:1292] Loss: 0.786 | Acc: 72.138% \n",
      "[epoch:4, iter:1293] Loss: 0.786 | Acc: 72.161% \n",
      "[epoch:4, iter:1294] Loss: 0.785 | Acc: 72.140% \n",
      "[epoch:4, iter:1295] Loss: 0.788 | Acc: 72.074% \n",
      "[epoch:4, iter:1296] Loss: 0.787 | Acc: 72.123% \n",
      "[epoch:4, iter:1297] Loss: 0.786 | Acc: 72.133% \n",
      "[epoch:4, iter:1298] Loss: 0.787 | Acc: 72.094% \n",
      "[epoch:4, iter:1299] Loss: 0.787 | Acc: 72.049% \n",
      "[epoch:4, iter:1300] Loss: 0.787 | Acc: 72.078% \n",
      "[epoch:4, iter:1301] Loss: 0.786 | Acc: 72.083% \n",
      "[epoch:4, iter:1302] Loss: 0.788 | Acc: 72.045% \n",
      "[epoch:4, iter:1303] Loss: 0.788 | Acc: 72.019% \n",
      "[epoch:4, iter:1304] Loss: 0.789 | Acc: 71.988% \n",
      "[epoch:4, iter:1305] Loss: 0.790 | Acc: 71.970% \n",
      "[epoch:4, iter:1306] Loss: 0.790 | Acc: 71.963% \n",
      "[epoch:4, iter:1307] Loss: 0.790 | Acc: 71.968% \n",
      "[epoch:4, iter:1308] Loss: 0.789 | Acc: 72.031% \n",
      "[epoch:4, iter:1309] Loss: 0.789 | Acc: 72.053% \n",
      "[epoch:4, iter:1310] Loss: 0.789 | Acc: 72.006% \n",
      "[epoch:4, iter:1311] Loss: 0.789 | Acc: 71.988% \n",
      "[epoch:4, iter:1312] Loss: 0.789 | Acc: 72.049% \n",
      "[epoch:4, iter:1313] Loss: 0.789 | Acc: 72.054% \n",
      "[epoch:4, iter:1314] Loss: 0.790 | Acc: 72.025% \n",
      "[epoch:4, iter:1315] Loss: 0.790 | Acc: 72.040% \n",
      "[epoch:4, iter:1316] Loss: 0.791 | Acc: 71.962% \n",
      "[epoch:4, iter:1317] Loss: 0.791 | Acc: 71.967% \n",
      "[epoch:4, iter:1318] Loss: 0.791 | Acc: 71.983% \n",
      "[epoch:4, iter:1319] Loss: 0.791 | Acc: 72.003% \n",
      "[epoch:4, iter:1320] Loss: 0.790 | Acc: 72.013% \n",
      "[epoch:4, iter:1321] Loss: 0.790 | Acc: 71.996% \n",
      "[epoch:4, iter:1322] Loss: 0.790 | Acc: 71.985% \n",
      "[epoch:4, iter:1323] Loss: 0.790 | Acc: 71.990% \n",
      "[epoch:4, iter:1324] Loss: 0.789 | Acc: 72.051% \n",
      "[epoch:4, iter:1325] Loss: 0.790 | Acc: 72.009% \n",
      "[epoch:4, iter:1326] Loss: 0.790 | Acc: 72.044% \n",
      "[epoch:4, iter:1327] Loss: 0.789 | Acc: 72.012% \n",
      "[epoch:4, iter:1328] Loss: 0.789 | Acc: 72.031% \n",
      "[epoch:4, iter:1329] Loss: 0.790 | Acc: 71.995% \n",
      "[epoch:4, iter:1330] Loss: 0.790 | Acc: 72.004% \n",
      "[epoch:4, iter:1331] Loss: 0.790 | Acc: 71.999% \n",
      "[epoch:4, iter:1332] Loss: 0.790 | Acc: 72.032% \n",
      "[epoch:4, iter:1333] Loss: 0.790 | Acc: 72.036% \n",
      "[epoch:4, iter:1334] Loss: 0.791 | Acc: 72.025% \n",
      "[epoch:4, iter:1335] Loss: 0.790 | Acc: 72.034% \n",
      "[epoch:4, iter:1336] Loss: 0.790 | Acc: 72.043% \n",
      "[epoch:4, iter:1337] Loss: 0.789 | Acc: 72.113% \n",
      "[epoch:4, iter:1338] Loss: 0.789 | Acc: 72.112% \n",
      "[epoch:4, iter:1339] Loss: 0.789 | Acc: 72.139% \n",
      "[epoch:4, iter:1340] Loss: 0.789 | Acc: 72.165% \n",
      "[epoch:4, iter:1341] Loss: 0.789 | Acc: 72.182% \n",
      "[epoch:4, iter:1342] Loss: 0.789 | Acc: 72.175% \n",
      "[epoch:4, iter:1343] Loss: 0.788 | Acc: 72.206% \n",
      "[epoch:4, iter:1344] Loss: 0.788 | Acc: 72.209% \n",
      "[epoch:4, iter:1345] Loss: 0.788 | Acc: 72.207% \n",
      "[epoch:4, iter:1346] Loss: 0.787 | Acc: 72.277% \n",
      "[epoch:4, iter:1347] Loss: 0.787 | Acc: 72.212% \n",
      "[epoch:4, iter:1348] Loss: 0.787 | Acc: 72.241% \n",
      "[epoch:4, iter:1349] Loss: 0.786 | Acc: 72.266% \n",
      "[epoch:4, iter:1350] Loss: 0.785 | Acc: 72.255% \n",
      "[epoch:4, iter:1351] Loss: 0.785 | Acc: 72.301% \n",
      "[epoch:4, iter:1352] Loss: 0.785 | Acc: 72.294% \n",
      "[epoch:4, iter:1353] Loss: 0.785 | Acc: 72.318% \n",
      "[epoch:4, iter:1354] Loss: 0.786 | Acc: 72.281% \n",
      "[epoch:4, iter:1355] Loss: 0.787 | Acc: 72.283% \n",
      "[epoch:4, iter:1356] Loss: 0.786 | Acc: 72.315% \n",
      "[epoch:4, iter:1357] Loss: 0.785 | Acc: 72.342% \n",
      "[epoch:4, iter:1358] Loss: 0.785 | Acc: 72.356% \n",
      "[epoch:4, iter:1359] Loss: 0.785 | Acc: 72.375% \n",
      "[epoch:4, iter:1360] Loss: 0.785 | Acc: 72.355% \n",
      "[epoch:4, iter:1361] Loss: 0.785 | Acc: 72.361% \n",
      "[epoch:4, iter:1362] Loss: 0.785 | Acc: 72.375% \n",
      "[epoch:4, iter:1363] Loss: 0.784 | Acc: 72.410% \n",
      "[epoch:4, iter:1364] Loss: 0.785 | Acc: 72.390% \n",
      "[epoch:4, iter:1365] Loss: 0.784 | Acc: 72.404% \n",
      "[epoch:4, iter:1366] Loss: 0.784 | Acc: 72.446% \n",
      "[epoch:4, iter:1367] Loss: 0.783 | Acc: 72.451% \n",
      "[epoch:4, iter:1368] Loss: 0.783 | Acc: 72.476% \n",
      "[epoch:4, iter:1369] Loss: 0.783 | Acc: 72.481% \n",
      "[epoch:4, iter:1370] Loss: 0.783 | Acc: 72.482% \n",
      "[epoch:4, iter:1371] Loss: 0.783 | Acc: 72.487% \n",
      "[epoch:4, iter:1372] Loss: 0.782 | Acc: 72.511% \n",
      "[epoch:4, iter:1373] Loss: 0.782 | Acc: 72.504% \n",
      "[epoch:4, iter:1374] Loss: 0.782 | Acc: 72.493% \n",
      "[epoch:4, iter:1375] Loss: 0.781 | Acc: 72.517% \n",
      "[epoch:4, iter:1376] Loss: 0.782 | Acc: 72.525% \n",
      "[epoch:4, iter:1377] Loss: 0.782 | Acc: 72.515% \n",
      "[epoch:4, iter:1378] Loss: 0.782 | Acc: 72.504% \n",
      "[epoch:4, iter:1379] Loss: 0.782 | Acc: 72.512% \n",
      "[epoch:4, iter:1380] Loss: 0.782 | Acc: 72.528% \n",
      "[epoch:4, iter:1381] Loss: 0.782 | Acc: 72.521% \n",
      "[epoch:4, iter:1382] Loss: 0.781 | Acc: 72.548% \n",
      "[epoch:4, iter:1383] Loss: 0.780 | Acc: 72.563% \n",
      "[epoch:4, iter:1384] Loss: 0.780 | Acc: 72.567% \n",
      "[epoch:4, iter:1385] Loss: 0.780 | Acc: 72.579% \n",
      "[epoch:4, iter:1386] Loss: 0.779 | Acc: 72.601% \n",
      "[epoch:4, iter:1387] Loss: 0.780 | Acc: 72.572% \n",
      "[epoch:4, iter:1388] Loss: 0.780 | Acc: 72.558% \n",
      "[epoch:4, iter:1389] Loss: 0.781 | Acc: 72.555% \n",
      "[epoch:4, iter:1390] Loss: 0.781 | Acc: 72.566% \n",
      "[epoch:4, iter:1391] Loss: 0.780 | Acc: 72.592% \n",
      "[epoch:4, iter:1392] Loss: 0.780 | Acc: 72.588% \n",
      "[epoch:4, iter:1393] Loss: 0.779 | Acc: 72.599% \n",
      "[epoch:4, iter:1394] Loss: 0.779 | Acc: 72.624% \n",
      "[epoch:4, iter:1395] Loss: 0.779 | Acc: 72.649% \n",
      "[epoch:4, iter:1396] Loss: 0.778 | Acc: 72.660% \n",
      "[epoch:4, iter:1397] Loss: 0.777 | Acc: 72.660% \n",
      "[epoch:4, iter:1398] Loss: 0.776 | Acc: 72.705% \n",
      "[epoch:4, iter:1399] Loss: 0.776 | Acc: 72.718% \n",
      "[epoch:4, iter:1400] Loss: 0.775 | Acc: 72.739% \n",
      "[epoch:4, iter:1401] Loss: 0.775 | Acc: 72.742% \n",
      "[epoch:4, iter:1402] Loss: 0.775 | Acc: 72.748% \n",
      "[epoch:4, iter:1403] Loss: 0.775 | Acc: 72.768% \n",
      "[epoch:4, iter:1404] Loss: 0.775 | Acc: 72.778% \n",
      "[epoch:4, iter:1405] Loss: 0.775 | Acc: 72.781% \n",
      "[epoch:4, iter:1406] Loss: 0.774 | Acc: 72.797% \n",
      "[epoch:4, iter:1407] Loss: 0.773 | Acc: 72.820% \n",
      "[epoch:4, iter:1408] Loss: 0.773 | Acc: 72.839% \n",
      "[epoch:4, iter:1409] Loss: 0.774 | Acc: 72.815% \n",
      "[epoch:4, iter:1410] Loss: 0.773 | Acc: 72.828% \n",
      "[epoch:4, iter:1411] Loss: 0.773 | Acc: 72.824% \n",
      "[epoch:4, iter:1412] Loss: 0.773 | Acc: 72.856% \n",
      "[epoch:4, iter:1413] Loss: 0.773 | Acc: 72.868% \n",
      "[epoch:4, iter:1414] Loss: 0.772 | Acc: 72.854% \n",
      "[epoch:4, iter:1415] Loss: 0.772 | Acc: 72.879% \n",
      "[epoch:4, iter:1416] Loss: 0.772 | Acc: 72.904% \n",
      "[epoch:4, iter:1417] Loss: 0.771 | Acc: 72.906% \n",
      "[epoch:4, iter:1418] Loss: 0.772 | Acc: 72.899% \n",
      "[epoch:4, iter:1419] Loss: 0.772 | Acc: 72.901% \n",
      "[epoch:4, iter:1420] Loss: 0.772 | Acc: 72.893% \n",
      "[epoch:4, iter:1421] Loss: 0.772 | Acc: 72.883% \n",
      "[epoch:4, iter:1422] Loss: 0.772 | Acc: 72.888% \n",
      "[epoch:4, iter:1423] Loss: 0.771 | Acc: 72.894% \n",
      "[epoch:4, iter:1424] Loss: 0.771 | Acc: 72.902% \n",
      "[epoch:4, iter:1425] Loss: 0.771 | Acc: 72.920% \n",
      "[epoch:4, iter:1426] Loss: 0.770 | Acc: 72.934% \n",
      "[epoch:4, iter:1427] Loss: 0.770 | Acc: 72.948% \n",
      "[epoch:4, iter:1428] Loss: 0.770 | Acc: 72.935% \n",
      "[epoch:4, iter:1429] Loss: 0.770 | Acc: 72.922% \n",
      "[epoch:4, iter:1430] Loss: 0.770 | Acc: 72.930% \n",
      "[epoch:4, iter:1431] Loss: 0.770 | Acc: 72.953% \n",
      "[epoch:4, iter:1432] Loss: 0.770 | Acc: 72.952% \n",
      "[epoch:4, iter:1433] Loss: 0.769 | Acc: 72.963% \n",
      "[epoch:4, iter:1434] Loss: 0.770 | Acc: 72.971% \n",
      "[epoch:4, iter:1435] Loss: 0.770 | Acc: 72.966% \n",
      "[epoch:4, iter:1436] Loss: 0.770 | Acc: 72.974% \n",
      "[epoch:4, iter:1437] Loss: 0.770 | Acc: 72.964% \n",
      "[epoch:4, iter:1438] Loss: 0.770 | Acc: 72.969% \n",
      "[epoch:4, iter:1439] Loss: 0.769 | Acc: 72.971% \n",
      "[epoch:4, iter:1440] Loss: 0.769 | Acc: 72.990% \n",
      "[epoch:4, iter:1441] Loss: 0.768 | Acc: 72.994% \n",
      "[epoch:4, iter:1442] Loss: 0.768 | Acc: 73.002% \n",
      "[epoch:4, iter:1443] Loss: 0.768 | Acc: 73.012% \n",
      "[epoch:4, iter:1444] Loss: 0.768 | Acc: 73.008% \n",
      "[epoch:4, iter:1445] Loss: 0.768 | Acc: 72.989% \n",
      "[epoch:4, iter:1446] Loss: 0.768 | Acc: 72.971% \n",
      "[epoch:4, iter:1447] Loss: 0.769 | Acc: 72.970% \n",
      "[epoch:4, iter:1448] Loss: 0.769 | Acc: 72.969% \n",
      "[epoch:4, iter:1449] Loss: 0.769 | Acc: 72.979% \n",
      "[epoch:4, iter:1450] Loss: 0.768 | Acc: 73.006% \n",
      "[epoch:4, iter:1451] Loss: 0.768 | Acc: 73.022% \n",
      "[epoch:4, iter:1452] Loss: 0.768 | Acc: 73.037% \n",
      "[epoch:4, iter:1453] Loss: 0.768 | Acc: 73.033% \n",
      "[epoch:4, iter:1454] Loss: 0.768 | Acc: 73.020% \n",
      "[epoch:4, iter:1455] Loss: 0.768 | Acc: 73.019% \n",
      "[epoch:4, iter:1456] Loss: 0.768 | Acc: 73.010% \n",
      "[epoch:4, iter:1457] Loss: 0.768 | Acc: 72.975% \n",
      "[epoch:4, iter:1458] Loss: 0.768 | Acc: 72.980% \n",
      "[epoch:4, iter:1459] Loss: 0.768 | Acc: 73.003% \n",
      "[epoch:4, iter:1460] Loss: 0.768 | Acc: 72.986% \n",
      "[epoch:4, iter:1461] Loss: 0.768 | Acc: 72.984% \n",
      "[epoch:4, iter:1462] Loss: 0.768 | Acc: 72.991% \n",
      "[epoch:4, iter:1463] Loss: 0.767 | Acc: 73.004% \n",
      "[epoch:4, iter:1464] Loss: 0.767 | Acc: 73.011% \n",
      "[epoch:4, iter:1465] Loss: 0.767 | Acc: 73.028% \n",
      "[epoch:4, iter:1466] Loss: 0.766 | Acc: 73.059% \n",
      "[epoch:4, iter:1467] Loss: 0.766 | Acc: 73.063% \n",
      "[epoch:4, iter:1468] Loss: 0.766 | Acc: 73.053% \n",
      "[epoch:4, iter:1469] Loss: 0.766 | Acc: 73.052% \n",
      "[epoch:4, iter:1470] Loss: 0.766 | Acc: 73.059% \n",
      "[epoch:4, iter:1471] Loss: 0.766 | Acc: 73.055% \n",
      "[epoch:4, iter:1472] Loss: 0.765 | Acc: 73.066% \n",
      "[epoch:4, iter:1473] Loss: 0.765 | Acc: 73.060% \n",
      "[epoch:4, iter:1474] Loss: 0.765 | Acc: 73.061% \n",
      "[epoch:4, iter:1475] Loss: 0.765 | Acc: 73.070% \n",
      "[epoch:4, iter:1476] Loss: 0.765 | Acc: 73.077% \n",
      "[epoch:4, iter:1477] Loss: 0.764 | Acc: 73.078% \n",
      "[epoch:4, iter:1478] Loss: 0.764 | Acc: 73.092% \n",
      "[epoch:4, iter:1479] Loss: 0.764 | Acc: 73.088% \n",
      "[epoch:4, iter:1480] Loss: 0.764 | Acc: 73.104% \n",
      "[epoch:4, iter:1481] Loss: 0.763 | Acc: 73.115% \n",
      "[epoch:4, iter:1482] Loss: 0.763 | Acc: 73.132% \n",
      "[epoch:4, iter:1483] Loss: 0.763 | Acc: 73.150% \n",
      "[epoch:4, iter:1484] Loss: 0.763 | Acc: 73.146% \n",
      "[epoch:4, iter:1485] Loss: 0.762 | Acc: 73.147% \n",
      "[epoch:4, iter:1486] Loss: 0.763 | Acc: 73.145% \n",
      "[epoch:4, iter:1487] Loss: 0.763 | Acc: 73.149% \n",
      "[epoch:4, iter:1488] Loss: 0.763 | Acc: 73.157% \n",
      "[epoch:4, iter:1489] Loss: 0.763 | Acc: 73.153% \n",
      "[epoch:4, iter:1490] Loss: 0.763 | Acc: 73.147% \n",
      "[epoch:4, iter:1491] Loss: 0.763 | Acc: 73.143% \n",
      "[epoch:4, iter:1492] Loss: 0.763 | Acc: 73.141% \n",
      "[epoch:4, iter:1493] Loss: 0.763 | Acc: 73.147% \n",
      "[epoch:4, iter:1494] Loss: 0.763 | Acc: 73.158% \n",
      "[epoch:4, iter:1495] Loss: 0.763 | Acc: 73.151% \n",
      "[epoch:4, iter:1496] Loss: 0.763 | Acc: 73.159% \n",
      "[epoch:4, iter:1497] Loss: 0.763 | Acc: 73.170% \n",
      "[epoch:4, iter:1498] Loss: 0.762 | Acc: 73.166% \n",
      "[epoch:4, iter:1499] Loss: 0.763 | Acc: 73.136% \n",
      "[epoch:4, iter:1500] Loss: 0.763 | Acc: 73.144% \n",
      "[epoch:4, iter:1501] Loss: 0.763 | Acc: 73.159% \n",
      "[epoch:4, iter:1502] Loss: 0.763 | Acc: 73.157% \n",
      "[epoch:4, iter:1503] Loss: 0.762 | Acc: 73.182% \n",
      "[epoch:4, iter:1504] Loss: 0.762 | Acc: 73.168% \n",
      "[epoch:4, iter:1505] Loss: 0.762 | Acc: 73.193% \n",
      "[epoch:4, iter:1506] Loss: 0.761 | Acc: 73.212% \n",
      "[epoch:4, iter:1507] Loss: 0.761 | Acc: 73.211% \n",
      "[epoch:4, iter:1508] Loss: 0.761 | Acc: 73.221% \n",
      "[epoch:4, iter:1509] Loss: 0.760 | Acc: 73.235% \n",
      "[epoch:4, iter:1510] Loss: 0.761 | Acc: 73.231% \n",
      "[epoch:4, iter:1511] Loss: 0.760 | Acc: 73.248% \n",
      "[epoch:4, iter:1512] Loss: 0.760 | Acc: 73.230% \n",
      "[epoch:4, iter:1513] Loss: 0.760 | Acc: 73.238% \n",
      "[epoch:4, iter:1514] Loss: 0.759 | Acc: 73.250% \n",
      "[epoch:4, iter:1515] Loss: 0.759 | Acc: 73.250% \n",
      "[epoch:4, iter:1516] Loss: 0.759 | Acc: 73.237% \n",
      "[epoch:4, iter:1517] Loss: 0.760 | Acc: 73.231% \n",
      "[epoch:4, iter:1518] Loss: 0.760 | Acc: 73.234% \n",
      "[epoch:4, iter:1519] Loss: 0.759 | Acc: 73.234% \n",
      "[epoch:4, iter:1520] Loss: 0.759 | Acc: 73.242% \n",
      "[epoch:4, iter:1521] Loss: 0.759 | Acc: 73.251% \n",
      "[epoch:4, iter:1522] Loss: 0.759 | Acc: 73.249% \n",
      "[epoch:4, iter:1523] Loss: 0.758 | Acc: 73.261% \n",
      "[epoch:4, iter:1524] Loss: 0.758 | Acc: 73.259% \n",
      "[epoch:4, iter:1525] Loss: 0.759 | Acc: 73.247% \n",
      "[epoch:4, iter:1526] Loss: 0.758 | Acc: 73.258% \n",
      "[epoch:4, iter:1527] Loss: 0.758 | Acc: 73.248% \n",
      "[epoch:4, iter:1528] Loss: 0.759 | Acc: 73.255% \n",
      "[epoch:4, iter:1529] Loss: 0.759 | Acc: 73.249% \n",
      "[epoch:4, iter:1530] Loss: 0.759 | Acc: 73.238% \n",
      "[epoch:4, iter:1531] Loss: 0.758 | Acc: 73.243% \n",
      "[epoch:4, iter:1532] Loss: 0.758 | Acc: 73.233% \n",
      "[epoch:4, iter:1533] Loss: 0.758 | Acc: 73.231% \n",
      "[epoch:4, iter:1534] Loss: 0.758 | Acc: 73.241% \n",
      "[epoch:4, iter:1535] Loss: 0.758 | Acc: 73.250% \n",
      "[epoch:4, iter:1536] Loss: 0.758 | Acc: 73.250% \n",
      "[epoch:4, iter:1537] Loss: 0.758 | Acc: 73.251% \n",
      "[epoch:4, iter:1538] Loss: 0.758 | Acc: 73.247% \n",
      "[epoch:4, iter:1539] Loss: 0.758 | Acc: 73.250% \n",
      "[epoch:4, iter:1540] Loss: 0.758 | Acc: 73.246% \n",
      "[epoch:4, iter:1541] Loss: 0.758 | Acc: 73.257% \n",
      "[epoch:4, iter:1542] Loss: 0.758 | Acc: 73.264% \n",
      "[epoch:4, iter:1543] Loss: 0.757 | Acc: 73.275% \n",
      "[epoch:4, iter:1544] Loss: 0.757 | Acc: 73.280% \n",
      "[epoch:4, iter:1545] Loss: 0.757 | Acc: 73.272% \n",
      "[epoch:4, iter:1546] Loss: 0.757 | Acc: 73.266% \n",
      "[epoch:4, iter:1547] Loss: 0.758 | Acc: 73.258% \n",
      "[epoch:4, iter:1548] Loss: 0.758 | Acc: 73.256% \n",
      "[epoch:4, iter:1549] Loss: 0.757 | Acc: 73.275% \n",
      "[epoch:4, iter:1550] Loss: 0.757 | Acc: 73.272% \n",
      "[epoch:4, iter:1551] Loss: 0.757 | Acc: 73.274% \n",
      "[epoch:4, iter:1552] Loss: 0.757 | Acc: 73.273% \n",
      "[epoch:4, iter:1553] Loss: 0.757 | Acc: 73.285% \n",
      "[epoch:4, iter:1554] Loss: 0.756 | Acc: 73.302% \n",
      "[epoch:4, iter:1555] Loss: 0.756 | Acc: 73.323% \n",
      "[epoch:4, iter:1556] Loss: 0.756 | Acc: 73.325% \n",
      "[epoch:4, iter:1557] Loss: 0.756 | Acc: 73.334% \n",
      "[epoch:4, iter:1558] Loss: 0.756 | Acc: 73.348% \n",
      "[epoch:4, iter:1559] Loss: 0.755 | Acc: 73.352% \n",
      "[epoch:4, iter:1560] Loss: 0.756 | Acc: 73.349% \n",
      "[epoch:4, iter:1561] Loss: 0.755 | Acc: 73.353% \n",
      "[epoch:4, iter:1562] Loss: 0.755 | Acc: 73.347% \n",
      "[epoch:4, iter:1563] Loss: 0.755 | Acc: 73.351% \n",
      "[epoch:4, iter:1564] Loss: 0.755 | Acc: 73.354% \n",
      "Waiting Test!\n",
      "Test acc：75.030%\n",
      "\n",
      "Epoch: 5\n",
      "[epoch:5, iter:1565] Loss: 0.538 | Acc: 78.906% \n",
      "[epoch:5, iter:1566] Loss: 0.632 | Acc: 78.516% \n",
      "[epoch:5, iter:1567] Loss: 0.612 | Acc: 79.167% \n",
      "[epoch:5, iter:1568] Loss: 0.630 | Acc: 77.539% \n",
      "[epoch:5, iter:1569] Loss: 0.630 | Acc: 77.812% \n",
      "[epoch:5, iter:1570] Loss: 0.633 | Acc: 77.734% \n",
      "[epoch:5, iter:1571] Loss: 0.652 | Acc: 77.009% \n",
      "[epoch:5, iter:1572] Loss: 0.674 | Acc: 76.270% \n",
      "[epoch:5, iter:1573] Loss: 0.663 | Acc: 76.997% \n",
      "[epoch:5, iter:1574] Loss: 0.658 | Acc: 77.422% \n",
      "[epoch:5, iter:1575] Loss: 0.647 | Acc: 77.983% \n",
      "[epoch:5, iter:1576] Loss: 0.646 | Acc: 78.060% \n",
      "[epoch:5, iter:1577] Loss: 0.641 | Acc: 78.125% \n",
      "[epoch:5, iter:1578] Loss: 0.648 | Acc: 77.734% \n",
      "[epoch:5, iter:1579] Loss: 0.651 | Acc: 77.552% \n",
      "[epoch:5, iter:1580] Loss: 0.651 | Acc: 77.588% \n",
      "[epoch:5, iter:1581] Loss: 0.655 | Acc: 77.436% \n",
      "[epoch:5, iter:1582] Loss: 0.657 | Acc: 77.431% \n",
      "[epoch:5, iter:1583] Loss: 0.661 | Acc: 77.467% \n",
      "[epoch:5, iter:1584] Loss: 0.666 | Acc: 77.188% \n",
      "[epoch:5, iter:1585] Loss: 0.665 | Acc: 77.232% \n",
      "[epoch:5, iter:1586] Loss: 0.666 | Acc: 77.166% \n",
      "[epoch:5, iter:1587] Loss: 0.660 | Acc: 77.310% \n",
      "[epoch:5, iter:1588] Loss: 0.660 | Acc: 77.311% \n",
      "[epoch:5, iter:1589] Loss: 0.659 | Acc: 77.406% \n",
      "[epoch:5, iter:1590] Loss: 0.660 | Acc: 77.434% \n",
      "[epoch:5, iter:1591] Loss: 0.658 | Acc: 77.373% \n",
      "[epoch:5, iter:1592] Loss: 0.657 | Acc: 77.455% \n",
      "[epoch:5, iter:1593] Loss: 0.653 | Acc: 77.586% \n",
      "[epoch:5, iter:1594] Loss: 0.652 | Acc: 77.708% \n",
      "[epoch:5, iter:1595] Loss: 0.652 | Acc: 77.646% \n",
      "[epoch:5, iter:1596] Loss: 0.655 | Acc: 77.539% \n",
      "[epoch:5, iter:1597] Loss: 0.654 | Acc: 77.533% \n",
      "[epoch:5, iter:1598] Loss: 0.647 | Acc: 77.803% \n",
      "[epoch:5, iter:1599] Loss: 0.649 | Acc: 77.701% \n",
      "[epoch:5, iter:1600] Loss: 0.650 | Acc: 77.756% \n",
      "[epoch:5, iter:1601] Loss: 0.649 | Acc: 77.724% \n",
      "[epoch:5, iter:1602] Loss: 0.650 | Acc: 77.693% \n",
      "[epoch:5, iter:1603] Loss: 0.651 | Acc: 77.784% \n",
      "[epoch:5, iter:1604] Loss: 0.652 | Acc: 77.695% \n",
      "[epoch:5, iter:1605] Loss: 0.656 | Acc: 77.515% \n",
      "[epoch:5, iter:1606] Loss: 0.659 | Acc: 77.418% \n",
      "[epoch:5, iter:1607] Loss: 0.662 | Acc: 77.235% \n",
      "[epoch:5, iter:1608] Loss: 0.665 | Acc: 77.202% \n",
      "[epoch:5, iter:1609] Loss: 0.665 | Acc: 77.188% \n",
      "[epoch:5, iter:1610] Loss: 0.663 | Acc: 77.191% \n",
      "[epoch:5, iter:1611] Loss: 0.668 | Acc: 76.995% \n",
      "[epoch:5, iter:1612] Loss: 0.670 | Acc: 76.986% \n",
      "[epoch:5, iter:1613] Loss: 0.667 | Acc: 77.041% \n",
      "[epoch:5, iter:1614] Loss: 0.668 | Acc: 76.969% \n",
      "[epoch:5, iter:1615] Loss: 0.672 | Acc: 76.792% \n",
      "[epoch:5, iter:1616] Loss: 0.670 | Acc: 76.833% \n",
      "[epoch:5, iter:1617] Loss: 0.669 | Acc: 76.843% \n",
      "[epoch:5, iter:1618] Loss: 0.667 | Acc: 76.968% \n",
      "[epoch:5, iter:1619] Loss: 0.669 | Acc: 76.903% \n",
      "[epoch:5, iter:1620] Loss: 0.669 | Acc: 76.869% \n",
      "[epoch:5, iter:1621] Loss: 0.668 | Acc: 76.850% \n",
      "[epoch:5, iter:1622] Loss: 0.668 | Acc: 76.859% \n",
      "[epoch:5, iter:1623] Loss: 0.668 | Acc: 76.827% \n",
      "[epoch:5, iter:1624] Loss: 0.671 | Acc: 76.732% \n",
      "[epoch:5, iter:1625] Loss: 0.671 | Acc: 76.755% \n",
      "[epoch:5, iter:1626] Loss: 0.671 | Acc: 76.701% \n",
      "[epoch:5, iter:1627] Loss: 0.669 | Acc: 76.786% \n",
      "[epoch:5, iter:1628] Loss: 0.670 | Acc: 76.746% \n",
      "[epoch:5, iter:1629] Loss: 0.670 | Acc: 76.755% \n",
      "[epoch:5, iter:1630] Loss: 0.670 | Acc: 76.716% \n",
      "[epoch:5, iter:1631] Loss: 0.668 | Acc: 76.831% \n",
      "[epoch:5, iter:1632] Loss: 0.669 | Acc: 76.838% \n",
      "[epoch:5, iter:1633] Loss: 0.667 | Acc: 76.947% \n",
      "[epoch:5, iter:1634] Loss: 0.667 | Acc: 76.942% \n",
      "[epoch:5, iter:1635] Loss: 0.667 | Acc: 76.948% \n",
      "[epoch:5, iter:1636] Loss: 0.670 | Acc: 76.866% \n",
      "[epoch:5, iter:1637] Loss: 0.671 | Acc: 76.809% \n",
      "[epoch:5, iter:1638] Loss: 0.670 | Acc: 76.848% \n",
      "[epoch:5, iter:1639] Loss: 0.671 | Acc: 76.781% \n",
      "[epoch:5, iter:1640] Loss: 0.671 | Acc: 76.758% \n",
      "[epoch:5, iter:1641] Loss: 0.671 | Acc: 76.684% \n",
      "[epoch:5, iter:1642] Loss: 0.672 | Acc: 76.613% \n",
      "[epoch:5, iter:1643] Loss: 0.673 | Acc: 76.622% \n",
      "[epoch:5, iter:1644] Loss: 0.671 | Acc: 76.738% \n",
      "[epoch:5, iter:1645] Loss: 0.671 | Acc: 76.649% \n",
      "[epoch:5, iter:1646] Loss: 0.671 | Acc: 76.658% \n",
      "[epoch:5, iter:1647] Loss: 0.670 | Acc: 76.694% \n",
      "[epoch:5, iter:1648] Loss: 0.671 | Acc: 76.674% \n",
      "[epoch:5, iter:1649] Loss: 0.671 | Acc: 76.682% \n",
      "[epoch:5, iter:1650] Loss: 0.671 | Acc: 76.699% \n",
      "[epoch:5, iter:1651] Loss: 0.672 | Acc: 76.643% \n",
      "[epoch:5, iter:1652] Loss: 0.673 | Acc: 76.598% \n",
      "[epoch:5, iter:1653] Loss: 0.675 | Acc: 76.580% \n",
      "[epoch:5, iter:1654] Loss: 0.676 | Acc: 76.562% \n",
      "[epoch:5, iter:1655] Loss: 0.675 | Acc: 76.571% \n",
      "[epoch:5, iter:1656] Loss: 0.676 | Acc: 76.562% \n",
      "[epoch:5, iter:1657] Loss: 0.674 | Acc: 76.596% \n",
      "[epoch:5, iter:1658] Loss: 0.674 | Acc: 76.646% \n",
      "[epoch:5, iter:1659] Loss: 0.674 | Acc: 76.645% \n",
      "[epoch:5, iter:1660] Loss: 0.674 | Acc: 76.660% \n",
      "[epoch:5, iter:1661] Loss: 0.673 | Acc: 76.667% \n",
      "[epoch:5, iter:1662] Loss: 0.673 | Acc: 76.706% \n",
      "[epoch:5, iter:1663] Loss: 0.672 | Acc: 76.752% \n",
      "[epoch:5, iter:1664] Loss: 0.673 | Acc: 76.742% \n",
      "[epoch:5, iter:1665] Loss: 0.673 | Acc: 76.748% \n",
      "[epoch:5, iter:1666] Loss: 0.673 | Acc: 76.754% \n",
      "[epoch:5, iter:1667] Loss: 0.672 | Acc: 76.782% \n",
      "[epoch:5, iter:1668] Loss: 0.672 | Acc: 76.818% \n",
      "[epoch:5, iter:1669] Loss: 0.675 | Acc: 76.734% \n",
      "[epoch:5, iter:1670] Loss: 0.675 | Acc: 76.747% \n",
      "[epoch:5, iter:1671] Loss: 0.676 | Acc: 76.730% \n",
      "[epoch:5, iter:1672] Loss: 0.676 | Acc: 76.758% \n",
      "[epoch:5, iter:1673] Loss: 0.676 | Acc: 76.756% \n",
      "[epoch:5, iter:1674] Loss: 0.676 | Acc: 76.747% \n",
      "[epoch:5, iter:1675] Loss: 0.677 | Acc: 76.682% \n",
      "[epoch:5, iter:1676] Loss: 0.677 | Acc: 76.723% \n",
      "[epoch:5, iter:1677] Loss: 0.678 | Acc: 76.659% \n",
      "[epoch:5, iter:1678] Loss: 0.678 | Acc: 76.658% \n",
      "[epoch:5, iter:1679] Loss: 0.678 | Acc: 76.678% \n",
      "[epoch:5, iter:1680] Loss: 0.678 | Acc: 76.670% \n",
      "[epoch:5, iter:1681] Loss: 0.678 | Acc: 76.676% \n",
      "[epoch:5, iter:1682] Loss: 0.678 | Acc: 76.635% \n",
      "[epoch:5, iter:1683] Loss: 0.677 | Acc: 76.654% \n",
      "[epoch:5, iter:1684] Loss: 0.677 | Acc: 76.673% \n",
      "[epoch:5, iter:1685] Loss: 0.676 | Acc: 76.685% \n",
      "[epoch:5, iter:1686] Loss: 0.676 | Acc: 76.671% \n",
      "[epoch:5, iter:1687] Loss: 0.676 | Acc: 76.651% \n",
      "[epoch:5, iter:1688] Loss: 0.676 | Acc: 76.626% \n",
      "[epoch:5, iter:1689] Loss: 0.675 | Acc: 76.650% \n",
      "[epoch:5, iter:1690] Loss: 0.674 | Acc: 76.680% \n",
      "[epoch:5, iter:1691] Loss: 0.675 | Acc: 76.673% \n",
      "[epoch:5, iter:1692] Loss: 0.674 | Acc: 76.703% \n",
      "[epoch:5, iter:1693] Loss: 0.675 | Acc: 76.672% \n",
      "[epoch:5, iter:1694] Loss: 0.674 | Acc: 76.725% \n",
      "[epoch:5, iter:1695] Loss: 0.675 | Acc: 76.694% \n",
      "[epoch:5, iter:1696] Loss: 0.676 | Acc: 76.687% \n",
      "[epoch:5, iter:1697] Loss: 0.676 | Acc: 76.662% \n",
      "[epoch:5, iter:1698] Loss: 0.676 | Acc: 76.638% \n",
      "[epoch:5, iter:1699] Loss: 0.677 | Acc: 76.586% \n",
      "[epoch:5, iter:1700] Loss: 0.677 | Acc: 76.574% \n",
      "[epoch:5, iter:1701] Loss: 0.678 | Acc: 76.591% \n",
      "[epoch:5, iter:1702] Loss: 0.678 | Acc: 76.540% \n",
      "[epoch:5, iter:1703] Loss: 0.679 | Acc: 76.540% \n",
      "[epoch:5, iter:1704] Loss: 0.679 | Acc: 76.557% \n",
      "[epoch:5, iter:1705] Loss: 0.678 | Acc: 76.585% \n",
      "[epoch:5, iter:1706] Loss: 0.678 | Acc: 76.596% \n",
      "[epoch:5, iter:1707] Loss: 0.678 | Acc: 76.579% \n",
      "[epoch:5, iter:1708] Loss: 0.678 | Acc: 76.600% \n",
      "[epoch:5, iter:1709] Loss: 0.677 | Acc: 76.649% \n",
      "[epoch:5, iter:1710] Loss: 0.677 | Acc: 76.643% \n",
      "[epoch:5, iter:1711] Loss: 0.676 | Acc: 76.679% \n",
      "[epoch:5, iter:1712] Loss: 0.676 | Acc: 76.647% \n",
      "[epoch:5, iter:1713] Loss: 0.676 | Acc: 76.641% \n",
      "[epoch:5, iter:1714] Loss: 0.676 | Acc: 76.661% \n",
      "[epoch:5, iter:1715] Loss: 0.675 | Acc: 76.650% \n",
      "[epoch:5, iter:1716] Loss: 0.675 | Acc: 76.676% \n",
      "[epoch:5, iter:1717] Loss: 0.673 | Acc: 76.716% \n",
      "[epoch:5, iter:1718] Loss: 0.674 | Acc: 76.684% \n",
      "[epoch:5, iter:1719] Loss: 0.674 | Acc: 76.714% \n",
      "[epoch:5, iter:1720] Loss: 0.674 | Acc: 76.728% \n",
      "[epoch:5, iter:1721] Loss: 0.674 | Acc: 76.707% \n",
      "[epoch:5, iter:1722] Loss: 0.673 | Acc: 76.701% \n",
      "[epoch:5, iter:1723] Loss: 0.674 | Acc: 76.641% \n",
      "[epoch:5, iter:1724] Loss: 0.674 | Acc: 76.631% \n",
      "[epoch:5, iter:1725] Loss: 0.674 | Acc: 76.630% \n",
      "[epoch:5, iter:1726] Loss: 0.674 | Acc: 76.649% \n",
      "[epoch:5, iter:1727] Loss: 0.674 | Acc: 76.658% \n",
      "[epoch:5, iter:1728] Loss: 0.673 | Acc: 76.682% \n",
      "[epoch:5, iter:1729] Loss: 0.674 | Acc: 76.667% \n",
      "[epoch:5, iter:1730] Loss: 0.673 | Acc: 76.666% \n",
      "[epoch:5, iter:1731] Loss: 0.673 | Acc: 76.656% \n",
      "[epoch:5, iter:1732] Loss: 0.674 | Acc: 76.614% \n",
      "[epoch:5, iter:1733] Loss: 0.673 | Acc: 76.590% \n",
      "[epoch:5, iter:1734] Loss: 0.673 | Acc: 76.613% \n",
      "[epoch:5, iter:1735] Loss: 0.672 | Acc: 76.613% \n",
      "[epoch:5, iter:1736] Loss: 0.672 | Acc: 76.649% \n",
      "[epoch:5, iter:1737] Loss: 0.672 | Acc: 76.657% \n",
      "[epoch:5, iter:1738] Loss: 0.672 | Acc: 76.661% \n",
      "[epoch:5, iter:1739] Loss: 0.673 | Acc: 76.598% \n",
      "[epoch:5, iter:1740] Loss: 0.673 | Acc: 76.594% \n",
      "[epoch:5, iter:1741] Loss: 0.673 | Acc: 76.602% \n",
      "[epoch:5, iter:1742] Loss: 0.672 | Acc: 76.615% \n",
      "[epoch:5, iter:1743] Loss: 0.671 | Acc: 76.645% \n",
      "[epoch:5, iter:1744] Loss: 0.671 | Acc: 76.667% \n",
      "[epoch:5, iter:1745] Loss: 0.671 | Acc: 76.645% \n",
      "[epoch:5, iter:1746] Loss: 0.672 | Acc: 76.640% \n",
      "[epoch:5, iter:1747] Loss: 0.672 | Acc: 76.614% \n",
      "[epoch:5, iter:1748] Loss: 0.673 | Acc: 76.567% \n",
      "[epoch:5, iter:1749] Loss: 0.674 | Acc: 76.512% \n",
      "[epoch:5, iter:1750] Loss: 0.674 | Acc: 76.512% \n",
      "[epoch:5, iter:1751] Loss: 0.674 | Acc: 76.500% \n",
      "[epoch:5, iter:1752] Loss: 0.675 | Acc: 76.479% \n",
      "[epoch:5, iter:1753] Loss: 0.674 | Acc: 76.529% \n",
      "[epoch:5, iter:1754] Loss: 0.674 | Acc: 76.538% \n",
      "[epoch:5, iter:1755] Loss: 0.674 | Acc: 76.534% \n",
      "[epoch:5, iter:1756] Loss: 0.674 | Acc: 76.534% \n",
      "[epoch:5, iter:1757] Loss: 0.674 | Acc: 76.546% \n",
      "[epoch:5, iter:1758] Loss: 0.674 | Acc: 76.542% \n",
      "[epoch:5, iter:1759] Loss: 0.675 | Acc: 76.554% \n",
      "[epoch:5, iter:1760] Loss: 0.674 | Acc: 76.586% \n",
      "[epoch:5, iter:1761] Loss: 0.674 | Acc: 76.574% \n",
      "[epoch:5, iter:1762] Loss: 0.674 | Acc: 76.574% \n",
      "[epoch:5, iter:1763] Loss: 0.675 | Acc: 76.551% \n",
      "[epoch:5, iter:1764] Loss: 0.675 | Acc: 76.566% \n",
      "[epoch:5, iter:1765] Loss: 0.675 | Acc: 76.543% \n",
      "[epoch:5, iter:1766] Loss: 0.676 | Acc: 76.520% \n",
      "[epoch:5, iter:1767] Loss: 0.675 | Acc: 76.536% \n",
      "[epoch:5, iter:1768] Loss: 0.675 | Acc: 76.540% \n",
      "[epoch:5, iter:1769] Loss: 0.675 | Acc: 76.543% \n",
      "[epoch:5, iter:1770] Loss: 0.676 | Acc: 76.521% \n",
      "[epoch:5, iter:1771] Loss: 0.677 | Acc: 76.498% \n",
      "[epoch:5, iter:1772] Loss: 0.677 | Acc: 76.506% \n",
      "[epoch:5, iter:1773] Loss: 0.677 | Acc: 76.469% \n",
      "[epoch:5, iter:1774] Loss: 0.678 | Acc: 76.447% \n",
      "[epoch:5, iter:1775] Loss: 0.678 | Acc: 76.477% \n",
      "[epoch:5, iter:1776] Loss: 0.678 | Acc: 76.467% \n",
      "[epoch:5, iter:1777] Loss: 0.678 | Acc: 76.467% \n",
      "[epoch:5, iter:1778] Loss: 0.678 | Acc: 76.471% \n",
      "[epoch:5, iter:1779] Loss: 0.679 | Acc: 76.435% \n",
      "[epoch:5, iter:1780] Loss: 0.679 | Acc: 76.418% \n",
      "[epoch:5, iter:1781] Loss: 0.679 | Acc: 76.433% \n",
      "[epoch:5, iter:1782] Loss: 0.679 | Acc: 76.416% \n",
      "[epoch:5, iter:1783] Loss: 0.679 | Acc: 76.455% \n",
      "[epoch:5, iter:1784] Loss: 0.679 | Acc: 76.463% \n",
      "[epoch:5, iter:1785] Loss: 0.679 | Acc: 76.449% \n",
      "[epoch:5, iter:1786] Loss: 0.680 | Acc: 76.464% \n",
      "[epoch:5, iter:1787] Loss: 0.680 | Acc: 76.436% \n",
      "[epoch:5, iter:1788] Loss: 0.681 | Acc: 76.406% \n",
      "[epoch:5, iter:1789] Loss: 0.681 | Acc: 76.406% \n",
      "[epoch:5, iter:1790] Loss: 0.681 | Acc: 76.400% \n",
      "[epoch:5, iter:1791] Loss: 0.681 | Acc: 76.377% \n",
      "[epoch:5, iter:1792] Loss: 0.681 | Acc: 76.364% \n",
      "[epoch:5, iter:1793] Loss: 0.682 | Acc: 76.368% \n",
      "[epoch:5, iter:1794] Loss: 0.681 | Acc: 76.352% \n",
      "[epoch:5, iter:1795] Loss: 0.681 | Acc: 76.360% \n",
      "[epoch:5, iter:1796] Loss: 0.682 | Acc: 76.327% \n",
      "[epoch:5, iter:1797] Loss: 0.681 | Acc: 76.338% \n",
      "[epoch:5, iter:1798] Loss: 0.681 | Acc: 76.342% \n",
      "[epoch:5, iter:1799] Loss: 0.681 | Acc: 76.353% \n",
      "[epoch:5, iter:1800] Loss: 0.681 | Acc: 76.351% \n",
      "[epoch:5, iter:1801] Loss: 0.681 | Acc: 76.361% \n",
      "[epoch:5, iter:1802] Loss: 0.681 | Acc: 76.336% \n",
      "[epoch:5, iter:1803] Loss: 0.681 | Acc: 76.327% \n",
      "[epoch:5, iter:1804] Loss: 0.681 | Acc: 76.328% \n",
      "[epoch:5, iter:1805] Loss: 0.682 | Acc: 76.316% \n",
      "[epoch:5, iter:1806] Loss: 0.682 | Acc: 76.317% \n",
      "[epoch:5, iter:1807] Loss: 0.682 | Acc: 76.312% \n",
      "[epoch:5, iter:1808] Loss: 0.682 | Acc: 76.300% \n",
      "[epoch:5, iter:1809] Loss: 0.681 | Acc: 76.307% \n",
      "[epoch:5, iter:1810] Loss: 0.681 | Acc: 76.321% \n",
      "[epoch:5, iter:1811] Loss: 0.681 | Acc: 76.332% \n",
      "[epoch:5, iter:1812] Loss: 0.681 | Acc: 76.323% \n",
      "[epoch:5, iter:1813] Loss: 0.682 | Acc: 76.296% \n",
      "[epoch:5, iter:1814] Loss: 0.682 | Acc: 76.287% \n",
      "[epoch:5, iter:1815] Loss: 0.682 | Acc: 76.307% \n",
      "[epoch:5, iter:1816] Loss: 0.682 | Acc: 76.299% \n",
      "[epoch:5, iter:1817] Loss: 0.682 | Acc: 76.291% \n",
      "[epoch:5, iter:1818] Loss: 0.682 | Acc: 76.292% \n",
      "[epoch:5, iter:1819] Loss: 0.682 | Acc: 76.296% \n",
      "[epoch:5, iter:1820] Loss: 0.683 | Acc: 76.260% \n",
      "[epoch:5, iter:1821] Loss: 0.683 | Acc: 76.265% \n",
      "[epoch:5, iter:1822] Loss: 0.683 | Acc: 76.248% \n",
      "[epoch:5, iter:1823] Loss: 0.683 | Acc: 76.246% \n",
      "[epoch:5, iter:1824] Loss: 0.683 | Acc: 76.256% \n",
      "[epoch:5, iter:1825] Loss: 0.683 | Acc: 76.260% \n",
      "[epoch:5, iter:1826] Loss: 0.684 | Acc: 76.258% \n",
      "[epoch:5, iter:1827] Loss: 0.684 | Acc: 76.257% \n",
      "[epoch:5, iter:1828] Loss: 0.683 | Acc: 76.264% \n",
      "[epoch:5, iter:1829] Loss: 0.683 | Acc: 76.288% \n",
      "[epoch:5, iter:1830] Loss: 0.682 | Acc: 76.295% \n",
      "[epoch:5, iter:1831] Loss: 0.682 | Acc: 76.311% \n",
      "[epoch:5, iter:1832] Loss: 0.681 | Acc: 76.321% \n",
      "[epoch:5, iter:1833] Loss: 0.682 | Acc: 76.310% \n",
      "[epoch:5, iter:1834] Loss: 0.682 | Acc: 76.293% \n",
      "[epoch:5, iter:1835] Loss: 0.682 | Acc: 76.297% \n",
      "[epoch:5, iter:1836] Loss: 0.682 | Acc: 76.287% \n",
      "[epoch:5, iter:1837] Loss: 0.683 | Acc: 76.262% \n",
      "[epoch:5, iter:1838] Loss: 0.683 | Acc: 76.249% \n",
      "[epoch:5, iter:1839] Loss: 0.683 | Acc: 76.250% \n",
      "[epoch:5, iter:1840] Loss: 0.683 | Acc: 76.245% \n",
      "[epoch:5, iter:1841] Loss: 0.683 | Acc: 76.235% \n",
      "[epoch:5, iter:1842] Loss: 0.683 | Acc: 76.234% \n",
      "[epoch:5, iter:1843] Loss: 0.683 | Acc: 76.252% \n",
      "[epoch:5, iter:1844] Loss: 0.682 | Acc: 76.275% \n",
      "[epoch:5, iter:1845] Loss: 0.683 | Acc: 76.254% \n",
      "[epoch:5, iter:1846] Loss: 0.682 | Acc: 76.263% \n",
      "[epoch:5, iter:1847] Loss: 0.683 | Acc: 76.259% \n",
      "[epoch:5, iter:1848] Loss: 0.683 | Acc: 76.243% \n",
      "[epoch:5, iter:1849] Loss: 0.684 | Acc: 76.217% \n",
      "[epoch:5, iter:1850] Loss: 0.683 | Acc: 76.221% \n",
      "[epoch:5, iter:1851] Loss: 0.683 | Acc: 76.228% \n",
      "[epoch:5, iter:1852] Loss: 0.683 | Acc: 76.234% \n",
      "[epoch:5, iter:1853] Loss: 0.683 | Acc: 76.233% \n",
      "[epoch:5, iter:1854] Loss: 0.683 | Acc: 76.234% \n",
      "[epoch:5, iter:1855] Loss: 0.683 | Acc: 76.246% \n",
      "[epoch:5, iter:1856] Loss: 0.684 | Acc: 76.228% \n",
      "[epoch:5, iter:1857] Loss: 0.683 | Acc: 76.240% \n",
      "[epoch:5, iter:1858] Loss: 0.684 | Acc: 76.238% \n",
      "[epoch:5, iter:1859] Loss: 0.683 | Acc: 76.250% \n",
      "[epoch:5, iter:1860] Loss: 0.683 | Acc: 76.264% \n",
      "[epoch:5, iter:1861] Loss: 0.683 | Acc: 76.249% \n",
      "[epoch:5, iter:1862] Loss: 0.684 | Acc: 76.248% \n",
      "[epoch:5, iter:1863] Loss: 0.683 | Acc: 76.257% \n",
      "[epoch:5, iter:1864] Loss: 0.684 | Acc: 76.232% \n",
      "[epoch:5, iter:1865] Loss: 0.684 | Acc: 76.243% \n",
      "[epoch:5, iter:1866] Loss: 0.683 | Acc: 76.234% \n",
      "[epoch:5, iter:1867] Loss: 0.683 | Acc: 76.227% \n",
      "[epoch:5, iter:1868] Loss: 0.684 | Acc: 76.205% \n",
      "[epoch:5, iter:1869] Loss: 0.684 | Acc: 76.230% \n",
      "[epoch:5, iter:1870] Loss: 0.684 | Acc: 76.225% \n",
      "[epoch:5, iter:1871] Loss: 0.684 | Acc: 76.237% \n",
      "[epoch:5, iter:1872] Loss: 0.684 | Acc: 76.228% \n",
      "[epoch:5, iter:1873] Loss: 0.684 | Acc: 76.226% \n",
      "[epoch:5, iter:1874] Loss: 0.684 | Acc: 76.245% \n",
      "[epoch:5, iter:1875] Loss: 0.684 | Acc: 76.236% \n",
      "[epoch:5, iter:1876] Loss: 0.684 | Acc: 76.237% \n",
      "[epoch:5, iter:1877] Loss: 0.683 | Acc: 76.253% \n",
      "[epoch:5, iter:1878] Loss: 0.683 | Acc: 76.266% \n",
      "[epoch:5, iter:1879] Loss: 0.683 | Acc: 76.262% \n",
      "[epoch:5, iter:1880] Loss: 0.683 | Acc: 76.278% \n",
      "[epoch:5, iter:1881] Loss: 0.684 | Acc: 76.267% \n",
      "[epoch:5, iter:1882] Loss: 0.684 | Acc: 76.268% \n",
      "[epoch:5, iter:1883] Loss: 0.684 | Acc: 76.249% \n",
      "[epoch:5, iter:1884] Loss: 0.684 | Acc: 76.257% \n",
      "[epoch:5, iter:1885] Loss: 0.684 | Acc: 76.251% \n",
      "[epoch:5, iter:1886] Loss: 0.684 | Acc: 76.242% \n",
      "[epoch:5, iter:1887] Loss: 0.684 | Acc: 76.253% \n",
      "[epoch:5, iter:1888] Loss: 0.685 | Acc: 76.235% \n",
      "[epoch:5, iter:1889] Loss: 0.685 | Acc: 76.238% \n",
      "[epoch:5, iter:1890] Loss: 0.684 | Acc: 76.261% \n",
      "[epoch:5, iter:1891] Loss: 0.683 | Acc: 76.283% \n",
      "[epoch:5, iter:1892] Loss: 0.683 | Acc: 76.279% \n",
      "[epoch:5, iter:1893] Loss: 0.683 | Acc: 76.273% \n",
      "[epoch:5, iter:1894] Loss: 0.683 | Acc: 76.271% \n",
      "[epoch:5, iter:1895] Loss: 0.683 | Acc: 76.286% \n",
      "[epoch:5, iter:1896] Loss: 0.683 | Acc: 76.282% \n",
      "[epoch:5, iter:1897] Loss: 0.683 | Acc: 76.290% \n",
      "[epoch:5, iter:1898] Loss: 0.683 | Acc: 76.284% \n",
      "[epoch:5, iter:1899] Loss: 0.683 | Acc: 76.292% \n",
      "[epoch:5, iter:1900] Loss: 0.683 | Acc: 76.295% \n",
      "[epoch:5, iter:1901] Loss: 0.683 | Acc: 76.291% \n",
      "[epoch:5, iter:1902] Loss: 0.683 | Acc: 76.294% \n",
      "[epoch:5, iter:1903] Loss: 0.683 | Acc: 76.300% \n",
      "[epoch:5, iter:1904] Loss: 0.683 | Acc: 76.305% \n",
      "[epoch:5, iter:1905] Loss: 0.682 | Acc: 76.324% \n",
      "[epoch:5, iter:1906] Loss: 0.682 | Acc: 76.323% \n",
      "[epoch:5, iter:1907] Loss: 0.683 | Acc: 76.305% \n",
      "[epoch:5, iter:1908] Loss: 0.682 | Acc: 76.315% \n",
      "[epoch:5, iter:1909] Loss: 0.683 | Acc: 76.311% \n",
      "[epoch:5, iter:1910] Loss: 0.682 | Acc: 76.314% \n",
      "[epoch:5, iter:1911] Loss: 0.682 | Acc: 76.304% \n",
      "[epoch:5, iter:1912] Loss: 0.682 | Acc: 76.322% \n",
      "[epoch:5, iter:1913] Loss: 0.682 | Acc: 76.345% \n",
      "[epoch:5, iter:1914] Loss: 0.682 | Acc: 76.344% \n",
      "[epoch:5, iter:1915] Loss: 0.681 | Acc: 76.353% \n",
      "[epoch:5, iter:1916] Loss: 0.681 | Acc: 76.369% \n",
      "[epoch:5, iter:1917] Loss: 0.681 | Acc: 76.377% \n",
      "[epoch:5, iter:1918] Loss: 0.680 | Acc: 76.386% \n",
      "[epoch:5, iter:1919] Loss: 0.681 | Acc: 76.375% \n",
      "[epoch:5, iter:1920] Loss: 0.680 | Acc: 76.387% \n",
      "[epoch:5, iter:1921] Loss: 0.680 | Acc: 76.398% \n",
      "[epoch:5, iter:1922] Loss: 0.680 | Acc: 76.397% \n",
      "[epoch:5, iter:1923] Loss: 0.680 | Acc: 76.415% \n",
      "[epoch:5, iter:1924] Loss: 0.679 | Acc: 76.434% \n",
      "[epoch:5, iter:1925] Loss: 0.679 | Acc: 76.446% \n",
      "[epoch:5, iter:1926] Loss: 0.679 | Acc: 76.459% \n",
      "[epoch:5, iter:1927] Loss: 0.679 | Acc: 76.464% \n",
      "[epoch:5, iter:1928] Loss: 0.679 | Acc: 76.449% \n",
      "[epoch:5, iter:1929] Loss: 0.679 | Acc: 76.436% \n",
      "[epoch:5, iter:1930] Loss: 0.679 | Acc: 76.443% \n",
      "[epoch:5, iter:1931] Loss: 0.678 | Acc: 76.460% \n",
      "[epoch:5, iter:1932] Loss: 0.678 | Acc: 76.465% \n",
      "[epoch:5, iter:1933] Loss: 0.678 | Acc: 76.474% \n",
      "[epoch:5, iter:1934] Loss: 0.678 | Acc: 76.474% \n",
      "[epoch:5, iter:1935] Loss: 0.678 | Acc: 76.470% \n",
      "[epoch:5, iter:1936] Loss: 0.678 | Acc: 76.470% \n",
      "[epoch:5, iter:1937] Loss: 0.678 | Acc: 76.470% \n",
      "[epoch:5, iter:1938] Loss: 0.677 | Acc: 76.466% \n",
      "[epoch:5, iter:1939] Loss: 0.677 | Acc: 76.479% \n",
      "[epoch:5, iter:1940] Loss: 0.677 | Acc: 76.488% \n",
      "[epoch:5, iter:1941] Loss: 0.676 | Acc: 76.504% \n",
      "[epoch:5, iter:1942] Loss: 0.677 | Acc: 76.509% \n",
      "[epoch:5, iter:1943] Loss: 0.676 | Acc: 76.507% \n",
      "[epoch:5, iter:1944] Loss: 0.676 | Acc: 76.505% \n",
      "[epoch:5, iter:1945] Loss: 0.676 | Acc: 76.501% \n",
      "[epoch:5, iter:1946] Loss: 0.676 | Acc: 76.518% \n",
      "[epoch:5, iter:1947] Loss: 0.676 | Acc: 76.505% \n",
      "[epoch:5, iter:1948] Loss: 0.676 | Acc: 76.506% \n",
      "[epoch:5, iter:1949] Loss: 0.676 | Acc: 76.516% \n",
      "[epoch:5, iter:1950] Loss: 0.676 | Acc: 76.530% \n",
      "[epoch:5, iter:1951] Loss: 0.676 | Acc: 76.528% \n",
      "[epoch:5, iter:1952] Loss: 0.675 | Acc: 76.542% \n",
      "[epoch:5, iter:1953] Loss: 0.675 | Acc: 76.546% \n",
      "[epoch:5, iter:1954] Loss: 0.675 | Acc: 76.546% \n",
      "[epoch:5, iter:1955] Loss: 0.675 | Acc: 76.544% \n",
      "Waiting Test!\n",
      "Test acc：76.180%\n",
      "Training Finished, TotalEPOCH=5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# check if cuda is available, if not just use cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# configuration of parameters\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
    "parser.add_argument('--outf', default='./model/', help='folder to output images and model checkpoints') \n",
    "args = parser.parse_args([])\n",
    "\n",
    "# configuration of hyperparameters\n",
    "EPOCH = 5  \n",
    "pre_epoch = 0  \n",
    "BATCH_SIZE = 128     \n",
    "LR = 0.01       \n",
    "\n",
    "# prepare the dataset and preprocessing\n",
    "# use mean and variance to normalize\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),  \n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)), \n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Get dataset online\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train) \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)   \n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Cifar-10 labels\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# define a resnet\n",
    "net = ResNet18().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "#optimize with mini-batch momentum-SGD using L2-normalization\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=5e-4) \n",
    "\n",
    "best_acc = 85 \n",
    "\n",
    "print(\"Start Training...\")\n",
    "\n",
    "for epoch in range(pre_epoch, EPOCH):\n",
    "    print('\\nEpoch: %d' % (epoch + 1))\n",
    "    net.train()\n",
    "    sum_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # preparing for data\n",
    "        length = len(trainloader)\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print out the loss and acc for every batch \n",
    "        sum_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.data).cpu().sum()\n",
    "        print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '\n",
    "              % (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "\n",
    "    # after each epoch print out the acc\n",
    "    print(\"Waiting Test!\")\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for data in testloader:\n",
    "            net.eval()\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "        print('Test acc：%.3f%%' % (100 * correct / total))\n",
    "        acc = 100. * correct / total\n",
    "\n",
    "print(\"Training Finished, TotalEPOCH=%d\" % EPOCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2dxC3chB8ED"
   },
   "source": [
    "best_acc= 96.285%\n",
    "\n",
    "In this src file, we just set the epoch = 5 for quick execution. While we were training the model, we have set epoch = 135 and it takes ~ 54min. You can check the changes of acc from the sreenshot in the zip-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KP57WBsLEKHh",
    "outputId": "9d5b9196-7023-4dd4-c236-24b33d68c5b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ResidualBlock(\n",
      "    (left): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): ResidualBlock(\n",
      "    (left): Sequential(\n",
      "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net.layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m0JIjSxTLqrI",
    "outputId": "b01d90d6-92f0-41d0-89df-f83fa4292c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(64, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "# Get the first CNN layer\n",
    "print(list(list(net.layer1[0].children())[0].children())[0])\n",
    "first_filter = list(list(net.layer1[0].children())[0].children())[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfF9CJVEE_up"
   },
   "source": [
    "# Task 1\n",
    "Plot the filters of the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "dmSjU4aS9GkK",
    "outputId": "1fcf0749-f0b2-4fdb-cd6e-a0f463a5baec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 16, 32, 32])\n",
      "tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.5124e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 2.8847e-01,  ..., 1.6369e+00,\n",
      "           2.0218e+00, 1.4376e-01],\n",
      "          [0.0000e+00, 8.4329e-01, 1.4488e+00,  ..., 2.6947e+00,\n",
      "           3.2912e+00, 1.3402e+00],\n",
      "          ...,\n",
      "          [3.8574e-01, 1.5705e+00, 6.9407e-01,  ..., 1.7895e+00,\n",
      "           2.2566e+00, 7.4816e-01],\n",
      "          [2.7489e+00, 3.1208e+00, 2.0009e+00,  ..., 0.0000e+00,\n",
      "           1.6437e+00, 0.0000e+00],\n",
      "          [1.5551e+00, 1.1544e+00, 1.2164e-01,  ..., 6.1860e-03,\n",
      "           9.8711e-01, 0.0000e+00]],\n",
      "\n",
      "         [[1.2969e+00, 1.0030e+00, 1.1965e+00,  ..., 7.8604e-02,\n",
      "           5.9599e-02, 1.9262e+00],\n",
      "          [8.3922e-01, 1.5745e-01, 7.3853e-01,  ..., 0.0000e+00,\n",
      "           2.5838e-03, 9.6541e-01],\n",
      "          [1.2438e+00, 0.0000e+00, 7.1265e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 6.8668e-01],\n",
      "          ...,\n",
      "          [2.0214e+00, 0.0000e+00, 2.4594e-01,  ..., 4.7214e-01,\n",
      "           0.0000e+00, 1.1860e+00],\n",
      "          [0.0000e+00, 3.7261e-03, 1.1285e+00,  ..., 1.4292e+00,\n",
      "           0.0000e+00, 1.9305e+00],\n",
      "          [2.9844e+00, 2.4328e+00, 1.3904e+00,  ..., 1.3175e+00,\n",
      "           4.6831e-01, 1.3119e+00]],\n",
      "\n",
      "         [[1.5956e+00, 8.2392e-01, 9.4927e-01,  ..., 0.0000e+00,\n",
      "           1.1005e+00, 7.8351e-02],\n",
      "          [1.6116e+00, 3.3349e-01, 2.7173e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.3989e+00],\n",
      "          [2.5975e+00, 1.8033e+00, 1.6717e+00,  ..., 0.0000e+00,\n",
      "           3.3053e-01, 2.0404e+00],\n",
      "          ...,\n",
      "          [2.7177e-02, 0.0000e+00, 2.2479e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 3.5702e-02],\n",
      "          [0.0000e+00, 0.0000e+00, 1.6624e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 3.8079e-01],\n",
      "          [2.7324e+00, 1.2393e+00, 0.0000e+00,  ..., 7.1217e-01,\n",
      "           0.0000e+00, 1.5627e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[8.8333e-01, 1.0510e+00, 1.6213e+00,  ..., 1.8235e+00,\n",
      "           1.1197e+00, 1.3441e+00],\n",
      "          [7.9222e-01, 3.9107e-01, 7.9676e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 2.1979e+00],\n",
      "          [1.1430e+00, 1.0302e+00, 1.0037e+00,  ..., 3.9145e-01,\n",
      "           0.0000e+00, 1.3908e+00],\n",
      "          ...,\n",
      "          [1.0028e+00, 1.6761e-01, 2.5757e-01,  ..., 1.0294e+00,\n",
      "           1.5115e-01, 0.0000e+00],\n",
      "          [2.6089e+00, 9.4049e-01, 0.0000e+00,  ..., 2.3268e+00,\n",
      "           1.1134e+00, 8.7503e-01],\n",
      "          [2.2019e+00, 1.1691e+00, 3.2673e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.0603e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           4.6462e-01, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1521e+00,\n",
      "           3.3662e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3463e+00,\n",
      "           2.8661e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [2.7100e-01, 1.8461e+00, 0.0000e+00,  ..., 1.5672e-01,\n",
      "           2.3999e-01, 0.0000e+00],\n",
      "          [2.8999e+00, 1.7524e+00, 2.8888e-01,  ..., 1.8244e+00,\n",
      "           3.3486e+00, 7.8897e-01],\n",
      "          [1.6569e+00, 2.3730e+00, 5.9654e-01,  ..., 3.3097e-01,\n",
      "           7.2458e-02, 0.0000e+00]],\n",
      "\n",
      "         [[1.8805e-01, 0.0000e+00, 0.0000e+00,  ..., 1.2778e+00,\n",
      "           3.0315e-01, 2.6138e-01],\n",
      "          [0.0000e+00, 1.2762e-01, 4.6992e-01,  ..., 3.4524e+00,\n",
      "           3.3591e+00, 2.2823e+00],\n",
      "          [5.1143e-01, 4.4458e-01, 0.0000e+00,  ..., 3.7145e-01,\n",
      "           1.1846e+00, 1.2420e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 1.8319e+00, 1.1172e+00,  ..., 1.7060e+00,\n",
      "           3.0260e+00, 1.1880e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           7.5238e-01, 9.0006e-01],\n",
      "          [1.5282e+00, 4.2611e-01, 1.1545e+00,  ..., 2.0176e+00,\n",
      "           1.4698e+00, 2.7979e+00]]],\n",
      "\n",
      "\n",
      "        [[[1.2410e-01, 4.9218e-01, 0.0000e+00,  ..., 4.3742e-01,\n",
      "           8.0016e-01, 4.0480e-01],\n",
      "          [3.9404e-01, 1.9224e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.4184e+00, 3.2253e-01, 3.7492e-01,  ..., 1.4543e+00,\n",
      "           1.4622e+00, 6.7968e-01],\n",
      "          ...,\n",
      "          [5.1606e-01, 1.2352e+00, 0.0000e+00,  ..., 3.3872e-01,\n",
      "           1.4211e+00, 1.3774e+00],\n",
      "          [1.7299e-01, 2.2090e+00, 2.6794e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 2.7861e-01],\n",
      "          [9.5725e-01, 7.7619e-01, 7.4002e-01,  ..., 0.0000e+00,\n",
      "           3.0706e-01, 5.3009e-01]],\n",
      "\n",
      "         [[1.0685e-01, 9.7384e-01, 1.2203e+00,  ..., 2.0153e+00,\n",
      "           8.3818e-01, 3.5706e+00],\n",
      "          [2.1149e+00, 1.4827e+00, 3.6863e-01,  ..., 1.2042e+00,\n",
      "           3.2421e-01, 1.8906e+00],\n",
      "          [2.4614e+00, 5.1949e-01, 1.8820e+00,  ..., 1.9662e+00,\n",
      "           8.5938e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 2.2759e-01, 0.0000e+00,  ..., 6.6558e-01,\n",
      "           1.4637e+00, 1.3072e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           2.0394e+00, 6.4259e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 7.1572e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 2.2448e-01,  ..., 0.0000e+00,\n",
      "           2.5146e-01, 0.0000e+00],\n",
      "          [6.4227e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           3.0215e-01, 1.3459e+00],\n",
      "          [0.0000e+00, 1.2659e+00, 0.0000e+00,  ..., 1.0714e+00,\n",
      "           6.9325e-01, 1.7598e+00],\n",
      "          ...,\n",
      "          [1.8993e+00, 0.0000e+00, 0.0000e+00,  ..., 1.5410e-03,\n",
      "           2.5049e-01, 1.0179e+00],\n",
      "          [2.2189e+00, 5.9585e-01, 0.0000e+00,  ..., 2.4874e+00,\n",
      "           8.9890e-01, 1.3349e+00],\n",
      "          [2.0906e+00, 5.6732e-01, 0.0000e+00,  ..., 1.9406e-01,\n",
      "           0.0000e+00, 9.1242e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.9696e+00, 1.4265e+00, 1.4080e+00,  ..., 1.2953e+00,\n",
      "           2.1701e+00, 1.4947e+00],\n",
      "          [1.4060e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.2379e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.3169e+00],\n",
      "          ...,\n",
      "          [1.8572e+00, 1.3377e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 7.0190e-01],\n",
      "          [1.9575e+00, 1.4944e+00, 0.0000e+00,  ..., 3.3755e-01,\n",
      "           9.2939e-01, 4.4911e-01],\n",
      "          [3.3998e+00, 3.6851e+00, 4.5127e-01,  ..., 4.4045e-01,\n",
      "           1.1748e+00, 9.9372e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [0.0000e+00, 2.5326e+00, 0.0000e+00,  ..., 1.1849e+00,\n",
      "           1.3552e+00, 0.0000e+00],\n",
      "          [4.6792e-01, 4.0329e-01, 2.3149e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [1.8766e+00, 2.1554e+00, 0.0000e+00,  ..., 1.4102e+00,\n",
      "           1.9443e+00, 1.4603e-01],\n",
      "          [1.7577e+00, 1.6131e+00, 1.5311e+00,  ..., 2.5225e+00,\n",
      "           1.8494e+00, 0.0000e+00],\n",
      "          [8.4598e-02, 6.7003e-01, 0.0000e+00,  ..., 1.1358e+00,\n",
      "           1.3060e+00, 2.7738e-02]],\n",
      "\n",
      "         [[9.1191e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.0157e-01, 0.0000e+00, 0.0000e+00,  ..., 1.2363e+00,\n",
      "           1.8931e+00, 2.4628e+00],\n",
      "          [1.3997e-01, 8.1344e-01, 8.7281e-01,  ..., 9.5073e-01,\n",
      "           6.5272e-01, 1.2915e+00],\n",
      "          ...,\n",
      "          [2.3581e+00, 4.2776e-01, 0.0000e+00,  ..., 2.1597e+00,\n",
      "           1.9987e+00, 6.4999e-01],\n",
      "          [9.5868e-02, 1.0975e+00, 0.0000e+00,  ..., 2.5272e-01,\n",
      "           7.6225e-01, 0.0000e+00],\n",
      "          [2.7723e+00, 5.9088e-01, 5.8278e-01,  ..., 2.0689e+00,\n",
      "           2.2248e+00, 0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 1.8132e-01,  ..., 0.0000e+00,\n",
      "           9.3365e-02, 1.3129e-01],\n",
      "          [1.3955e+00, 1.6408e+00, 2.0795e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.5876e+00, 2.7842e+00, 3.1215e+00,  ..., 1.5153e+00,\n",
      "           1.2339e+00, 4.2292e-01],\n",
      "          ...,\n",
      "          [1.0433e+00, 3.0124e+00, 3.2603e+00,  ..., 6.3885e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2461e+00, 3.1296e+00, 2.7840e+00,  ..., 8.1016e-01,\n",
      "           6.0629e-01, 0.0000e+00],\n",
      "          [1.4622e+00, 1.3448e+00, 1.0779e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[5.0228e-01, 0.0000e+00, 7.6577e-01,  ..., 7.9832e-01,\n",
      "           5.9280e-01, 2.6949e+00],\n",
      "          [1.6251e+00, 2.3035e-01, 3.8855e-01,  ..., 5.6189e-01,\n",
      "           4.5649e-01, 9.7866e-01],\n",
      "          [3.0091e-01, 0.0000e+00, 2.6888e-01,  ..., 1.1569e+00,\n",
      "           4.0304e-02, 5.9807e-01],\n",
      "          ...,\n",
      "          [1.2102e+00, 0.0000e+00, 0.0000e+00,  ..., 7.5694e-01,\n",
      "           4.7363e-01, 1.6630e+00],\n",
      "          [5.5753e-01, 6.6252e-01, 9.4459e-01,  ..., 1.3175e+00,\n",
      "           7.9969e-01, 2.1715e+00],\n",
      "          [3.5600e+00, 2.6927e+00, 1.3214e+00,  ..., 1.8139e+00,\n",
      "           7.1668e-01, 1.5227e+00]],\n",
      "\n",
      "         [[2.8568e-01, 7.0118e-02, 3.8987e-02,  ..., 1.0452e+00,\n",
      "           5.6895e-01, 8.9182e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 1.9917e-02,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.8436e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 7.7463e-01,  ..., 2.0501e+00,\n",
      "           1.5565e+00, 1.9640e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.6423e-01,\n",
      "           8.9368e-01, 2.0283e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.2928e+00,\n",
      "           1.9879e+00, 1.7713e+00],\n",
      "          [2.4323e+00, 1.7525e+00, 4.2121e-01,  ..., 2.0526e+00,\n",
      "           2.1460e+00, 2.4719e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.6851e+00, 6.6969e-01, 1.2704e+00,  ..., 1.2400e+00,\n",
      "           1.1845e+00, 1.2474e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 2.3137e+00],\n",
      "          [1.8530e+00, 5.8235e-01, 0.0000e+00,  ..., 6.8858e-01,\n",
      "           0.0000e+00, 2.0762e+00],\n",
      "          ...,\n",
      "          [2.6283e+00, 1.2033e+00, 1.2132e+00,  ..., 5.5204e-01,\n",
      "           6.1220e-01, 2.4644e+00],\n",
      "          [3.0190e+00, 1.4545e+00, 1.1821e+00,  ..., 6.9945e-01,\n",
      "           5.8641e-01, 1.8459e+00],\n",
      "          [2.2786e+00, 8.4971e-01, 0.0000e+00,  ..., 1.7689e+00,\n",
      "           1.0612e+00, 2.4937e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2246e+00, 4.1529e+00, 7.1798e-01,  ..., 9.7955e-01,\n",
      "           4.8869e-01, 0.0000e+00],\n",
      "          [1.3718e+00, 2.6079e+00, 1.2243e+00,  ..., 7.7869e-01,\n",
      "           5.4332e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [5.6584e-01, 2.6357e+00, 1.7585e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.9500e+00, 2.6386e+00, 2.2508e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.8289e+00, 2.5113e+00, 1.6465e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.4064e+00, 7.8445e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           7.4639e-02, 0.0000e+00],\n",
      "          [1.0029e+00, 2.9686e+00, 5.2952e-01,  ..., 1.9564e+00,\n",
      "           2.7980e+00, 2.0972e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           6.9130e-01, 9.4798e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 3.5428e-01, 9.7825e-01,  ..., 6.7259e-01,\n",
      "           1.2629e+00, 5.2404e-01],\n",
      "          [0.0000e+00, 1.7826e-01, 6.3842e-01,  ..., 6.6335e-01,\n",
      "           1.0119e+00, 4.9024e-01],\n",
      "          [1.3537e+00, 0.0000e+00, 1.2074e+00,  ..., 1.7450e+00,\n",
      "           1.0030e+00, 1.5873e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 2.2336e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 4.7788e-02],\n",
      "          [1.4670e-01, 8.7203e-01, 1.4698e+00,  ..., 4.4047e-01,\n",
      "           3.0139e-01, 1.5019e-01],\n",
      "          [0.0000e+00, 1.8774e+00, 8.5851e-01,  ..., 1.6055e+00,\n",
      "           2.0275e+00, 1.1089e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 2.1380e+00,  ..., 2.2596e-01,\n",
      "           3.2755e-01, 0.0000e+00],\n",
      "          [1.2934e+00, 2.4603e+00, 2.0079e+00,  ..., 1.4971e+00,\n",
      "           1.0129e+00, 5.7697e-01],\n",
      "          [4.1343e-01, 9.0510e-01, 0.0000e+00,  ..., 3.0133e-03,\n",
      "           1.6879e-01, 0.0000e+00]],\n",
      "\n",
      "         [[5.2799e-01, 5.0009e-01, 6.9497e-01,  ..., 3.2815e-01,\n",
      "           7.1371e-01, 2.1698e+00],\n",
      "          [9.2577e-01, 0.0000e+00, 1.0625e+00,  ..., 2.1625e-01,\n",
      "           2.4973e-02, 6.3488e-01],\n",
      "          [3.0059e+00, 5.9801e-01, 2.7659e-01,  ..., 3.9716e-01,\n",
      "           0.0000e+00, 6.8567e-01],\n",
      "          ...,\n",
      "          [1.0802e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.4714e+00],\n",
      "          [4.1826e-01, 6.0244e-01, 4.2453e-01,  ..., 1.5993e+00,\n",
      "           3.4182e-01, 1.8727e+00],\n",
      "          [4.0145e+00, 2.0033e+00, 1.8611e+00,  ..., 8.8358e-01,\n",
      "           7.7714e-01, 2.2070e+00]],\n",
      "\n",
      "         [[1.1672e+00, 5.4976e-02, 0.0000e+00,  ..., 1.4873e+00,\n",
      "           1.1771e+00, 9.4828e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.5685e+00],\n",
      "          [1.7732e+00, 1.3607e+00, 1.8284e-02,  ..., 3.5201e-01,\n",
      "           1.0520e+00, 1.5582e+00],\n",
      "          ...,\n",
      "          [1.1755e+00, 9.2498e-01, 0.0000e+00,  ..., 5.8467e-01,\n",
      "           8.4427e-01, 1.8550e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.4327e+00, 1.6882e+00, 2.2488e+00,  ..., 2.2532e+00,\n",
      "           1.6215e+00, 2.2884e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[7.7667e-01, 1.8664e+00, 1.3592e+00,  ..., 1.2061e+00,\n",
      "           1.2776e+00, 1.4863e+00],\n",
      "          [6.6625e-01, 6.3156e-01, 3.8627e-01,  ..., 8.4564e-02,\n",
      "           0.0000e+00, 2.2582e+00],\n",
      "          [1.5301e+00, 5.3732e-01, 8.0587e-01,  ..., 1.1153e+00,\n",
      "           0.0000e+00, 1.7463e+00],\n",
      "          ...,\n",
      "          [1.1969e+00, 1.9804e+00, 7.2162e-01,  ..., 6.9815e-01,\n",
      "           5.9716e-01, 1.0356e+00],\n",
      "          [6.7343e-01, 4.5397e-01, 3.4351e-01,  ..., 8.3854e-01,\n",
      "           3.1514e-01, 1.0850e+00],\n",
      "          [3.0239e+00, 1.3000e+00, 1.5218e-02,  ..., 4.6902e-01,\n",
      "           7.6565e-02, 1.5113e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.3631e-01, 1.2845e+00, 2.1368e-01,  ..., 1.7482e+00,\n",
      "           1.0498e+00, 0.0000e+00],\n",
      "          [1.5117e+00, 1.1946e+00, 3.7491e-01,  ..., 1.8384e+00,\n",
      "           1.9295e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [6.2115e-02, 1.2133e+00, 1.9068e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.4531e+00, 2.7194e+00, 3.8313e+00,  ..., 5.2667e-01,\n",
      "           2.2690e-01, 0.0000e+00],\n",
      "          [9.9909e-01, 2.9132e+00, 2.0856e+00,  ..., 8.8553e-01,\n",
      "           1.2320e+00, 0.0000e+00]],\n",
      "\n",
      "         [[9.6601e-01, 2.0183e-01, 2.6098e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.6690e-01, 1.9449e+00, 1.2663e+00,  ..., 2.5693e+00,\n",
      "           2.4578e+00, 1.3199e+00],\n",
      "          [1.8859e-01, 1.7147e-01, 0.0000e+00,  ..., 8.5952e-01,\n",
      "           1.5747e+00, 4.2516e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 5.2969e-01,  ..., 1.8497e+00,\n",
      "           2.2868e+00, 3.9772e-01],\n",
      "          [9.7275e-01, 1.0760e+00, 0.0000e+00,  ..., 3.2326e-01,\n",
      "           1.8330e+00, 2.4525e-01],\n",
      "          [2.2608e+00, 0.0000e+00, 0.0000e+00,  ..., 1.3154e+00,\n",
      "           2.3085e+00, 2.8050e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.9821e-01,\n",
      "           0.0000e+00, 1.8914e-01],\n",
      "          [7.2871e-01, 1.4006e+00, 1.0165e+00,  ..., 1.1331e+00,\n",
      "           1.8690e+00, 2.8507e-01],\n",
      "          [1.1820e+00, 2.0929e+00, 1.3800e+00,  ..., 1.4237e+00,\n",
      "           3.2993e+00, 1.0730e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 2.4928e+00, 1.3185e+00,  ..., 1.8250e+00,\n",
      "           2.7005e+00, 2.0297e-01],\n",
      "          [0.0000e+00, 1.8784e+00, 1.5659e+00,  ..., 7.7421e-01,\n",
      "           2.4107e+00, 0.0000e+00],\n",
      "          [2.6751e+00, 2.3426e+00, 6.7469e-01,  ..., 7.3109e-01,\n",
      "           9.5370e-01, 0.0000e+00]],\n",
      "\n",
      "         [[3.8635e-01, 8.3423e-02, 1.1136e+00,  ..., 2.3759e-01,\n",
      "           1.1809e-01, 1.8162e+00],\n",
      "          [7.8638e-01, 5.5208e-01, 3.0313e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.1639e-02],\n",
      "          [0.0000e+00, 2.7343e-01, 9.1749e-01,  ..., 3.9582e-02,\n",
      "           0.0000e+00, 2.0195e-01],\n",
      "          ...,\n",
      "          [9.2660e-01, 2.3398e-02, 9.0387e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 6.9933e-01],\n",
      "          [5.0039e-01, 9.0985e-03, 2.5004e-01,  ..., 7.2766e-01,\n",
      "           4.0943e-01, 1.8414e+00],\n",
      "          [1.5228e+00, 7.6359e-01, 7.8077e-01,  ..., 1.6130e+00,\n",
      "           6.9606e-01, 1.3527e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 8.8371e-01,\n",
      "           1.3167e+00, 4.0743e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 9.1982e-01],\n",
      "          [3.5747e-01, 0.0000e+00, 3.2874e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 8.1715e-01],\n",
      "          ...,\n",
      "          [1.2364e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 4.4681e-01],\n",
      "          [9.4816e-01, 7.9220e-01, 1.1583e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.7075e+00, 2.7400e+00, 2.4086e+00,  ..., 1.2560e+00,\n",
      "           0.0000e+00, 1.8080e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.9579e+00, 1.7007e+00, 1.4531e+00,  ..., 1.1075e+00,\n",
      "           1.3913e+00, 1.3748e+00],\n",
      "          [0.0000e+00, 5.1626e-01, 4.0831e-01,  ..., 0.0000e+00,\n",
      "           2.5667e-03, 2.8489e+00],\n",
      "          [9.6679e-01, 5.2245e-01, 1.5114e-02,  ..., 9.6058e-01,\n",
      "           0.0000e+00, 1.5635e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 9.5164e-01, 2.3170e-01,  ..., 1.1801e+00,\n",
      "           0.0000e+00, 8.6320e-01],\n",
      "          [2.5245e-01, 1.6459e-02, 5.1467e-01,  ..., 1.9603e+00,\n",
      "           9.1745e-01, 1.0363e+00],\n",
      "          [5.5934e-01, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 9.4185e-01]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.5589e-01, 0.0000e+00],\n",
      "          [1.0996e+00, 2.0734e+00, 0.0000e+00,  ..., 3.1563e+00,\n",
      "           2.1000e+00, 0.0000e+00],\n",
      "          [9.9872e-01, 1.2796e+00, 0.0000e+00,  ..., 2.0622e+00,\n",
      "           2.1669e+00, 0.0000e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 5.6061e-01, 0.0000e+00,  ..., 6.1899e-01,\n",
      "           3.0671e-02, 0.0000e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 7.6560e-01,  ..., 1.3502e+00,\n",
      "           2.3952e+00, 7.7774e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.1173e-01,\n",
      "           3.3139e-01, 0.0000e+00]],\n",
      "\n",
      "         [[1.2892e+00, 2.3434e-01, 1.5076e-01,  ..., 2.5034e-02,\n",
      "           1.8168e-01, 0.0000e+00],\n",
      "          [3.1969e-01, 1.2343e+00, 4.2669e-01,  ..., 3.2773e+00,\n",
      "           3.0184e+00, 1.5356e+00],\n",
      "          [0.0000e+00, 2.5196e-01, 6.6193e-01,  ..., 3.4408e-01,\n",
      "           8.4163e-01, 6.5719e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.1836e+00,\n",
      "           2.0470e+00, 1.7597e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 9.6951e-02,\n",
      "           1.0534e+00, 7.8189e-01],\n",
      "          [1.0624e+00, 1.7172e+00, 2.7749e+00,  ..., 4.7705e-01,\n",
      "           9.4955e-01, 2.5222e+00]]],\n",
      "\n",
      "\n",
      "        [[[0.0000e+00, 0.0000e+00, 6.6598e-01,  ..., 3.3185e-01,\n",
      "           6.6963e-01, 2.3411e-01],\n",
      "          [8.3520e-01, 1.6828e+00, 1.9466e+00,  ..., 6.6736e-01,\n",
      "           6.3600e-01, 7.7306e-01],\n",
      "          [1.7309e+00, 2.0241e+00, 2.0212e+00,  ..., 1.2520e+00,\n",
      "           1.9638e+00, 1.1038e+00],\n",
      "          ...,\n",
      "          [1.0962e+00, 3.1304e+00, 3.7256e+00,  ..., 2.9695e+00,\n",
      "           1.6563e+00, 4.8326e-01],\n",
      "          [1.2020e+00, 2.9264e+00, 2.5541e+00,  ..., 4.0035e+00,\n",
      "           2.0729e+00, 9.5447e-02],\n",
      "          [1.6708e+00, 1.2964e+00, 1.3532e+00,  ..., 1.2950e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[3.9758e-01, 3.8672e-01, 9.6674e-01,  ..., 5.6050e-01,\n",
      "           1.0900e+00, 2.0046e+00],\n",
      "          [1.3668e+00, 3.1560e-01, 5.2853e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 2.0614e-01],\n",
      "          [2.3666e-01, 0.0000e+00, 6.4244e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 1.3487e-01],\n",
      "          ...,\n",
      "          [1.3319e+00, 0.0000e+00, 1.4583e-01,  ..., 3.4266e-01,\n",
      "           0.0000e+00, 1.6025e+00],\n",
      "          [6.4536e-01, 7.2431e-01, 1.2163e+00,  ..., 1.5326e+00,\n",
      "           4.8700e-01, 2.2418e+00],\n",
      "          [3.7423e+00, 2.6993e+00, 1.1945e+00,  ..., 1.7845e+00,\n",
      "           2.1897e-01, 1.4630e+00]],\n",
      "\n",
      "         [[1.6849e-01, 0.0000e+00, 0.0000e+00,  ..., 8.1851e-01,\n",
      "           1.0991e+00, 1.0074e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           1.8909e-01, 2.1004e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 1.7399e-01,  ..., 4.8007e-01,\n",
      "           1.4690e+00, 1.7081e+00],\n",
      "          ...,\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 8.1854e-01],\n",
      "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 5.6300e-01,\n",
      "           7.2263e-01, 3.8973e-01],\n",
      "          [2.4688e+00, 1.8439e+00, 1.6260e-01,  ..., 2.4167e+00,\n",
      "           1.8141e+00, 2.0459e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[1.6095e+00, 1.1761e+00, 1.3945e+00,  ..., 1.0082e+00,\n",
      "           1.1632e+00, 1.5418e+00],\n",
      "          [0.0000e+00, 1.0418e-01, 5.2166e-01,  ..., 0.0000e+00,\n",
      "           2.1429e-01, 2.9079e+00],\n",
      "          [1.4408e+00, 6.0694e-01, 0.0000e+00,  ..., 1.0802e+00,\n",
      "           0.0000e+00, 2.5561e+00],\n",
      "          ...,\n",
      "          [2.5529e+00, 1.2926e+00, 1.0693e+00,  ..., 1.8856e+00,\n",
      "           9.1371e-02, 9.3659e-01],\n",
      "          [3.1281e+00, 1.7878e+00, 1.4739e+00,  ..., 6.6433e-01,\n",
      "           2.4140e-01, 6.5232e-01],\n",
      "          [2.1749e+00, 8.9431e-01, 0.0000e+00,  ..., 9.7377e-01,\n",
      "           4.4108e-01, 1.8285e+00]],\n",
      "\n",
      "         [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.0599e+00, 3.2040e+00, 1.0083e+00,  ..., 2.1999e+00,\n",
      "           5.1788e-01, 0.0000e+00],\n",
      "          [1.7353e+00, 2.1167e+00, 7.5437e-01,  ..., 1.2372e+00,\n",
      "           6.2971e-01, 0.0000e+00],\n",
      "          ...,\n",
      "          [4.2479e-01, 2.6960e+00, 2.0467e+00,  ..., 1.9862e+00,\n",
      "           1.2845e+00, 0.0000e+00],\n",
      "          [1.9339e+00, 2.6609e+00, 2.3196e+00,  ..., 1.2603e+00,\n",
      "           1.5850e+00, 0.0000e+00],\n",
      "          [2.0029e+00, 2.4791e+00, 1.4765e+00,  ..., 1.2814e+00,\n",
      "           0.0000e+00, 0.0000e+00]],\n",
      "\n",
      "         [[1.3493e+00, 9.3334e-01, 1.6786e-01,  ..., 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [7.1497e-01, 1.6526e+00, 7.8359e-01,  ..., 1.9699e+00,\n",
      "           1.5443e+00, 1.2264e+00],\n",
      "          [0.0000e+00, 0.0000e+00, 6.3673e-01,  ..., 6.5850e-01,\n",
      "           1.3146e+00, 4.6182e-01],\n",
      "          ...,\n",
      "          [0.0000e+00, 5.9811e-01, 1.2859e+00,  ..., 1.6119e+00,\n",
      "           1.7885e+00, 8.0911e-01],\n",
      "          [0.0000e+00, 3.3645e-02, 1.9581e-01,  ..., 2.1108e+00,\n",
      "           1.0447e+00, 4.4408e-02],\n",
      "          [1.4530e+00, 0.0000e+00, 1.4208e+00,  ..., 2.3321e+00,\n",
      "           1.2154e+00, 2.0882e+00]]]], device='cuda:0',\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "global res\n",
    "print(res.size())\n",
    "print(res)\n",
    "\n",
    "# torchvision.utils.make_grid(res)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "for i in range (0,128):\n",
    "    z = res[i]\n",
    "    ax.plot_surface(z.cpu().detach().numpy()[0],z.cpu().detach().numpy()[1],z.cpu().detach().numpy()[2],cmap='rainbow')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycx-VExsLDoL"
   },
   "outputs": [],
   "source": [
    "# visualize the first conv layer filters\n",
    "def virtualize(color):\n",
    "  plt.figure(figsize=(20, 17))\n",
    "  for i, filter in enumerate(first_filter):\n",
    "    # (4, 4) because in conv0 we have 3x3 filters and total of 16 (see printed shapes)\n",
    "    plt.subplot(4, 4, i+1) \n",
    "    plt.imshow(filter[0, :, :].cpu().detach(), cmap=color)\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "id": "GX7ifIQyuYJ4",
    "outputId": "06022baf-d5a8-4407-e2f0-f0527eb94bb1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1224 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "virtualize(\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 955
    },
    "id": "HdC5u9Bfua9w",
    "outputId": "da60021d-f172-47bc-c4af-9c3ac6b8dcdb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1224 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "virtualize(\"rainbow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVwQF-wIFExn"
   },
   "source": [
    "# Task 3\n",
    "Is deeper always better? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0Lvd6Y0FKC7"
   },
   "source": [
    "The accuracy will be reduced sometimes. Observed that in the 45th epoch, the accuracy has following changes: 92.5% --> 92.4% --> 92.5% --> 92.7% --> 92.4%.\n",
    "Arround 50th epoch, the accuracy fluctuates between 94% and 95%. When acc approches 90%, the increasing rate will much slower compared to the beginning of training. Sometimes when the network comes deeper, the phenomenon degradation will happen(loss will be increased which is actually not overfitting because overfitting leads to decreasing of loss) and the gradient will be closer to 0."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN-ResNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0446944c23cb48b08cd1e0d270478a5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_759886e77ad941cd8ebc9b3d33311fb2",
       "IPY_MODEL_8cb2a46ee9044db6b2f1aba1b5d01f1f"
      ],
      "layout": "IPY_MODEL_494eb3708e364fabb989d364d8c2d1d9"
     }
    },
    "494eb3708e364fabb989d364d8c2d1d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fdb7a3f28514830ab18df59dcbb19a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67f97d835c6d46648af2cfb703882ca0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "759886e77ad941cd8ebc9b3d33311fb2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67f97d835c6d46648af2cfb703882ca0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c7d5e01911ac4a8c974ac2e66902de11",
      "value": 1
     }
    },
    "8cb2a46ee9044db6b2f1aba1b5d01f1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93163ac16ca14b1e8870852b67209f12",
      "placeholder": "​",
      "style": "IPY_MODEL_4fdb7a3f28514830ab18df59dcbb19a9",
      "value": " 170500096/? [00:20&lt;00:00, 51430402.28it/s]"
     }
    },
    "93163ac16ca14b1e8870852b67209f12": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7d5e01911ac4a8c974ac2e66902de11": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
