{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZdvSQOoiI14"
   },
   "source": [
    "# Text Generation with RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNInpv8pbBll",
    "outputId": "897f7902-8c11-48e8-abb5-df90b32302c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2bNHI95GiN86"
   },
   "source": [
    "### 1 Dataset\n",
    "Define the path of the file, you want to read and train the model on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eN7ESM2VkPTg"
   },
   "source": [
    "We have attach the text file in zip, if you also use colab, then you should upload the text file as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "twi2Oez5bWEL"
   },
   "outputs": [],
   "source": [
    "with open('./poetry.txt', 'r') as f:\n",
    "    poetry_corpus = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dO5cz2f1iedK"
   },
   "source": [
    "\n",
    "#### Inspect the dataset\n",
    "Take a look at the first 250 characters in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "haXm0ExqbZ7C",
    "outputId": "f08d6d46-ca1c-49b6-b964-26c0fe707082"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'寒随穷律变，春逐鸟声开。\\n初风飘带柳，晚雪间花梅。\\n碧林青旧竹，绿沼翠新苔。\\n芝田初雁去，绮树巧莺来。\\n晚霞聊自怡，初晴弥可喜。\\n日晃百花色，风动千林翠。\\n池鱼跃不同，园鸟声还异。\\n寄言博通者，知予物'"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poetry_corpus[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zleJg_iHbcqj",
    "outputId": "72318650-a356-4359-f912-4f9d78fe960d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1516944"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poetry_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5co_hqgHmass"
   },
   "source": [
    "Replace/remove all chinese punctuations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "BWDOoImtberM",
    "outputId": "5554f4c0-b602-4bc6-98d9-799250ec71c2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'寒随穷律变 春逐鸟声开  初风飘带柳 晚雪间花梅  碧林青旧竹 绿沼翠新苔  芝田初雁去 绮树巧莺来  晚霞聊自怡 初晴弥可喜  日晃百花色 风动千林翠  池鱼跃不同 园鸟声还异  寄言博通者 知予物'"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poetry_corpus = poetry_corpus.replace('\\n', ' ').replace('\\r', ' ').replace('，', ' ').replace('。', ' ')\n",
    "poetry_corpus[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgXob0iCimQD"
   },
   "source": [
    "### 2 Process the dataset for the learning task\n",
    "The task that we want our model to achieve is: given a character, or a sequence of characters, what is the most probable next character?\n",
    "\n",
    "To achieve this, we will input a sequence of characters to the model, and train the model to predict the output, that is, the following character at each time step. RNNs maintain an internal state that depends on previously seen elements, so information about all characters seen up until a given moment will be taken into account in generating the prediction.\n",
    "\n",
    "#### Vectorize the text\n",
    "Before we begin training our RNN model, we'll need to create a numerical representation of our text-based dataset. To do this, we'll generate two lookup tables: one that maps characters to numbers, and a second that maps numbers back to characters. Recall that we just identified the unique characters present in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "N79FV1bfbh5A"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class TextConverter(object):\n",
    "    def __init__(self, text_path, max_vocab=5000):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            text_path: text position\n",
    "            max_vocab: max. # text\n",
    "        \"\"\"\n",
    "\n",
    "        with open(text_path, 'r') as f:\n",
    "            text = f.read()\n",
    "        text = text.replace('\\n', ' ').replace('\\r', ' ').replace('，', ' ').replace('。', ' ')\n",
    "        \n",
    "        # remove the repeated char\n",
    "        vocab = set(text)\n",
    "\n",
    "        # if # char more than max_vocab, remove those whose freqs are less.\n",
    "        vocab_count = {}\n",
    "\n",
    "        # compute freq\n",
    "        for word in vocab:\n",
    "            vocab_count[word] = 0\n",
    "        for word in text:\n",
    "            vocab_count[word] += 1\n",
    "        vocab_count_list = []\n",
    "        for word in vocab_count:\n",
    "            vocab_count_list.append((word, vocab_count[word]))\n",
    "        vocab_count_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if len(vocab_count_list) > max_vocab:\n",
    "            vocab_count_list = vocab_count_list[:max_vocab]\n",
    "        vocab = [x[0] for x in vocab_count_list]\n",
    "        self.vocab = vocab\n",
    "\n",
    "        self.word_to_int_table = {c: i for i, c in enumerate(self.vocab)}\n",
    "        self.int_to_word_table = dict(enumerate(self.vocab))\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.vocab) + 1\n",
    "\n",
    "    def word_to_int(self, word):\n",
    "        if word in self.word_to_int_table:\n",
    "            return self.word_to_int_table[word]\n",
    "        else:\n",
    "            return len(self.vocab)\n",
    "\n",
    "    def int_to_word(self, index):\n",
    "        if index == len(self.vocab):\n",
    "            return '<unk>'\n",
    "        elif index < len(self.vocab):\n",
    "            return self.int_to_word_table[index]\n",
    "        else:\n",
    "            raise Exception('Unknown index!')\n",
    "\n",
    "    def text_to_arr(self, text):\n",
    "        arr = []\n",
    "        for word in text:\n",
    "            arr.append(self.word_to_int(word))\n",
    "        return np.array(arr)\n",
    "\n",
    "    def arr_to_text(self, arr):\n",
    "        words = []\n",
    "        for index in arr:\n",
    "            words.append(self.int_to_word(index))\n",
    "        return \"\".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "nnwkxXHZbkNh"
   },
   "outputs": [],
   "source": [
    "convert = TextConverter('./poetry.txt', max_vocab=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gva4ecM7iuBf"
   },
   "source": [
    "\n",
    "This gives us an integer representation for each character. Observe that the unique characters (i.e., our vocabulary) in the text are mapped as indices from 0 to len(unique). Let's take a peek at this numerical representation of our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9-_SMa6boPL",
    "outputId": "17fbc1af-f825-4123-dcde-cea70ffa4628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寒随穷律变 春逐鸟声开\n",
      "[ 38 173 350 901 573   0  11 390 107  56  86]\n"
     ]
    }
   ],
   "source": [
    "# orginal char(poetry)\n",
    "txt_char = poetry_corpus[:11]\n",
    "print(txt_char)\n",
    "\n",
    "# convert to integers\n",
    "# We can also look at how the first part of the text is mapped to an integer representation\n",
    "print(convert.text_to_arr(txt_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N54nDRTrbqtj",
    "outputId": "d34b6d00-83d0-4941-ab76-55cb7524bfd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75847\n"
     ]
    }
   ],
   "source": [
    "n_step = 20\n",
    "\n",
    "# length of the given sequence\n",
    "num_seq = int(len(poetry_corpus) / n_step)\n",
    "\n",
    "text = poetry_corpus[:num_seq*n_step]\n",
    "\n",
    "print(num_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXRt5pypjBfL"
   },
   "source": [
    "#### Defining a method to encode one hot labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Yzs1mXcsi-WD"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(arr, n_labels):\n",
    "    # Initialize the the encoded array\n",
    "    one_hot = np.zeros((np.multiply(*arr.shape), n_labels), dtype=np.float32)\n",
    "\n",
    "    # Fill the appropriate elements with ones\n",
    "    one_hot[np.arange(one_hot.shape[0]), arr.flatten()] = 1.\n",
    "\n",
    "    # Finally reshape it to get back to the original array\n",
    "    one_hot = one_hot.reshape((*arr.shape, n_labels))\n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Sa3BjHFjJjv"
   },
   "source": [
    "#### Defining a method to make mini-batches for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "BLmDJgPUjFXq"
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, batch_size, seq_length):\n",
    "    '''Create a generator that returns batches of size\n",
    "       batch_size x seq_length from arr.\n",
    "\n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       batch_size: Batch size, the number of sequences per batch\n",
    "       seq_length: Number of encoded chars in a sequence\n",
    "    '''\n",
    "\n",
    "    batch_size_total = batch_size * seq_length\n",
    "    # total number of batches we can make\n",
    "    n_batches = len(arr) // batch_size_total\n",
    "\n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:n_batches * batch_size_total]\n",
    "    # Reshape into batch_size rows\n",
    "    arr = arr.reshape((batch_size, -1))\n",
    "\n",
    "    # iterate through the array, one sequence at a time\n",
    "    for n in range(0, arr.shape[1], seq_length):\n",
    "        # The features\n",
    "        x = arr[:, n:n + seq_length]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        try:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, n + seq_length]\n",
    "        except IndexError:\n",
    "            y[:, :-1], y[:, -1] = x[:, 1:], arr[:, 0]\n",
    "        yield x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ndVW132YbsTC",
    "outputId": "dcce0dae-e551-4d9b-d277-10772e347be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([75847, 20])\n",
      "tensor([ 38, 173, 350, 901, 573,   0,  11, 390, 107,  56,  86,   0,   0, 157,\n",
      "          4, 435, 292, 190,   0, 132])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "arr = convert.text_to_arr(text)\n",
    "arr = arr.reshape((num_seq, -1))\n",
    "arr = torch.from_numpy(arr)\n",
    "\n",
    "print(arr.shape)\n",
    "print(arr[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "d09p_OHDbx1z"
   },
   "outputs": [],
   "source": [
    "class TextDataset(object):\n",
    "    def __init__(self, arr):\n",
    "        self.arr = arr\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        x = self.arr[item, :]\n",
    "\n",
    "        # construct label\n",
    "        y = torch.zeros(x.shape)\n",
    "        \n",
    "        # Use the first character entered as the label for the last input\n",
    "        y[:-1], y[-1] = x[1:], x[0]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "xFDy83kcbz1y"
   },
   "outputs": [],
   "source": [
    "train_set = TextDataset(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mb7WIimBb1mO",
    "outputId": "a2a4d7e6-8d8d-46b2-8ee4-491d02d8e873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寒随穷律变 春逐鸟声开  初风飘带柳 晚\n",
      "随穷律变 春逐鸟声开  初风飘带柳 晚寒\n"
     ]
    }
   ],
   "source": [
    "x, y = train_set[0]\n",
    "print(convert.arr_to_text(x.numpy()))\n",
    "print(convert.arr_to_text(y.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFJINnkxjP1O"
   },
   "source": [
    "### 3 The Recurrent Neural Network (RNN) model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0O6gaTzHjjnU"
   },
   "source": [
    "Declaring the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "DHt03uM-b4GC"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "use_gpu = True\n",
    "\n",
    "class VanillaCharRNN(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim, hidden_size, \n",
    "                 num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.word_to_vec = nn.Embedding(num_classes, embed_dim)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_size, num_layers)\n",
    "        self.project = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, hs=None):\n",
    "        batch = x.shape[0]\n",
    "        if hs is None:\n",
    "            hs = Variable(\n",
    "                torch.zeros(self.num_layers, batch, self.hidden_size))\n",
    "            if use_gpu:\n",
    "                hs = hs.cuda()\n",
    "        word_embed = self.word_to_vec(x)  # (batch, len, embed)\n",
    "        word_embed = word_embed.permute(1, 0, 2)  # (len, batch, embed)\n",
    "        out, h0 = self.rnn(word_embed, hs)  # (len, batch, hidden)\n",
    "        le, mb, hd = out.shape\n",
    "        out = out.view(le * mb, hd)\n",
    "        out = self.project(out)\n",
    "        out = out.view(le, mb, -1)\n",
    "        out = out.permute(1, 0, 2).contiguous()  # (batch, len, hidden)\n",
    "        return out.view(-1, out.shape[2]), h0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBG_gz1QhVXw"
   },
   "source": [
    "Declaring the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "y3XqQSjIb6EX"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "train_data = DataLoader(train_set, batch_size, True, num_workers=4)\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuU5DikKhokT"
   },
   "source": [
    "Define and print the net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2p2imIQjfIU"
   },
   "source": [
    "\n",
    "###### Check if GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmO-IKa5b8Dy",
    "outputId": "a28b4f68-a42b-4f4f-c943-8bc7a710e16a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaCharRNN(\n",
      "  (word_to_vec): Embedding(5386, 512)\n",
      "  (rnn): GRU(512, 512, num_layers=2)\n",
      "  (project): Linear(in_features=512, out_features=5386, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = VanillaCharRNN(convert.vocab_size, 512, 512, 2, 0.5)\n",
    "if use_gpu:\n",
    "    model = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "basic_optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "optimizer = basic_optimizer\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiPKZ_dIj4Sx"
   },
   "source": [
    "\n",
    "#### Declaring the train method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "faAN1mfJcC-v",
    "outputId": "c318e25d-e85b-42b4-afbf-ab3eb437ccc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, perplexity is: 248.098\n",
      "epoch: 2, perplexity is: 127.901\n",
      "epoch: 3, perplexity is: 80.512\n",
      "epoch: 4, perplexity is: 57.031\n",
      "epoch: 5, perplexity is: 42.753\n",
      "epoch: 6, perplexity is: 33.407\n",
      "epoch: 7, perplexity is: 26.851\n",
      "epoch: 8, perplexity is: 22.089\n",
      "epoch: 9, perplexity is: 18.595\n",
      "epoch: 10, perplexity is: 15.899\n",
      "epoch: 11, perplexity is: 13.847\n",
      "epoch: 12, perplexity is: 12.250\n",
      "epoch: 13, perplexity is: 10.991\n",
      "epoch: 14, perplexity is: 9.964\n",
      "epoch: 15, perplexity is: 9.123\n",
      "epoch: 16, perplexity is: 8.420\n",
      "epoch: 17, perplexity is: 7.858\n",
      "epoch: 18, perplexity is: 7.379\n",
      "epoch: 19, perplexity is: 6.963\n",
      "epoch: 20, perplexity is: 6.608\n"
     ]
    }
   ],
   "source": [
    "for e in range(epochs):\n",
    "    train_loss = 0\n",
    "    for data in train_data:\n",
    "        x, y = data\n",
    "        y = y.long()\n",
    "        if use_gpu:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        x, y = Variable(x), Variable(y)\n",
    "\n",
    "        # Forward.\n",
    "        score, _ = model(x)\n",
    "        loss = criterion(score, y.view(-1))\n",
    "\n",
    "        # Backward.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # Clip gradient.\n",
    "        nn.utils.clip_grad_norm(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "    print('epoch: {}, perplexity is: {:.3f}'.format(e+1, np.exp(train_loss / len(train_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Zj_e4TXkCEj"
   },
   "source": [
    "\n",
    "##### Defining a method to generate the next character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hsaBy-HCnF5V"
   },
   "outputs": [],
   "source": [
    "def predict(model, char, h=None, top_k=None):\n",
    "    ''' Given a character, predict the next character.\n",
    "        Returns the predicted character and the hidden state.\n",
    "    '''\n",
    "\n",
    "    # tensor inputs\n",
    "    x = np.array([[char2idx[char]]])\n",
    "    x = one_hot_encode(x, len(model.vocab))\n",
    "    inputs = torch.from_numpy(x)\n",
    "\n",
    "    if (train_on_gpu):\n",
    "        inputs = inputs.cuda()\n",
    "\n",
    "    # detach hidden state from history\n",
    "    h = tuple([each.data for each in h])\n",
    "    '''TODO: feed the current input into the model and generate output'''\n",
    "    output, h = model('''TODO''') # TODO\n",
    "\n",
    "    # get the character probabilities\n",
    "    p = F.softmax(out, dim=1).data\n",
    "    if (train_on_gpu):\n",
    "        p = p.cpu()  # move to cpu\n",
    "\n",
    "    # get top characters\n",
    "    if top_k is None:\n",
    "        top_ch = np.arange(len(model.vocab))\n",
    "    else:\n",
    "        p, top_ch = p.topk(top_k)\n",
    "        top_ch = top_ch.numpy().squeeze()\n",
    "\n",
    "    # select the likely next character with some element of randomness\n",
    "    p = p.numpy().squeeze()\n",
    "    char = np.random.choice(top_ch, p=p / p.sum())\n",
    "\n",
    "    # return the encoded value of the predicted char and the hidden state\n",
    "    return idx2char[char], h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "4AsXDwDrcE5T"
   },
   "outputs": [],
   "source": [
    "def predict(preds, top_n=5):\n",
    "    top_pred_prob, top_pred_label = torch.topk(preds, top_n, 1)\n",
    "    top_pred_prob /= torch.sum(top_pred_prob)\n",
    "    top_pred_prob = top_pred_prob.squeeze(0).cpu().numpy()\n",
    "    top_pred_label = top_pred_label.squeeze(0).cpu().numpy()\n",
    "    c = np.random.choice(top_pred_label, size=1, p=top_pred_prob)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bP24Rj9ah0aC"
   },
   "source": [
    "**Declaring to generate new text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYxiTs7zcG9L",
    "outputId": "e7010567-acc0-48ca-9af1-da63a04b161c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9416, -0.9998, -0.9980,  ..., -0.9998,  0.7702, -0.9505]],\n",
      "\n",
      "        [[-0.9991, -0.9974,  1.0000,  ..., -0.2473, -0.7346, -0.7575]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9419, -0.9999, -0.2492,  ...,  0.0621,  0.7704, -0.9597]],\n",
      "\n",
      "        [[-0.9903, -0.9997,  0.9999,  ...,  1.0000,  0.3231, -0.7575]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9420, -1.0000,  0.8979,  ..., -0.9992,  0.7701, -0.9598]],\n",
      "\n",
      "        [[-0.9973, -1.0000,  1.0000,  ...,  1.0000,  0.9668, -0.7575]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9420, -0.9738, -0.9495,  ..., -1.0000,  0.7692, -0.9597]],\n",
      "\n",
      "        [[-0.9459, -0.9915,  0.6617,  ...,  1.0000,  0.9421, -0.7575]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9459, -0.9734, -0.9495,  ..., -0.9916, -0.1108, -0.9437]],\n",
      "\n",
      "        [[-0.2516,  0.9996, -0.9091,  ...,  1.0000, -0.5957, -0.7576]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9732,  0.9981, -0.9464,  ...,  0.9995, -0.9281, -1.0000]],\n",
      "\n",
      "        [[-0.7798,  0.9937, -0.7657,  ..., -0.2899, -0.9736, -0.9366]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9480,  0.9471, -0.9462,  ..., -0.5523,  0.0347, -0.9520]],\n",
      "\n",
      "        [[ 0.5620, -0.0736,  0.9983,  ..., -0.0291, -0.9587, -0.8756]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9722, -0.2526,  0.9975,  ...,  0.6727, -0.0845, -0.9986]],\n",
      "\n",
      "        [[-0.5102, -0.9752,  0.9598,  ..., -0.9709, -0.8095, -0.9189]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-1.0000, -0.9393,  1.0000,  ..., -0.9999, -0.9955, -0.9986]],\n",
      "\n",
      "        [[ 0.9964,  0.0678,  0.2757,  ...,  1.0000, -0.9978, -0.9617]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-1.0000, -0.9994, -0.9681,  ..., -1.0000, -0.9996, -0.9986]],\n",
      "\n",
      "        [[-0.9753, -0.8927, -0.2596,  ...,  1.0000, -1.0000, -0.9633]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-1.0000, -0.9750, -0.9699,  ..., -1.0000, -0.9995, -0.9986]],\n",
      "\n",
      "        [[ 0.5340,  0.9985, -0.9641,  ...,  1.0000, -0.9999, -0.9633]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9998, -0.9794, -0.9464,  ..., -0.9271, -0.9385, -0.9932]],\n",
      "\n",
      "        [[-0.9998, -0.7872, -0.4005,  ...,  0.7981, -0.9978, -0.9633]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9443, -0.9975, -0.9803,  ..., -0.8513, -0.5364,  0.9832]],\n",
      "\n",
      "        [[-1.0000, -0.5922,  0.7841,  ..., -0.5873,  0.9988, -0.9634]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9441,  0.9363, -0.9783,  ...,  0.9896,  0.9630,  0.9822]],\n",
      "\n",
      "        [[-0.9642, -1.0000,  1.0000,  ..., -0.9722,  0.9648,  0.7468]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9483,  0.9999,  0.9726,  ...,  0.9997, -0.9976,  0.9820]],\n",
      "\n",
      "        [[-0.7303,  0.0692, -1.0000,  ..., -0.9180,  0.9990,  0.7473]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9891, -0.0350,  0.9999,  ...,  0.9591, -0.9956,  0.9673]],\n",
      "\n",
      "        [[-0.9984, -0.9933, -0.8203,  ...,  0.9917,  0.9988,  0.7478]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9891, -0.9848, -0.5915,  ..., -0.8657, -0.9992,  0.9668]],\n",
      "\n",
      "        [[-0.9960, -1.0000, -0.6871,  ...,  1.0000,  0.9988,  0.7474]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9888,  0.9288,  0.8970,  ..., -0.7224, -0.9992,  0.9668]],\n",
      "\n",
      "        [[-1.0000, -1.0000,  0.9884,  ...,  1.0000,  0.3770,  0.7482]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9888,  0.9226, -0.9231,  ..., -0.9394, -0.9986,  0.9667]],\n",
      "\n",
      "        [[-0.9998, -0.9812,  0.0364,  ...,  1.0000,  0.3770,  0.7482]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9888,  0.8887, -0.9131,  ..., -0.9380,  0.0694,  0.1559]],\n",
      "\n",
      "        [[-0.9954, -0.9997, -1.0000,  ...,  1.0000,  0.3966,  0.7481]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9889,  0.8884, -0.3538,  ..., -0.9380,  0.4976,  0.1553]],\n",
      "\n",
      "        [[-0.9919, -0.9812, -1.0000,  ..., -0.9975,  0.4168,  0.7481]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.7535,  0.9046, -0.3533,  ...,  0.0396,  0.9949,  0.1461]],\n",
      "\n",
      "        [[-0.9858, -0.9971, -1.0000,  ..., -0.9984,  0.5227,  0.7490]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.7567,  0.9045,  0.9278,  ..., -0.4027,  0.9232,  0.1461]],\n",
      "\n",
      "        [[-0.4488, -0.9984, -1.0000,  ...,  0.5115,  0.9928,  0.7965]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.8663,  0.8609,  0.9188,  ..., -0.9517,  0.7077,  0.1318]],\n",
      "\n",
      "        [[-1.0000, -0.9996, -1.0000,  ...,  0.9997,  0.9769,  0.7965]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.8666,  0.8608, -0.9099,  ..., -1.0000, -0.2667,  0.1203]],\n",
      "\n",
      "        [[-1.0000, -1.0000, -1.0000,  ...,  1.0000,  0.9753,  0.7965]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.8691,  0.5992, -0.9099,  ..., -0.9912, -0.9263, -0.8230]],\n",
      "\n",
      "        [[-0.9775, -0.8856, -1.0000,  ...,  1.0000,  0.6730,  0.7963]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.8455,  0.9404, -0.9086,  ...,  0.9864,  1.0000, -0.9996]],\n",
      "\n",
      "        [[-0.9998, -1.0000,  0.4514,  ..., -1.0000,  0.9983,  0.9327]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.8092,  0.9970, -0.9086,  ...,  0.9933, -0.0206, -0.9997]],\n",
      "\n",
      "        [[ 0.9846, -0.9953, -0.9739,  ..., -1.0000,  0.9985,  0.9327]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9839,  0.8221,  0.4116,  ..., -0.8939, -0.9274, -0.9997]],\n",
      "\n",
      "        [[-0.1342, -0.9951, -1.0000,  ..., -0.9831, -0.4810,  0.9468]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "tensor([[[-0.9841,  0.6946, -0.9928,  ..., -0.9927, -0.9965, -0.9997]],\n",
      "\n",
      "        [[-0.7892, -0.9995, -0.9998,  ...,  0.8439, -0.7275,  0.9468]]],\n",
      "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
      "Generate text is: 天青色等烟雨来游  自昔重城外 犹教白日芜生幻 逢天花天山  白波天天地\n"
     ]
    }
   ],
   "source": [
    "begin = '天青色等烟雨'\n",
    "text_len = 30\n",
    "\n",
    "model = model.eval()\n",
    "samples = [convert.word_to_int(c) for c in begin]\n",
    "input_txt = torch.LongTensor(samples)[None]\n",
    "if use_gpu:\n",
    "  input_txt = input_txt.cuda()\n",
    "input_txt = Variable(input_txt)\n",
    "_, init_state = model(input_txt)\n",
    "result = samples\n",
    "model_input = input_txt[:, -1][:, None]\n",
    "for i in range(text_len):\n",
    "  # Get the predicted character and the hidden state. \n",
    "  out, init_state = model(model_input, init_state)\n",
    "  print(init_state)\n",
    "  pred = predict(out.data)\n",
    "  model_input = Variable(torch.LongTensor(pred))[None]\n",
    "  if use_gpu:\n",
    "      model_input = model_input.cuda()\n",
    "  result.append(pred[0])\n",
    "text = convert.arr_to_text(result)\n",
    "print('Generate text is: {}'.format(text))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
