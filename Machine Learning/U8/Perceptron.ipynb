{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3cWwlbatGdm"
   },
   "source": [
    "# Mustererkennung/Machine Learning - Assignment 8\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T12:46:51.443420Z",
     "start_time": "2018-12-11T12:46:50.570749Z"
    },
    "id": "luPsF5SptGdt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T12:46:51.501147Z",
     "start_time": "2018-12-11T12:46:51.445163Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CpeeFeXKtGdu",
    "outputId": "cf860553-0831-4606-e3ca-81959af4ee2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3            4\n",
       "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
       "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
       "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
       "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
       "4  5.0  3.6  1.4  0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Classifier:\n",
    "    \n",
    "    def accuracy(self, labels, predictions):\n",
    "        return np.mean(labels == predictions)\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"./Data/iris.data\", header=None)\n",
    "data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WaByN8YtGdx"
   },
   "source": [
    "#### Splitting the data into training/test and according to their class memberships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-11T12:46:51.517929Z",
     "start_time": "2018-12-11T12:46:51.502925Z"
    },
    "id": "E2-w2GzqtGdy"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[list(range(4))], data[4], test_size=0.2, random_state=None, stratify=data[4])\n",
    "\n",
    "X_train_setosa = X_train[y_train=='Iris-setosa'].to_numpy()\n",
    "X_train_versicolor = X_train[y_train=='Iris-versicolor'].to_numpy()\n",
    "X_train_virginica = X_train[y_train=='Iris-virginica'].to_numpy()\n",
    "\n",
    "y_train_setosa = y_train[y_train=='Iris-setosa'].to_numpy()\n",
    "y_train_versicolor = y_train[y_train=='Iris-versicolor'].to_numpy()\n",
    "y_train_virginica = y_train[y_train=='Iris-virginica'].to_numpy()\n",
    "\n",
    "X_test_setosa_v_v = X_test.to_numpy()\n",
    "y_test_setosa_v_v = (y_test == 'Iris-setosa').astype(int).to_numpy()\n",
    "\n",
    "X_test_versicolor_virginica = X_test[y_test!='Iris-setosa'].to_numpy()\n",
    "y_test_versicolor_virginica = (y_test[y_test!='Iris-setosa'] == 'Iris-versicolor').astype(int).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_setosa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_setosa_v_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_setosa_v_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_versicolor_virginica.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1:  seperate Setosa from Versicolor and Virginica "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_norm(w_1, w_2):\n",
    "    return np.linalg.norm(w_1-w_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, w, theta):\n",
    "        self.w = w\n",
    "        self.theta = theta\n",
    "    \n",
    "    def fit(self, X_pos, X_neg, y_pos, y_neg):\n",
    "        # initialize the w\n",
    "        w_1 = np.mean(X_pos, 0)\n",
    "        \n",
    "        X_data = np.concatenate((X_pos, X_neg), axis=0)\n",
    "        \n",
    "        n_data = X_data.shape[0]\n",
    "        n_pos = X_pos.shape[0]\n",
    "        \n",
    "        for i in range(10000): \n",
    "            \n",
    "            w = w_1\n",
    "            \n",
    "            index = np.random.randint(n_data)\n",
    "            v = X_data[index]\n",
    "            \n",
    "            if(index < n_pos and w.T @ v > 0):\n",
    "                continue\n",
    "            \n",
    "            if(index < n_pos and w.T @ v <= 0):\n",
    "                w_1 = w + v\n",
    "            \n",
    "            if(index >= n_pos and w.T @ v < 0):\n",
    "                continue\n",
    "            \n",
    "            if(index >= n_pos and w.T @ v >= 0):\n",
    "                w_1 = w - v\n",
    "            \n",
    "            if(sub_norm(w_1, w) <= self.theta):\n",
    "                break\n",
    "        self.w = w_1\n",
    "        \n",
    "    def calculate(self, v):\n",
    "        if(self.w.T @ v > 0):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def predict(self, X_data):\n",
    "        num = X_data.shape[0]\n",
    "        res = np.zeros(num)\n",
    "        \n",
    "        for i in range(num):\n",
    "            if(self.calculate(X_data[i]) == 1):\n",
    "                res[i] = 1\n",
    "                \n",
    "        return res\n",
    "        \n",
    "    def accuracy(self, labels, predictions):\n",
    "        return np.mean(labels == predictions)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(np.mean(X_train_setosa, 0),1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "perceptron.fit(X_train_setosa, np.concatenate((X_train_versicolor, X_train_virginica)), y_train_setosa, np.concatenate((y_train_versicolor, y_train_virginica)))\n",
    "predictions = perceptron.predict(X_test_setosa_v_v)\n",
    "print(perceptron.accuracy(y_test_setosa_v_v, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_vec(X_data, v):\n",
    "    for i in range(len(X_data)):\n",
    "        X_data[i] -= v\n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-19603a28d780>:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  X_test_versicolor = X_test[y_test=='Iris-versicolor']\n",
      "<ipython-input-24-19603a28d780>:2: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  y_test_versicolor = y_test[y_test=='Iris-versicolor']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n"
     ]
    }
   ],
   "source": [
    "X_test_versicolor = X_test[y_test=='Iris-versicolor']\n",
    "y_test_versicolor = y_test[y_test=='Iris-versicolor']\n",
    "\n",
    "temp = np.mean(X_train)\n",
    "\n",
    "perceptron.fit(sub_vec(X_train_versicolor, temp), sub_vec(X_train_virginica, temp),y_train_versicolor, y_train_virginica)\n",
    "predictions = perceptron.predict(X_test_versicolor_virginica)\n",
    "print(perceptron.accuracy(y_test_versicolor_virginica, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The problem while classifying Versicolor from Virginica__ is that all vector have positive projection on w so that with perceptron we can't get right separation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train = './Data/zip.train'\n",
    "path_to_test = './Data/zip.test'\n",
    "training_data = np.array(pd.read_csv(path_to_train, sep=' ', header=None))\n",
    "test_data = np.array(pd.read_csv(path_to_test, sep =' ',header=None))\n",
    "\n",
    "X_train, y_train = training_data[:,1:-1], training_data[:,0]\n",
    "X_test, y_test = test_data[:,1:], test_data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7291, 256)\n",
      "(2007, 256)\n",
      "(7291,)\n",
      "(2007,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    '''\n",
    "    depth's shape: d(constant)   n_neuron's shape 1*d\n",
    "    '''\n",
    "    def __init__(self, depth, n_neuron):\n",
    "        self.depth = depth\n",
    "        self.n_neuron = n_neuron\n",
    "        \n",
    "        self.input = []\n",
    "        self.weight = []\n",
    "        self.b = []\n",
    "        \n",
    "    def init_value(self, X_data):\n",
    "        # 256 * 1\n",
    "        before = X_data.shape[0]\n",
    "        for i in self.n_neuron:\n",
    "            # i * 256 --> i * 1\n",
    "            temp_weight = np.random.random((i, before))\n",
    "            temp_b = np.random.random((i, 1))\n",
    "            \n",
    "            self.weight.append(temp_weight)\n",
    "            self.b.append(temp_b)\n",
    "            \n",
    "            before = i\n",
    "            \n",
    "    def sigmod(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "            \n",
    "    def heaven_function(self, x):\n",
    "        return self.sigmod(x)\n",
    "        \n",
    "    def forward_prop(self, X_data):\n",
    "        self.init_value(X_data.T)\n",
    "        \n",
    "        self.input = X_data.T\n",
    "        \n",
    "        # go through all depths\n",
    "        for d in range(self.depth):\n",
    "            temp = self.weight[d] @ self.input + self.b[d]\n",
    "            self.input = self.heaven_function(temp)\n",
    "            \n",
    "        return self.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51395318 0.51395318 0.51395318 0.51395318 0.51395318]\n",
      " [0.69474249 0.69474249 0.69474249 0.69474249 0.69474249]\n",
      " [0.69748147 0.69748147 0.69748147 0.69748147 0.69748147]]\n",
      "[[0.51395489 0.51395481 0.51395321 0.51396081 0.51395429]\n",
      " [0.69474438 0.6947443  0.69474252 0.69475097 0.69474372]\n",
      " [0.69748244 0.69748239 0.69748148 0.69748582 0.6974821 ]]\n",
      "[[0.51395318 0.51395318 0.51395318 0.51395318 0.51395318]\n",
      " [0.69474249 0.69474249 0.69474249 0.69474249 0.69474249]\n",
      " [0.69748147 0.69748147 0.69748147 0.69748147 0.69748147]]\n",
      "[[0.51395318 0.51395318 0.51395318 0.51395318 0.51395318]\n",
      " [0.69474249 0.69474249 0.69474249 0.69474249 0.69474249]\n",
      " [0.69748147 0.69748147 0.69748147 0.69748147 0.69748147]]\n",
      "[[0.51395318 0.51395318 0.51395318 0.51395318 0.51395318]\n",
      " [0.69474249 0.69474249 0.69474249 0.69474249 0.69474249]\n",
      " [0.69748147 0.69748147 0.69748147 0.69748147 0.69748147]]\n"
     ]
    }
   ],
   "source": [
    "ann = ANN(2, [5, 3])\n",
    "\n",
    "for i in range(5):\n",
    "    print(ann.forward_prop(X_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Perceptron.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
